{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's anyalyse train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['textID', 'text', 'selected_text', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 27481 rows and 4 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3534, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have to predict the selected text from the given text and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, it looks like there are 1 text is missing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['selected_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['textID'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>fdb77c3752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID text selected_text sentiment\n",
       "314  fdb77c3752  NaN           NaN   neutral"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['text'].isnull()] # By using conditional selecting we can see which row has the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there is no text, the sentiment is neutral. Will it be better if I just remove this row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed the 1 row which had no value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected_text is a subset of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>22463</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>b622ed93ab</td>\n",
       "      <td>ouch acid reflux hurt too...</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>11117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            textID                           text selected_text sentiment\n",
       "count        27480                          27480         27480     27480\n",
       "unique       27480                          27480         22463         3\n",
       "top     b622ed93ab   ouch acid reflux hurt too...          good   neutral\n",
       "freq             1                              1           199     11117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the unique row of selected_text column, we can see that there are some selected_text which repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only three sentiments: positive, negative and neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           textID   text  selected_text\n",
      "sentiment                              \n",
      "negative     7781   7781           7781\n",
      "neutral     11117  11117          11117\n",
      "positive     8582   8582           8582\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('sentiment').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most text's are neutral...positive next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cfa40ced08>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='sentiment', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding MetaFeatures to our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding jaccard similarity index to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jaccard similarity or jaccard index is the similarity between two set/strings of values...it is defined by the no. of elements common to both the string(A intersection B) divided by the total number of elements(A union B)...you can see both strings as sets and thus use set operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_jaccard=[]\n",
    "\n",
    "for ind,row in data.iterrows():\n",
    "    sentence1 = row.text\n",
    "    sentence2 = row.selected_text\n",
    "\n",
    "    jaccard_score = jaccard(sentence1,sentence2)\n",
    "    results_jaccard.append(jaccard_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.2,\n",
       " 0.16666666666666666,\n",
       " 0.6,\n",
       " 0.21428571428571427,\n",
       " 1.0,\n",
       " 0.07142857142857142,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_jaccard[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that there are some items which have received a jaccard score of 1.... meaning that the selected text is exactly the same as the text itself...no item will have 0 jaccard index bcz selected_text is a subset of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the jaccard score to our data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['jaccard_index'] = results_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  jaccard_index  \n",
       "0  I`d have responded, if I were going   neutral       1.000000  \n",
       "1                             Sooo SAD  negative       0.200000  \n",
       "2                          bullying me  negative       0.166667  \n",
       "3                       leave me alone  negative       0.600000  \n",
       "4                        Sons of ****,  negative       0.214286  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding number of words in text, number of words in selected_text and the difference between the two in our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_words_ST'] = data['selected_text'].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_words_T'] = data['text'].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diff_in_words'] = data['num_words_T'] - data['num_words_ST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  I`d have responded, if I were going   neutral       1.000000             7   \n",
       "1                             Sooo SAD  negative       0.200000             2   \n",
       "2                          bullying me  negative       0.166667             2   \n",
       "3                       leave me alone  negative       0.600000             3   \n",
       "4                        Sons of ****,  negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words  \n",
       "0            7              0  \n",
       "1           10              8  \n",
       "2            5              3  \n",
       "3            5              2  \n",
       "4           14             11  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cfa4ca4d48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x='diff_in_words', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the rows have no differnce in their selected_text and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 27480 rows, 12000 rows have the same number of words in their selected_text and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the jaccard index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cfa51ad608>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.countplot(x='jaccard_index', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same result, of course......more than 12000 rows have jaccard index as 1....so do we remove those rows or ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                  text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going   \n",
       "\n",
       "                         selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  I`d have responded, if I were going   neutral            1.0             7   \n",
       "\n",
       "   num_words_T  diff_in_words  \n",
       "0            7              0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm....not sure...let's leave it be for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Before We Dive into extracting information out of words in text and selected text,let's first clean the data....bcz there are many symbols which do not convey sentiment but are there in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['selected_text'] = data['selected_text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words  \n",
       "0            7              0  \n",
       "1           10              8  \n",
       "2            5              3  \n",
       "3            5              2  \n",
       "4           14             11  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, any punctuation marks that might have been there are now removed...bcz sentiments are not decided by punctuation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the most common words in our target: selected_text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow0_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow1_col1 {\n",
       "            background-color:  #3383be;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow2_col1 {\n",
       "            background-color:  #57a0ce;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow3_col1 {\n",
       "            background-color:  #9ac8e0;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow4_col1 {\n",
       "            background-color:  #c4daee;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow5_col1 {\n",
       "            background-color:  #caddf0;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow6_col1 {\n",
       "            background-color:  #d3e4f3;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow7_col1 {\n",
       "            background-color:  #d9e7f5;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow8_col1 {\n",
       "            background-color:  #dae8f6;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow9_col1 {\n",
       "            background-color:  #dfebf7;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow10_col1 {\n",
       "            background-color:  #e3eef9;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow11_col1 {\n",
       "            background-color:  #e9f2fa;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow12_col1 {\n",
       "            background-color:  #eaf3fb;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow13_col1 {\n",
       "            background-color:  #eef5fc;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow14_col1 {\n",
       "            background-color:  #eff6fc;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow15_col1 {\n",
       "            background-color:  #f2f8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow16_col1 {\n",
       "            background-color:  #f4f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow17_col1 {\n",
       "            background-color:  #f6faff;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow18_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_f108da86_f1e0_11ea_9406_a19454a1cd3drow19_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Common_words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow0_col0\" class=\"data row0 col0\" >i</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow0_col1\" class=\"data row0 col1\" >7200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow1_col0\" class=\"data row1 col0\" >to</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow1_col1\" class=\"data row1 col1\" >5305</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow2_col0\" class=\"data row2 col0\" >the</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow2_col1\" class=\"data row2 col1\" >4590</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow3_col0\" class=\"data row3 col0\" >a</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow3_col1\" class=\"data row3 col1\" >3538</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow4_col0\" class=\"data row4 col0\" >my</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow4_col1\" class=\"data row4 col1\" >2783</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow5_col0\" class=\"data row5 col0\" >you</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow5_col1\" class=\"data row5 col1\" >2624</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow6_col0\" class=\"data row6 col0\" >and</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow6_col1\" class=\"data row6 col1\" >2321</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow7_col0\" class=\"data row7 col0\" >it</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow7_col1\" class=\"data row7 col1\" >2158</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow8_col0\" class=\"data row8 col0\" >is</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow8_col1\" class=\"data row8 col1\" >2115</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow9_col0\" class=\"data row9 col0\" >in</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow9_col1\" class=\"data row9 col1\" >1986</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow10_col0\" class=\"data row10 col0\" >for</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow10_col1\" class=\"data row10 col1\" >1854</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow11_col0\" class=\"data row11 col0\" >im</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow11_col1\" class=\"data row11 col1\" >1676</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow12_col0\" class=\"data row12 col0\" >of</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow12_col1\" class=\"data row12 col1\" >1638</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow13_col0\" class=\"data row13 col0\" >me</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow13_col1\" class=\"data row13 col1\" >1540</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow14_col0\" class=\"data row14 col0\" >on</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow14_col1\" class=\"data row14 col1\" >1488</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow15_col0\" class=\"data row15 col0\" >so</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow15_col1\" class=\"data row15 col1\" >1410</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow16_col0\" class=\"data row16 col0\" >have</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow16_col1\" class=\"data row16 col1\" >1345</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow17_col0\" class=\"data row17 col0\" >that</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow17_col1\" class=\"data row17 col1\" >1297</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow18_col0\" class=\"data row18 col0\" >but</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow18_col1\" class=\"data row18 col1\" >1267</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3dlevel0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow19_col0\" class=\"data row19 col0\" >good</td>\n",
       "                        <td id=\"T_f108da86_f1e0_11ea_9406_a19454a1cd3drow19_col1\" class=\"data row19 col1\" >1251</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cfa6d6a908>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "data['temp_list'] = data['selected_text'].apply(lambda x:str(x).split())\n",
    "top = Counter([item for sublist in data['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to remove the stopwords...Stopwords are the English words which does not add much meaning to a sentence....like I which takes the first place in our count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(x):\n",
    "    return [y for y in x if y not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons, of]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words                                  temp_list  \n",
       "0            7              0  [id, have, responded, if, i, were, going]  \n",
       "1           10              8                                [sooo, sad]  \n",
       "2            5              3                             [bullying, me]  \n",
       "3            5              2                         [leave, me, alone]  \n",
       "4           14             11                                 [sons, of]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp_list'] = data['temp_list'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words               temp_list  \n",
       "0            7              0  [id, responded, going]  \n",
       "1           10              8             [sooo, sad]  \n",
       "2            5              3              [bullying]  \n",
       "3            5              2          [leave, alone]  \n",
       "4           14             11                  [sons]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that useless words which not have much meaning in sentences(also called as stopwords) have been removed!!!! Let's see what's the count of selected_text now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow0_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow1_col1 {\n",
       "            background-color:  #4090c5;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow2_col1 {\n",
       "            background-color:  #79b5d9;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow3_col1 {\n",
       "            background-color:  #aacfe5;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow4_col1 {\n",
       "            background-color:  #bad6eb;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow5_col1 {\n",
       "            background-color:  #ccdff1;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow6_col1 {\n",
       "            background-color:  #cddff1;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow7_col1 {\n",
       "            background-color:  #cde0f1;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow8_col1 {\n",
       "            background-color:  #d8e7f5;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow9_col1 {\n",
       "            background-color:  #e7f1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow10_col1 {\n",
       "            background-color:  #e7f1fa;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow11_col1 {\n",
       "            background-color:  #eaf3fb;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow12_col1 {\n",
       "            background-color:  #f0f6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow13_col1 {\n",
       "            background-color:  #f1f7fd;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow14_col1 {\n",
       "            background-color:  #f4f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow15_col1 {\n",
       "            background-color:  #f5f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow16_col1 {\n",
       "            background-color:  #f5fafe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow17_col1 {\n",
       "            background-color:  #f6faff;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow18_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow19_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Common_words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow0_col0\" class=\"data row0 col0\" >im</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow0_col1\" class=\"data row0 col1\" >1676</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow1_col0\" class=\"data row1 col0\" >good</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow1_col1\" class=\"data row1 col1\" >1251</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow2_col0\" class=\"data row2 col0\" >day</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow2_col1\" class=\"data row2 col1\" >1058</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow3_col0\" class=\"data row3 col0\" >love</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow3_col1\" class=\"data row3 col1\" >909</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow4_col0\" class=\"data row4 col0\" >happy</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow4_col1\" class=\"data row4 col1\" >852</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow5_col0\" class=\"data row5 col0\" >like</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow5_col1\" class=\"data row5 col1\" >774</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow6_col0\" class=\"data row6 col0\" >get</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow6_col1\" class=\"data row6 col1\" >772</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow7_col0\" class=\"data row7 col0\" >dont</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow7_col1\" class=\"data row7 col1\" >765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow8_col0\" class=\"data row8 col0\" >go</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow8_col1\" class=\"data row8 col1\" >700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow9_col0\" class=\"data row9 col0\" >cant</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow9_col1\" class=\"data row9 col1\" >613</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow10_col0\" class=\"data row10 col0\" >work</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow10_col1\" class=\"data row10 col1\" >612</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow11_col0\" class=\"data row11 col0\" >going</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow11_col1\" class=\"data row11 col1\" >592</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow12_col0\" class=\"data row12 col0\" >today</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow12_col1\" class=\"data row12 col1\" >564</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow13_col0\" class=\"data row13 col0\" >got</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow13_col1\" class=\"data row13 col1\" >558</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow14_col0\" class=\"data row14 col0\" >one</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow14_col1\" class=\"data row14 col1\" >538</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow15_col0\" class=\"data row15 col0\" >time</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow15_col1\" class=\"data row15 col1\" >534</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow16_col0\" class=\"data row16 col0\" >thanks</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow16_col1\" class=\"data row16 col1\" >532</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow17_col0\" class=\"data row17 col0\" >lol</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow17_col1\" class=\"data row17 col1\" >528</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow18_col0\" class=\"data row18 col0\" >really</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow18_col1\" class=\"data row18 col1\" >520</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3dlevel0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow19_col0\" class=\"data row19 col0\" >u</td>\n",
       "                        <td id=\"T_0b34c0a2_f1e1_11ea_9969_a19454a1cd3drow19_col1\" class=\"data row19 col1\" >519</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cfa6d64ec8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([item for sublist in data['temp_list'] for item in sublist]) #this is a a very cool code it returns the most\n",
    "#occuring items in a list !!!!\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmmm.....Im was not removed after applying the remove stopwords function....should I remove it ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words               temp_list  \n",
       "0            7              0  [id, responded, going]  \n",
       "1           10              8             [sooo, sad]  \n",
       "2            5              3              [bullying]  \n",
       "3            5              2          [leave, alone]  \n",
       "4           14             11                  [sons]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'responded',\n",
       " 'going',\n",
       " 'sooo',\n",
       " 'sad',\n",
       " 'bullying',\n",
       " 'leave',\n",
       " 'alone',\n",
       " 'sons',\n",
       " 'shameless',\n",
       " 'plugging',\n",
       " 'best',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'earth',\n",
       " 'fun',\n",
       " 'soooo',\n",
       " 'high',\n",
       " 'wow',\n",
       " 'u',\n",
       " 'became',\n",
       " 'cooler',\n",
       " 'much',\n",
       " 'love',\n",
       " 'hopeful',\n",
       " 'reckon',\n",
       " 'chances',\n",
       " 'minimal',\n",
       " 'p',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'get',\n",
       " 'cake',\n",
       " 'stuff',\n",
       " 'like',\n",
       " 'dangerously',\n",
       " 'lost',\n",
       " 'test',\n",
       " 'test',\n",
       " 'lg',\n",
       " 'uh',\n",
       " 'oh',\n",
       " 'sunburned',\n",
       " 'sigh',\n",
       " 'sick',\n",
       " 'onna',\n",
       " 'hes',\n",
       " 'oh',\n",
       " 'marly',\n",
       " 'im',\n",
       " 'sorry',\n",
       " 'hope',\n",
       " 'find',\n",
       " 'soon',\n",
       " 'interesting',\n",
       " 'cleaning',\n",
       " 'house',\n",
       " 'family',\n",
       " 'comming',\n",
       " 'later',\n",
       " 'today',\n",
       " 'gotta',\n",
       " 'restart',\n",
       " 'computer',\n",
       " 'thought',\n",
       " 'supposed',\n",
       " 'put',\n",
       " 'end',\n",
       " 'constant',\n",
       " 'rebootiness',\n",
       " 'see',\n",
       " 'wat',\n",
       " 'mean',\n",
       " 'bout',\n",
       " 'friidays',\n",
       " 'called',\n",
       " 'lose',\n",
       " 'friday',\n",
       " 'smh',\n",
       " 'free',\n",
       " 'fillin',\n",
       " 'app',\n",
       " 'ipod',\n",
       " 'fun',\n",
       " 'im',\n",
       " 'addicted',\n",
       " 'im',\n",
       " 'sorry',\n",
       " 'internet',\n",
       " 'fun',\n",
       " 'power',\n",
       " 'back',\n",
       " 'working',\n",
       " 'quiteheavenly',\n",
       " 'hope',\n",
       " 'well',\n",
       " 'much',\n",
       " 'unhappy',\n",
       " 'minute',\n",
       " 'funny',\n",
       " 'ahhh',\n",
       " 'slept',\n",
       " 'game',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'try',\n",
       " 'best',\n",
       " 'watch',\n",
       " 'tomorrow',\n",
       " 'though',\n",
       " 'hope',\n",
       " 'play',\n",
       " 'army',\n",
       " 'thats',\n",
       " 'end',\n",
       " 'tears',\n",
       " 'fears',\n",
       " 'miss',\n",
       " 'case',\n",
       " 'wonder',\n",
       " 'really',\n",
       " 'busy',\n",
       " 'today',\n",
       " 'coming',\n",
       " 'adding',\n",
       " 'tons',\n",
       " 'new',\n",
       " 'blogs',\n",
       " 'updates',\n",
       " 'stay',\n",
       " 'tuned',\n",
       " 'soooooo',\n",
       " 'sleeeeepy',\n",
       " 'little',\n",
       " 'happy',\n",
       " 'fo',\n",
       " 'car',\n",
       " 'happy',\n",
       " 'big',\n",
       " 'big',\n",
       " 'dent',\n",
       " 'boot',\n",
       " 'hoping',\n",
       " 'theyre',\n",
       " 'going',\n",
       " 'write',\n",
       " 'crossing',\n",
       " 'fingers',\n",
       " 'waiting',\n",
       " 'avid',\n",
       " 'fan',\n",
       " 'mayday',\n",
       " 'ratt',\n",
       " 'rocked',\n",
       " 'nashville',\n",
       " 'toniteone',\n",
       " 'thing',\n",
       " 'sucked',\n",
       " 'encore',\n",
       " 'like',\n",
       " 'still',\n",
       " 'fun',\n",
       " 'show',\n",
       " 'pearcy',\n",
       " 'hott',\n",
       " 'bad',\n",
       " 'boy',\n",
       " 'look',\n",
       " 'love',\n",
       " 'girl',\n",
       " 'hair',\n",
       " 'salon',\n",
       " 'asked',\n",
       " 'shall',\n",
       " 'trim',\n",
       " 'eyebrows',\n",
       " 'old',\n",
       " 'feel',\n",
       " 'suckkkkkk',\n",
       " 'visiting',\n",
       " 'friendster',\n",
       " 'facebook',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'go',\n",
       " 'im',\n",
       " 'thrilled',\n",
       " 'mine',\n",
       " 'check',\n",
       " 'connect',\n",
       " 'tweeple',\n",
       " 'hate',\n",
       " 'twitter',\n",
       " 'also',\n",
       " 'bored',\n",
       " 'school',\n",
       " 'third',\n",
       " 'freelesson',\n",
       " 'freistunde',\n",
       " 'hm',\n",
       " 'us',\n",
       " 'guess',\n",
       " 'u',\n",
       " 'dissappointed',\n",
       " 'past',\n",
       " 'days',\n",
       " 'romance',\n",
       " 'zero',\n",
       " 'funny',\n",
       " 'id',\n",
       " 'rather',\n",
       " 'early',\n",
       " 'runbut',\n",
       " 'morning',\n",
       " 'runner',\n",
       " 'hurts',\n",
       " 'back',\n",
       " 'later',\n",
       " 'torn',\n",
       " 'ace',\n",
       " 'hearts',\n",
       " 'fun',\n",
       " 'speaking',\n",
       " 'lost',\n",
       " 'friends',\n",
       " 'im',\n",
       " 'alone',\n",
       " 'sleepy',\n",
       " 'haha',\n",
       " 'yes',\n",
       " 'give',\n",
       " 'easily',\n",
       " 'favorite',\n",
       " 'jealous',\n",
       " 'photoshoot',\n",
       " 'awesome',\n",
       " 'yay',\n",
       " 'playing',\n",
       " 'show',\n",
       " 'tonight',\n",
       " 'boo',\n",
       " 'gonna',\n",
       " 'soggy',\n",
       " 'im',\n",
       " 'work',\n",
       " 'right',\n",
       " 'playing',\n",
       " 'chilliin',\n",
       " 'know',\n",
       " 'agent',\n",
       " 'let',\n",
       " 'know',\n",
       " 'still',\n",
       " 'smell',\n",
       " 'smoke',\n",
       " 'kitchenfire',\n",
       " 'better',\n",
       " 'anyone',\n",
       " 'extra',\n",
       " 'keane',\n",
       " 'ticket',\n",
       " 'promise',\n",
       " 'buy',\n",
       " 'drink',\n",
       " 'take',\n",
       " 'rad',\n",
       " 'pics',\n",
       " 'fb',\n",
       " 'blog',\n",
       " 'flickr',\n",
       " 'etc',\n",
       " 'ride',\n",
       " 'one',\n",
       " 'catch',\n",
       " 'one',\n",
       " 'summer',\n",
       " 'til',\n",
       " 'pop',\n",
       " 'open',\n",
       " 'one',\n",
       " 'good',\n",
       " 'gorjuz',\n",
       " 'yea',\n",
       " 'kno',\n",
       " 'asked',\n",
       " 'yesterday',\n",
       " 'tha',\n",
       " 'hospital',\n",
       " 'talked',\n",
       " 'u',\n",
       " 'said',\n",
       " 'ok',\n",
       " 'im',\n",
       " 'popped',\n",
       " 'say',\n",
       " 'hi',\n",
       " 'check',\n",
       " 'things',\n",
       " 'ill',\n",
       " 'probably',\n",
       " 'head',\n",
       " 'guttah',\n",
       " 'later',\n",
       " 'tonight',\n",
       " 'baddd',\n",
       " 'sources',\n",
       " 'say',\n",
       " 'sooo',\n",
       " 'tired',\n",
       " 'hey',\n",
       " 'change',\n",
       " 'twitter',\n",
       " 'account',\n",
       " 'didnt',\n",
       " 'even',\n",
       " 'tell',\n",
       " 'thank',\n",
       " 'yyyyyyyyyoooooooooouuuuu',\n",
       " 'lucky',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " 'waiting',\n",
       " 'ride',\n",
       " 'sick',\n",
       " 'sorry',\n",
       " 'guys',\n",
       " 'happy',\n",
       " 'star',\n",
       " 'wars',\n",
       " 'day',\n",
       " 'everyone',\n",
       " 'enjoy',\n",
       " 'holiday',\n",
       " 'uk',\n",
       " 'miles',\n",
       " 'im',\n",
       " 'essex',\n",
       " 'give',\n",
       " 'plenty',\n",
       " 'warning',\n",
       " 'arrive',\n",
       " 'time',\n",
       " 'get',\n",
       " 'least',\n",
       " 'one',\n",
       " 'free',\n",
       " 'beers',\n",
       " 'snoring',\n",
       " 'annoying',\n",
       " 'n',\n",
       " 'keeps',\n",
       " 'sleeping',\n",
       " 'like',\n",
       " 'right',\n",
       " 'lol',\n",
       " 'honestly',\n",
       " 'wud',\n",
       " 'miss',\n",
       " 'eva',\n",
       " 'left',\n",
       " 'love',\n",
       " 'miss',\n",
       " 'bby',\n",
       " 'cool',\n",
       " 'love',\n",
       " 'mounce',\n",
       " 'yes',\n",
       " 'lasts',\n",
       " 'way',\n",
       " 'past',\n",
       " 'bedtime',\n",
       " 'hi',\n",
       " 'joined',\n",
       " 'twitter',\n",
       " 'tired',\n",
       " 'eating',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'getting',\n",
       " 'ready',\n",
       " 'graduation',\n",
       " 'happy',\n",
       " 'mothers',\n",
       " 'day',\n",
       " 'mums',\n",
       " 'freaked',\n",
       " 'unfortunately',\n",
       " 'gonna',\n",
       " 'read',\n",
       " 'story',\n",
       " 'bout',\n",
       " 'adam',\n",
       " 'lambert',\n",
       " 'online',\n",
       " 'bed',\n",
       " 'nighty',\n",
       " 'night',\n",
       " 'best',\n",
       " 'pretty',\n",
       " 'certainly',\n",
       " 'cheers',\n",
       " 'huh',\n",
       " 'horrible',\n",
       " 'busy',\n",
       " 'awesome',\n",
       " 'least',\n",
       " 'get',\n",
       " 'watch',\n",
       " 'time',\n",
       " 'lets',\n",
       " 'go',\n",
       " 'pens',\n",
       " 'cool',\n",
       " 'wear',\n",
       " 'black',\n",
       " 'time',\n",
       " 'go',\n",
       " 'thanks',\n",
       " 'safe',\n",
       " 'wish',\n",
       " 'allowed',\n",
       " 'go',\n",
       " 'u',\n",
       " 'friendster',\n",
       " 'add',\n",
       " 'email',\n",
       " 'adress',\n",
       " 'add',\n",
       " 'add',\n",
       " 'tickets',\n",
       " 'thank',\n",
       " 'acsm',\n",
       " 'unfathomable',\n",
       " 'think',\n",
       " 'one',\n",
       " 'one',\n",
       " 'kept',\n",
       " 'comfort',\n",
       " 'bedrooms',\n",
       " 'yes',\n",
       " 'love',\n",
       " 'dont',\n",
       " 'feel',\n",
       " 'confident',\n",
       " 'sad',\n",
       " 'hahaa',\n",
       " 'awesomee',\n",
       " 'awesomeeeee',\n",
       " 'hate',\n",
       " 'fallout',\n",
       " 'keeps',\n",
       " 'making',\n",
       " 'jump',\n",
       " 'im',\n",
       " 'also',\n",
       " 'low',\n",
       " 'health',\n",
       " 'money',\n",
       " 'ammo',\n",
       " 'food',\n",
       " 'dont',\n",
       " 'worry',\n",
       " 'ill',\n",
       " 'get',\n",
       " 'itunes',\n",
       " 'lost',\n",
       " 'songs',\n",
       " 'whats',\n",
       " 'gloomy',\n",
       " 'weather',\n",
       " 'sun',\n",
       " 'must',\n",
       " 'tired',\n",
       " 'come',\n",
       " 'play',\n",
       " 'heading',\n",
       " 'victoria',\n",
       " 'gardens',\n",
       " 'impulse',\n",
       " 'buys',\n",
       " 'haha',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'poor',\n",
       " 'well',\n",
       " 'prob',\n",
       " 'dads',\n",
       " 'watching',\n",
       " 'mtv',\n",
       " 'going',\n",
       " 'minutee',\n",
       " 'absolutely',\n",
       " 'whats',\n",
       " 'matter',\n",
       " 'chickadee',\n",
       " 'adore',\n",
       " 'good',\n",
       " 'love',\n",
       " 'painful',\n",
       " 'sad',\n",
       " 'e',\n",
       " 'nice',\n",
       " 'wish',\n",
       " 'namaskar',\n",
       " 'namaste',\n",
       " 'r',\n",
       " 'marathi',\n",
       " 'people',\n",
       " 'say',\n",
       " 'namaskar',\n",
       " 'marathi',\n",
       " 'word',\n",
       " 'naaaah',\n",
       " 'congrats',\n",
       " 'cuss',\n",
       " 'like',\n",
       " 'matter',\n",
       " 'minutes',\n",
       " 'didnt',\n",
       " 'know',\n",
       " 'reward',\n",
       " 'humous',\n",
       " 'doritos',\n",
       " 'oh',\n",
       " 'yes',\n",
       " 'missed',\n",
       " 'awesome',\n",
       " 'weather',\n",
       " 'today',\n",
       " 'going',\n",
       " 'normal',\n",
       " 'day',\n",
       " 'hope',\n",
       " 'group',\n",
       " 'pilots',\n",
       " 'large',\n",
       " 'airline',\n",
       " 'come',\n",
       " 'last',\n",
       " 'night',\n",
       " 'much',\n",
       " 'drink',\n",
       " 'terrible',\n",
       " 'unfortunatley',\n",
       " 'sucks',\n",
       " 'tho',\n",
       " 'hate',\n",
       " 'fighting',\n",
       " 'watched',\n",
       " 'didnt',\n",
       " 'want',\n",
       " 'win',\n",
       " 'put',\n",
       " 'good',\n",
       " 'fightlol',\n",
       " 'carwarmed',\n",
       " 'sprite',\n",
       " 'tastes',\n",
       " 'like',\n",
       " 'sore',\n",
       " 'throat',\n",
       " 'came',\n",
       " 'cross',\n",
       " 'country',\n",
       " 'beat',\n",
       " 'dumbo',\n",
       " 'enjoyable',\n",
       " 'endearing',\n",
       " 'tomorrow',\n",
       " 'valerias',\n",
       " 'lunch',\n",
       " 'going',\n",
       " 'get',\n",
       " 'hair',\n",
       " 'done',\n",
       " 'im',\n",
       " 'arraving',\n",
       " 'late',\n",
       " 'got',\n",
       " 'cousins',\n",
       " 'babtizm',\n",
       " 'whatever',\n",
       " 'spell',\n",
       " 'goooooddd',\n",
       " 'morning',\n",
       " 'tweets',\n",
       " 'hate',\n",
       " 'fine',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'ones',\n",
       " 'mmmmmmmm',\n",
       " 'morning',\n",
       " 'neither',\n",
       " 'hours',\n",
       " 'work',\n",
       " 'sunday',\n",
       " 'boo',\n",
       " 'find',\n",
       " 'time',\n",
       " 'two',\n",
       " 'hour',\n",
       " 'lunchbreak',\n",
       " 'though',\n",
       " 'yeah',\n",
       " 'bugger',\n",
       " 'forgot',\n",
       " 'still',\n",
       " 'washing',\n",
       " 'machine',\n",
       " 'sending',\n",
       " 'love',\n",
       " 'blessings',\n",
       " 'healing',\n",
       " 'thoughts',\n",
       " 'family',\n",
       " 'peace',\n",
       " 'really',\n",
       " 'bad',\n",
       " 'ah',\n",
       " 'yes',\n",
       " 'know',\n",
       " 'feeling',\n",
       " 'night',\n",
       " 'cookers',\n",
       " 'dad',\n",
       " 'brutal',\n",
       " 'nope',\n",
       " 'coquitlam',\n",
       " 'boring',\n",
       " 'p',\n",
       " 'sounds',\n",
       " 'like',\n",
       " 'fun',\n",
       " 'big',\n",
       " 'booming',\n",
       " 'thunder',\n",
       " 'storm',\n",
       " 'almost',\n",
       " 'maybe',\n",
       " 'go',\n",
       " 'home',\n",
       " 'early',\n",
       " 'ah',\n",
       " 'probably',\n",
       " 'great',\n",
       " 'excited',\n",
       " 'good',\n",
       " 'morning',\n",
       " 'best',\n",
       " 'show',\n",
       " 'ever',\n",
       " 'messed',\n",
       " 'think',\n",
       " 'iv',\n",
       " 'hurt',\n",
       " 'tooth',\n",
       " 'eilish',\n",
       " 'cassie',\n",
       " 'drawing',\n",
       " 'competiton',\n",
       " 'draw',\n",
       " 'cookies',\n",
       " 'pineapples',\n",
       " 'haha',\n",
       " 'l',\n",
       " 'want',\n",
       " 'know',\n",
       " 'auditions',\n",
       " 'mander',\n",
       " 'text',\n",
       " 'orreply',\n",
       " 'please',\n",
       " 'secret',\n",
       " 'namerebecca',\n",
       " 'please',\n",
       " 'miss',\n",
       " 'need',\n",
       " 'get',\n",
       " 'computer',\n",
       " 'fixed',\n",
       " 'illness',\n",
       " 'cool',\n",
       " 'people',\n",
       " 'want',\n",
       " 'find',\n",
       " 'following',\n",
       " 'today',\n",
       " 'english',\n",
       " 'guess',\n",
       " 'english',\n",
       " 'dont',\n",
       " 'tweet',\n",
       " 'siri',\n",
       " 'woulda',\n",
       " 'put',\n",
       " 'honeybut',\n",
       " 'dont',\n",
       " 'totally',\n",
       " 'loved',\n",
       " 'u',\n",
       " 'helped',\n",
       " 'thru',\n",
       " 'hrdest',\n",
       " 'time',\n",
       " 'life',\n",
       " 'sad',\n",
       " 'finally',\n",
       " 'got',\n",
       " 'call',\n",
       " 'marriage',\n",
       " 'counseling',\n",
       " 'days',\n",
       " 'late',\n",
       " 'ok',\n",
       " 'baby',\n",
       " 'sick',\n",
       " 'impromptu',\n",
       " 'pool',\n",
       " 'party',\n",
       " 'except',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'swim',\n",
       " 'cant',\n",
       " 'get',\n",
       " 'oww',\n",
       " 'happy',\n",
       " 'year',\n",
       " 'goooooooooooood',\n",
       " 'morrrrrrrrning',\n",
       " 'phew',\n",
       " 'make',\n",
       " 'note',\n",
       " 'case',\n",
       " 'anyone',\n",
       " 'else',\n",
       " 'runs',\n",
       " 'issue',\n",
       " 'vote',\n",
       " 'every',\n",
       " 'day',\n",
       " 'diet',\n",
       " 'killing',\n",
       " 'talk',\n",
       " 'bored',\n",
       " 'e',\n",
       " 'fun',\n",
       " 'far',\n",
       " 'good',\n",
       " 'sleep',\n",
       " 'hours',\n",
       " 'getting',\n",
       " 'bit',\n",
       " 'twitchy',\n",
       " 'whats',\n",
       " 'twatter',\n",
       " 'lately',\n",
       " 'either',\n",
       " 'cant',\n",
       " 'get',\n",
       " 'replies',\n",
       " 'dont',\n",
       " 'turn',\n",
       " 'lost',\n",
       " 'voice',\n",
       " 'hate',\n",
       " 'ive',\n",
       " 'heard',\n",
       " 'fall',\n",
       " 'im',\n",
       " 'waiting',\n",
       " 'nightmares',\n",
       " 'huggles',\n",
       " 'creeper',\n",
       " 'feel',\n",
       " 'disappointed',\n",
       " 'cyberstalking',\n",
       " 'skills',\n",
       " 'internet',\n",
       " 'privacy',\n",
       " 'headache',\n",
       " 'happy',\n",
       " 'grabbing',\n",
       " 'coffee',\n",
       " 'making',\n",
       " 'mom',\n",
       " 'breakfast',\n",
       " 'going',\n",
       " 'fun',\n",
       " 'thanks',\n",
       " 'major',\n",
       " 'chop',\n",
       " 'thank',\n",
       " 'got',\n",
       " 'updated',\n",
       " 'ipod',\n",
       " 'hahaha',\n",
       " 'crush',\n",
       " 'saw',\n",
       " 'james',\n",
       " 'carville',\n",
       " 'store',\n",
       " 'today',\n",
       " 'head',\n",
       " 'really',\n",
       " 'bald',\n",
       " 'yellow',\n",
       " 'means',\n",
       " 'youre',\n",
       " 'going',\n",
       " 'come',\n",
       " 'back',\n",
       " 'vancouver',\n",
       " 'way',\n",
       " 'hahah',\n",
       " 'feeling',\n",
       " 'smooth',\n",
       " 'ew',\n",
       " 'traffic',\n",
       " 'downloading',\n",
       " 'songs',\n",
       " 'trying',\n",
       " 'sneak',\n",
       " 'lil',\n",
       " 'homework',\n",
       " 'main',\n",
       " 'priority',\n",
       " 'songs',\n",
       " 'lol',\n",
       " 'alonei',\n",
       " 'need',\n",
       " 'coffee',\n",
       " 'sounds',\n",
       " 'like',\n",
       " 'bad',\n",
       " 'day',\n",
       " 'day',\n",
       " 'realize',\n",
       " 'mess',\n",
       " 'youve',\n",
       " 'put',\n",
       " 'one',\n",
       " 'happiest',\n",
       " 'days',\n",
       " 'life',\n",
       " 'hate',\n",
       " 'bike',\n",
       " 'nesmith',\n",
       " 'worse',\n",
       " 'taxes',\n",
       " 'jonas',\n",
       " 'brothers',\n",
       " 'live',\n",
       " 'party',\n",
       " 'rocking',\n",
       " 'hard',\n",
       " 'happy',\n",
       " 'would',\n",
       " 'love',\n",
       " 'test',\n",
       " 'though',\n",
       " 'fun',\n",
       " 'night',\n",
       " 'exception',\n",
       " 'short',\n",
       " 'dude',\n",
       " 'larenz',\n",
       " 'fineass',\n",
       " 'tate',\n",
       " 'yum',\n",
       " 'thought',\n",
       " 'wolverine',\n",
       " 'awesome',\n",
       " 'hopefully',\n",
       " 'yes',\n",
       " 'work',\n",
       " 'hmmm',\n",
       " 'maybe',\n",
       " 'thats',\n",
       " 'meant',\n",
       " 'eluded',\n",
       " 'something',\n",
       " 'brand',\n",
       " 'new',\n",
       " 'know',\n",
       " 'media',\n",
       " 'done',\n",
       " 'spa',\n",
       " 'meeting',\n",
       " 'vic',\n",
       " 'late',\n",
       " 'lunch',\n",
       " 'happy',\n",
       " 'always',\n",
       " 'wanted',\n",
       " 'go',\n",
       " 'oz',\n",
       " 'thx',\n",
       " 'luv',\n",
       " 'thats',\n",
       " 'need',\n",
       " 'okay',\n",
       " 'im',\n",
       " 'dedicating',\n",
       " 'tweet',\n",
       " 'fact',\n",
       " 'im',\n",
       " 'going',\n",
       " 'apple',\n",
       " 'store',\n",
       " 'huge',\n",
       " 'crack',\n",
       " 'glass',\n",
       " 'screen',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'actually',\n",
       " 'allowed',\n",
       " 'stay',\n",
       " 'let',\n",
       " 'know',\n",
       " 'turns',\n",
       " 'sass',\n",
       " 'detect',\n",
       " 'long',\n",
       " 'isnt',\n",
       " 'back',\n",
       " 'sass',\n",
       " 'haha',\n",
       " 'ahaha',\n",
       " 'sports',\n",
       " 'bar',\n",
       " 'shatranjanpoli',\n",
       " 'rest',\n",
       " 'ph',\n",
       " 'sports',\n",
       " 'bar',\n",
       " 'andheri',\n",
       " 'w',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'whether',\n",
       " 'helps',\n",
       " 'google',\n",
       " 'ki',\n",
       " 'jai',\n",
       " 'ho',\n",
       " 'im',\n",
       " 'sleeping',\n",
       " 'un',\n",
       " 'seriously',\n",
       " 'live',\n",
       " 'pain',\n",
       " 'bring',\n",
       " 'okay',\n",
       " 'im',\n",
       " 'back',\n",
       " 'later',\n",
       " 'g',\n",
       " 'powerblog',\n",
       " 'challenge',\n",
       " 'keep',\n",
       " 'talking',\n",
       " 'im',\n",
       " 'newbie',\n",
       " 'followe',\n",
       " 'died',\n",
       " 'waiting',\n",
       " 'tish',\n",
       " 'get',\n",
       " 'got',\n",
       " 'drive',\n",
       " 'moms',\n",
       " 'crv',\n",
       " 'pick',\n",
       " 'duckie',\n",
       " 'first',\n",
       " 'time',\n",
       " 'going',\n",
       " 'well',\n",
       " 'going',\n",
       " 'shower',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'smell',\n",
       " 'school',\n",
       " 'tomorrow',\n",
       " 'sigh',\n",
       " 'know',\n",
       " 'hopefully',\n",
       " 'free',\n",
       " 'twitter',\n",
       " 'tools',\n",
       " 'get',\n",
       " 'followers',\n",
       " 'got',\n",
       " 'home',\n",
       " 'work',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for sublist in data['temp_list'] for item in sublist] # I do not understand this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " textID                                   cb774db0d1\n",
       " text              id have responded if i were going\n",
       " selected_text     id have responded if i were going\n",
       " sentiment                                   neutral\n",
       " jaccard_index                                     1\n",
       " num_words_ST                                      7\n",
       " num_words_T                                       7\n",
       " diff_in_words                                     0\n",
       " temp_list                    [id, responded, going]\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeim(x):\n",
    "    y = []\n",
    "    for i in x:\n",
    "        if i!='im':\n",
    "            y.append(i)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp_list'] = data['temp_list'].apply(lambda x:removeim(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words               temp_list  \n",
       "0            7              0  [id, responded, going]  \n",
       "1           10              8             [sooo, sad]  \n",
       "2            5              3              [bullying]  \n",
       "3            5              2          [leave, alone]  \n",
       "4           14             11                  [sons]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have removed all im words in temp_list....let's see which is the most common words in selected_text now!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow0_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow1_col1 {\n",
       "            background-color:  #2474b7;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow2_col1 {\n",
       "            background-color:  #60a7d2;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow3_col1 {\n",
       "            background-color:  #7db8da;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow4_col1 {\n",
       "            background-color:  #a6cee4;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow5_col1 {\n",
       "            background-color:  #a8cee4;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow6_col1 {\n",
       "            background-color:  #aacfe5;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow7_col1 {\n",
       "            background-color:  #c7dbef;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow8_col1 {\n",
       "            background-color:  #deebf7;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow9_col1 {\n",
       "            background-color:  #deebf7;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow10_col1 {\n",
       "            background-color:  #e3eef9;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow11_col1 {\n",
       "            background-color:  #ebf3fb;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow12_col1 {\n",
       "            background-color:  #edf4fc;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow13_col1 {\n",
       "            background-color:  #f2f8fd;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow14_col1 {\n",
       "            background-color:  #f3f8fe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow15_col1 {\n",
       "            background-color:  #f4f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow16_col1 {\n",
       "            background-color:  #f5f9fe;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow17_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow18_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow19_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Common_words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow0_col0\" class=\"data row0 col0\" >good</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow0_col1\" class=\"data row0 col1\" >1251</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow1_col0\" class=\"data row1 col0\" >day</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow1_col1\" class=\"data row1 col1\" >1058</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow2_col0\" class=\"data row2 col0\" >love</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow2_col1\" class=\"data row2 col1\" >909</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow3_col0\" class=\"data row3 col0\" >happy</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow3_col1\" class=\"data row3 col1\" >852</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow4_col0\" class=\"data row4 col0\" >like</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow4_col1\" class=\"data row4 col1\" >774</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow5_col0\" class=\"data row5 col0\" >get</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow5_col1\" class=\"data row5 col1\" >772</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow6_col0\" class=\"data row6 col0\" >dont</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow6_col1\" class=\"data row6 col1\" >765</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow7_col0\" class=\"data row7 col0\" >go</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow7_col1\" class=\"data row7 col1\" >700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow8_col0\" class=\"data row8 col0\" >cant</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow8_col1\" class=\"data row8 col1\" >613</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow9_col0\" class=\"data row9 col0\" >work</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow9_col1\" class=\"data row9 col1\" >612</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow10_col0\" class=\"data row10 col0\" >going</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow10_col1\" class=\"data row10 col1\" >592</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow11_col0\" class=\"data row11 col0\" >today</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow11_col1\" class=\"data row11 col1\" >564</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow12_col0\" class=\"data row12 col0\" >got</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow12_col1\" class=\"data row12 col1\" >558</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow13_col0\" class=\"data row13 col0\" >one</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow13_col1\" class=\"data row13 col1\" >538</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow14_col0\" class=\"data row14 col0\" >time</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow14_col1\" class=\"data row14 col1\" >534</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow15_col0\" class=\"data row15 col0\" >thanks</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow15_col1\" class=\"data row15 col1\" >532</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow16_col0\" class=\"data row16 col0\" >lol</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow16_col1\" class=\"data row16 col1\" >528</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow17_col0\" class=\"data row17 col0\" >really</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow17_col1\" class=\"data row17 col1\" >520</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow18_col0\" class=\"data row18 col0\" >u</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow18_col1\" class=\"data row18 col1\" >519</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3dlevel0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow19_col0\" class=\"data row19 col0\" >miss</td>\n",
       "                        <td id=\"T_0b5daf1e_f1e1_11ea_8e9b_a19454a1cd3drow19_col1\" class=\"data row19 col1\" >519</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cfa6801b48>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([item for sublist in data['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that good is the most common word in selected_text !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common word in text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp_list1'] = data['text'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "      <th>temp_list1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying]</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, alone]</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons]</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words               temp_list  \\\n",
       "0            7              0  [id, responded, going]   \n",
       "1           10              8             [sooo, sad]   \n",
       "2            5              3              [bullying]   \n",
       "3            5              2          [leave, alone]   \n",
       "4           14             11                  [sons]   \n",
       "\n",
       "                                          temp_list1  \n",
       "0          [id, have, responded, if, i, were, going]  \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...  \n",
       "2                       [my, boss, is, bullying, me]  \n",
       "3                [what, interview, leave, me, alone]  \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'have',\n",
       " 'responded',\n",
       " 'if',\n",
       " 'i',\n",
       " 'were',\n",
       " 'going',\n",
       " 'sooo',\n",
       " 'sad',\n",
       " 'i',\n",
       " 'will',\n",
       " 'miss',\n",
       " 'you',\n",
       " 'here',\n",
       " 'in',\n",
       " 'san',\n",
       " 'diego',\n",
       " 'my',\n",
       " 'boss',\n",
       " 'is',\n",
       " 'bullying',\n",
       " 'me',\n",
       " 'what',\n",
       " 'interview',\n",
       " 'leave',\n",
       " 'me',\n",
       " 'alone',\n",
       " 'sons',\n",
       " 'of',\n",
       " 'why',\n",
       " 'couldnt',\n",
       " 'they',\n",
       " 'put',\n",
       " 'them',\n",
       " 'on',\n",
       " 'the',\n",
       " 'releases',\n",
       " 'we',\n",
       " 'already',\n",
       " 'bought',\n",
       " 'some',\n",
       " 'shameless',\n",
       " 'plugging',\n",
       " 'for',\n",
       " 'the',\n",
       " 'best',\n",
       " 'rangers',\n",
       " 'forum',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'feedings',\n",
       " 'for',\n",
       " 'the',\n",
       " 'baby',\n",
       " 'are',\n",
       " 'fun',\n",
       " 'when',\n",
       " 'he',\n",
       " 'is',\n",
       " 'all',\n",
       " 'smiles',\n",
       " 'and',\n",
       " 'coos',\n",
       " 'soooo',\n",
       " 'high',\n",
       " 'both',\n",
       " 'of',\n",
       " 'you',\n",
       " 'journey',\n",
       " 'wow',\n",
       " 'u',\n",
       " 'just',\n",
       " 'became',\n",
       " 'cooler',\n",
       " 'hehe',\n",
       " 'is',\n",
       " 'that',\n",
       " 'possible',\n",
       " 'as',\n",
       " 'much',\n",
       " 'as',\n",
       " 'i',\n",
       " 'love',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hopeful',\n",
       " 'i',\n",
       " 'reckon',\n",
       " 'the',\n",
       " 'chances',\n",
       " 'are',\n",
       " 'minimal',\n",
       " 'p',\n",
       " 'im',\n",
       " 'never',\n",
       " 'gonna',\n",
       " 'get',\n",
       " 'my',\n",
       " 'cake',\n",
       " 'and',\n",
       " 'stuff',\n",
       " 'i',\n",
       " 'really',\n",
       " 'really',\n",
       " 'like',\n",
       " 'the',\n",
       " 'song',\n",
       " 'love',\n",
       " 'story',\n",
       " 'by',\n",
       " 'taylor',\n",
       " 'swift',\n",
       " 'my',\n",
       " 'sharpie',\n",
       " 'is',\n",
       " 'running',\n",
       " 'dangerously',\n",
       " 'low',\n",
       " 'on',\n",
       " 'ink',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'music',\n",
       " 'tonight',\n",
       " 'but',\n",
       " 'i',\n",
       " 'lost',\n",
       " 'my',\n",
       " 'voice',\n",
       " 'test',\n",
       " 'test',\n",
       " 'from',\n",
       " 'the',\n",
       " 'lg',\n",
       " 'uh',\n",
       " 'oh',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sunburned',\n",
       " 'sok',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'alternatives',\n",
       " 'as',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'sigh',\n",
       " 'ive',\n",
       " 'been',\n",
       " 'sick',\n",
       " 'for',\n",
       " 'the',\n",
       " 'past',\n",
       " 'few',\n",
       " 'days',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'my',\n",
       " 'hair',\n",
       " 'looks',\n",
       " 'wierd',\n",
       " 'if',\n",
       " 'i',\n",
       " 'didnt',\n",
       " 'have',\n",
       " 'a',\n",
       " 'hat',\n",
       " 'on',\n",
       " 'it',\n",
       " 'would',\n",
       " 'look',\n",
       " 'is',\n",
       " 'back',\n",
       " 'home',\n",
       " 'now',\n",
       " 'gonna',\n",
       " 'miss',\n",
       " 'every',\n",
       " 'one',\n",
       " 'hes',\n",
       " 'just',\n",
       " 'not',\n",
       " 'that',\n",
       " 'into',\n",
       " 'you',\n",
       " 'oh',\n",
       " 'marly',\n",
       " 'im',\n",
       " 'so',\n",
       " 'sorry',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'find',\n",
       " 'her',\n",
       " 'soon',\n",
       " 'playing',\n",
       " 'ghost',\n",
       " 'online',\n",
       " 'is',\n",
       " 'really',\n",
       " 'interesting',\n",
       " 'the',\n",
       " 'new',\n",
       " 'updates',\n",
       " 'are',\n",
       " 'kirin',\n",
       " 'pet',\n",
       " 'and',\n",
       " 'metamorph',\n",
       " 'for',\n",
       " 'third',\n",
       " 'job',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'dragon',\n",
       " 'pet',\n",
       " 'is',\n",
       " 'cleaning',\n",
       " 'the',\n",
       " 'house',\n",
       " 'for',\n",
       " 'her',\n",
       " 'family',\n",
       " 'who',\n",
       " 'is',\n",
       " 'comming',\n",
       " 'later',\n",
       " 'today',\n",
       " 'gotta',\n",
       " 'restart',\n",
       " 'my',\n",
       " 'computer',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'was',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'put',\n",
       " 'an',\n",
       " 'end',\n",
       " 'to',\n",
       " 'the',\n",
       " 'constant',\n",
       " 'rebootiness',\n",
       " 'see',\n",
       " 'wat',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'bout',\n",
       " 'friidays',\n",
       " 'its',\n",
       " 'called',\n",
       " 'lose',\n",
       " 'friday',\n",
       " 'smh',\n",
       " 'the',\n",
       " 'free',\n",
       " 'fillin',\n",
       " 'app',\n",
       " 'on',\n",
       " 'my',\n",
       " 'ipod',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'im',\n",
       " 'addicted',\n",
       " 'im',\n",
       " 'sorry',\n",
       " 'on',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'malaysiano',\n",
       " 'internet',\n",
       " 'access',\n",
       " 'to',\n",
       " 'twit',\n",
       " 'juss',\n",
       " 'came',\n",
       " 'backk',\n",
       " 'from',\n",
       " 'berkeleyy',\n",
       " 'omg',\n",
       " 'its',\n",
       " 'madd',\n",
       " 'fun',\n",
       " 'out',\n",
       " 'there',\n",
       " 'havent',\n",
       " 'been',\n",
       " 'out',\n",
       " 'there',\n",
       " 'in',\n",
       " 'a',\n",
       " 'minute',\n",
       " 'whassqoodd',\n",
       " 'went',\n",
       " 'to',\n",
       " 'sleep',\n",
       " 'and',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'power',\n",
       " 'cut',\n",
       " 'in',\n",
       " 'noida',\n",
       " 'power',\n",
       " 'back',\n",
       " 'up',\n",
       " 'not',\n",
       " 'working',\n",
       " 'too',\n",
       " 'im',\n",
       " 'going',\n",
       " 'home',\n",
       " 'now',\n",
       " 'have',\n",
       " 'you',\n",
       " 'seen',\n",
       " 'my',\n",
       " 'new',\n",
       " 'twitter',\n",
       " 'design',\n",
       " 'quiteheavenly',\n",
       " 'isn',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'unni',\n",
       " 'will',\n",
       " 'make',\n",
       " 'the',\n",
       " 'audition',\n",
       " 'fighting',\n",
       " 'dahye',\n",
       " 'unni',\n",
       " 'if',\n",
       " 'it',\n",
       " 'is',\n",
       " 'any',\n",
       " 'consolation',\n",
       " 'i',\n",
       " 'got',\n",
       " 'my',\n",
       " 'bmi',\n",
       " 'tested',\n",
       " 'hahaha',\n",
       " 'it',\n",
       " 'says',\n",
       " 'i',\n",
       " 'am',\n",
       " 'obesed',\n",
       " 'well',\n",
       " 'so',\n",
       " 'much',\n",
       " 'for',\n",
       " 'being',\n",
       " 'unhappy',\n",
       " 'for',\n",
       " 'about',\n",
       " 'minutes',\n",
       " 'thats',\n",
       " 'very',\n",
       " 'funny',\n",
       " 'cute',\n",
       " 'kids',\n",
       " 'ahhh',\n",
       " 'i',\n",
       " 'slept',\n",
       " 'through',\n",
       " 'the',\n",
       " 'game',\n",
       " 'im',\n",
       " 'gonna',\n",
       " 'try',\n",
       " 'my',\n",
       " 'best',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'tomorrow',\n",
       " 'though',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'we',\n",
       " 'play',\n",
       " 'army',\n",
       " 'thats',\n",
       " 'it',\n",
       " 'its',\n",
       " 'the',\n",
       " 'end',\n",
       " 'tears',\n",
       " 'for',\n",
       " 'fears',\n",
       " 'vs',\n",
       " 'eric',\n",
       " 'prydz',\n",
       " 'dj',\n",
       " 'hero',\n",
       " 'born',\n",
       " 'and',\n",
       " 'raised',\n",
       " 'in',\n",
       " 'nyc',\n",
       " 'and',\n",
       " 'living',\n",
       " 'in',\n",
       " 'texas',\n",
       " 'for',\n",
       " 'the',\n",
       " 'past',\n",
       " 'years',\n",
       " 'i',\n",
       " 'still',\n",
       " 'miss',\n",
       " 'ny',\n",
       " 'just',\n",
       " 'in',\n",
       " 'case',\n",
       " 'you',\n",
       " 'wonder',\n",
       " 'we',\n",
       " 'are',\n",
       " 'really',\n",
       " 'busy',\n",
       " 'today',\n",
       " 'and',\n",
       " 'this',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'with',\n",
       " 'adding',\n",
       " 'tons',\n",
       " 'of',\n",
       " 'new',\n",
       " 'blogs',\n",
       " 'and',\n",
       " 'updates',\n",
       " 'stay',\n",
       " 'tuned',\n",
       " 'im',\n",
       " 'soooooo',\n",
       " 'sleeeeepy',\n",
       " 'the',\n",
       " 'last',\n",
       " 'day',\n",
       " 'o',\n",
       " 'school',\n",
       " 'was',\n",
       " 'todaysniffle',\n",
       " 'a',\n",
       " 'little',\n",
       " 'happy',\n",
       " 'for',\n",
       " 'the',\n",
       " 'wine',\n",
       " 'jeje',\n",
       " 'ok',\n",
       " 'itsm',\n",
       " 'my',\n",
       " 'free',\n",
       " 'time',\n",
       " 'so',\n",
       " 'who',\n",
       " 'cares',\n",
       " 'jaja',\n",
       " 'i',\n",
       " 'love',\n",
       " 'this',\n",
       " 'day',\n",
       " 'car',\n",
       " 'not',\n",
       " 'happy',\n",
       " 'big',\n",
       " 'big',\n",
       " 'dent',\n",
       " 'in',\n",
       " 'boot',\n",
       " 'hoping',\n",
       " 'theyre',\n",
       " 'not',\n",
       " 'going',\n",
       " 'to',\n",
       " 'write',\n",
       " 'it',\n",
       " 'off',\n",
       " 'crossing',\n",
       " 'fingers',\n",
       " 'and',\n",
       " 'waiting',\n",
       " 'im',\n",
       " 'an',\n",
       " 'avid',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'magazine',\n",
       " 'and',\n",
       " 'i',\n",
       " 'love',\n",
       " 'your',\n",
       " 'magazines',\n",
       " 'mayday',\n",
       " 'ratt',\n",
       " 'rocked',\n",
       " 'nashville',\n",
       " 'toniteone',\n",
       " 'thing',\n",
       " 'sucked',\n",
       " 'no',\n",
       " 'encore',\n",
       " 'like',\n",
       " 'in',\n",
       " 'the',\n",
       " 'they',\n",
       " 'still',\n",
       " 'have',\n",
       " 'a',\n",
       " 'fun',\n",
       " 'show',\n",
       " 'pearcy',\n",
       " 'has',\n",
       " 'that',\n",
       " 'hott',\n",
       " 'bad',\n",
       " 'boy',\n",
       " 'look',\n",
       " 'i',\n",
       " 'love',\n",
       " 'to',\n",
       " 'but',\n",
       " 'im',\n",
       " 'only',\n",
       " 'available',\n",
       " 'from',\n",
       " 'and',\n",
       " 'where',\n",
       " 'dear',\n",
       " 'would',\n",
       " 'love',\n",
       " 'to',\n",
       " 'help',\n",
       " 'convert',\n",
       " 'her',\n",
       " 'vids',\n",
       " 'the',\n",
       " 'girl',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hair',\n",
       " 'salon',\n",
       " 'asked',\n",
       " 'me',\n",
       " 'shall',\n",
       " 'i',\n",
       " 'trim',\n",
       " 'your',\n",
       " 'eyebrows',\n",
       " 'how',\n",
       " 'old',\n",
       " 'do',\n",
       " 'i',\n",
       " 'feel',\n",
       " 'egh',\n",
       " 'blah',\n",
       " 'and',\n",
       " 'boooooooooooo',\n",
       " 'i',\n",
       " 'dunno',\n",
       " 'wanna',\n",
       " 'go',\n",
       " 'to',\n",
       " 'work',\n",
       " 'hangovers',\n",
       " 'suckkkkkk',\n",
       " 'im',\n",
       " 'a',\n",
       " 'drunk',\n",
       " 'mess',\n",
       " 'visiting',\n",
       " 'my',\n",
       " 'friendster',\n",
       " 'and',\n",
       " 'facebook',\n",
       " 'i',\n",
       " 'donbt',\n",
       " 'like',\n",
       " 'to',\n",
       " 'peel',\n",
       " 'prawns',\n",
       " 'i',\n",
       " 'also',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'going',\n",
       " 'shopping',\n",
       " 'running',\n",
       " 'out',\n",
       " 'of',\n",
       " 'money',\n",
       " 'and',\n",
       " 'crawling',\n",
       " 'round',\n",
       " 'the',\n",
       " 'car',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'more',\n",
       " 'which',\n",
       " 'case',\n",
       " 'i',\n",
       " 'got',\n",
       " 'a',\n",
       " 'new',\n",
       " 'one',\n",
       " 'last',\n",
       " 'week',\n",
       " 'and',\n",
       " 'im',\n",
       " 'not',\n",
       " 'thrilled',\n",
       " 'at',\n",
       " 'all',\n",
       " 'with',\n",
       " 'mine',\n",
       " 'then',\n",
       " 'you',\n",
       " 'should',\n",
       " 'check',\n",
       " 'out',\n",
       " 'and',\n",
       " 'connect',\n",
       " 'with',\n",
       " 'other',\n",
       " 'tweeple',\n",
       " 'who',\n",
       " 'hate',\n",
       " 'twitter',\n",
       " 'also',\n",
       " 'bored',\n",
       " 'at',\n",
       " 'school',\n",
       " 'its',\n",
       " 'my',\n",
       " 'third',\n",
       " 'freelesson',\n",
       " 'freistunde',\n",
       " 'hm',\n",
       " 'both',\n",
       " 'of',\n",
       " 'us',\n",
       " 'i',\n",
       " 'guess',\n",
       " 'it',\n",
       " 'is',\n",
       " 'u',\n",
       " 'have',\n",
       " 'dissappointed',\n",
       " 'me',\n",
       " 'that',\n",
       " 'past',\n",
       " 'few',\n",
       " 'days',\n",
       " 'romance',\n",
       " 'zero',\n",
       " 'is',\n",
       " 'funny',\n",
       " 'id',\n",
       " 'rather',\n",
       " 'do',\n",
       " 'the',\n",
       " 'early',\n",
       " 'runbut',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'morning',\n",
       " 'runner',\n",
       " 'bah',\n",
       " 'a',\n",
       " 'coworker',\n",
       " 'ran',\n",
       " 'into',\n",
       " 'work',\n",
       " 'late',\n",
       " 'and',\n",
       " 'her',\n",
       " 'bag',\n",
       " 'smacked',\n",
       " 'into',\n",
       " 'my',\n",
       " 'knee',\n",
       " 'it',\n",
       " 'really',\n",
       " 'hurts',\n",
       " 'now',\n",
       " 'will',\n",
       " 'be',\n",
       " 'back',\n",
       " 'later',\n",
       " 'aw',\n",
       " 'torn',\n",
       " 'ace',\n",
       " 'of',\n",
       " 'hearts',\n",
       " 'hunchback',\n",
       " 'what',\n",
       " 'fun',\n",
       " 'are',\n",
       " 'you',\n",
       " 'speaking',\n",
       " 'of',\n",
       " 'i',\n",
       " 'lost',\n",
       " 'all',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'im',\n",
       " 'alone',\n",
       " 'and',\n",
       " 'sleepyi',\n",
       " 'wanna',\n",
       " 'go',\n",
       " 'home',\n",
       " 'haha',\n",
       " 'yes',\n",
       " 'i',\n",
       " 'give',\n",
       " 'in',\n",
       " 'to',\n",
       " 'easily',\n",
       " 'what',\n",
       " 'better',\n",
       " 'way',\n",
       " 'to',\n",
       " 'spoil',\n",
       " 'mum',\n",
       " 'than',\n",
       " 'to',\n",
       " 'let',\n",
       " 'her',\n",
       " 'kick',\n",
       " 'back',\n",
       " 'and',\n",
       " 'relax',\n",
       " 'over',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'meal',\n",
       " 'and',\n",
       " 'a',\n",
       " 'bottle',\n",
       " 'of',\n",
       " 'her',\n",
       " 'favorite',\n",
       " 'wine',\n",
       " 'our',\n",
       " 'wine',\n",
       " 'was',\n",
       " 'a',\n",
       " 'red',\n",
       " 'mannnn',\n",
       " 'got',\n",
       " 'an',\n",
       " 'iphone',\n",
       " 'im',\n",
       " 'jealous',\n",
       " 'is',\n",
       " 'at',\n",
       " 'a',\n",
       " 'photoshoot',\n",
       " 'hes',\n",
       " 'awesome',\n",
       " 'have',\n",
       " 'you',\n",
       " 'worked',\n",
       " 'with',\n",
       " 'him',\n",
       " 'before',\n",
       " 'hes',\n",
       " 'a',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'yay',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'show',\n",
       " 'tonight',\n",
       " 'boo',\n",
       " 'its',\n",
       " 'gonna',\n",
       " 'soggy',\n",
       " 'and',\n",
       " 'im',\n",
       " 'at',\n",
       " 'work',\n",
       " 'right',\n",
       " 'before',\n",
       " 'playing',\n",
       " 'chilliin',\n",
       " 'if',\n",
       " 'you',\n",
       " 'know',\n",
       " 'such',\n",
       " 'agent',\n",
       " 'do',\n",
       " 'let',\n",
       " 'me',\n",
       " 'know',\n",
       " 'i',\n",
       " 'still',\n",
       " 'smell',\n",
       " 'of',\n",
       " 'smoke',\n",
       " 'kitchenfire',\n",
       " 'a',\n",
       " 'celticslakers',\n",
       " 'rematch',\n",
       " 'sounds',\n",
       " 'better',\n",
       " 'dont',\n",
       " 'you',\n",
       " 'think',\n",
       " 'lol',\n",
       " 'anyone',\n",
       " 'have',\n",
       " 'an',\n",
       " 'extra',\n",
       " 'keane',\n",
       " 'ticket',\n",
       " 'i',\n",
       " 'promise',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'you',\n",
       " 'a',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'take',\n",
       " 'rad',\n",
       " 'pics',\n",
       " 'for',\n",
       " 'your',\n",
       " 'fb',\n",
       " 'blog',\n",
       " 'flickr',\n",
       " 'etc',\n",
       " 'you',\n",
       " 'can',\n",
       " 'ride',\n",
       " 'one',\n",
       " 'you',\n",
       " 'can',\n",
       " 'catch',\n",
       " 'one',\n",
       " 'but',\n",
       " 'its',\n",
       " 'not',\n",
       " 'summer',\n",
       " 'til',\n",
       " 'you',\n",
       " 'pop',\n",
       " 'open',\n",
       " 'one',\n",
       " 'she',\n",
       " 'is',\n",
       " 'good',\n",
       " 'so',\n",
       " 'gorjuz',\n",
       " 'yea',\n",
       " 'i',\n",
       " 'kno',\n",
       " 'i',\n",
       " 'asked',\n",
       " 'her',\n",
       " 'yesterday',\n",
       " 'when',\n",
       " 'we',\n",
       " 'were',\n",
       " 'at',\n",
       " 'tha',\n",
       " 'hospital',\n",
       " 'if',\n",
       " 'she',\n",
       " 'talked',\n",
       " 'to',\n",
       " 'u',\n",
       " 'and',\n",
       " 'she',\n",
       " 'said',\n",
       " 'no',\n",
       " 'ok',\n",
       " 'im',\n",
       " 'out',\n",
       " 'of',\n",
       " 'here',\n",
       " 'for',\n",
       " 'now',\n",
       " 'just',\n",
       " 'popped',\n",
       " 'in',\n",
       " 'to',\n",
       " 'say',\n",
       " 'hi',\n",
       " 'and',\n",
       " 'check',\n",
       " 'on',\n",
       " 'things',\n",
       " 'ill',\n",
       " 'probably',\n",
       " 'head',\n",
       " 'to',\n",
       " 'the',\n",
       " 'guttah',\n",
       " 'later',\n",
       " 'on',\n",
       " 'tonight',\n",
       " 'wow',\n",
       " 'i',\n",
       " 'am',\n",
       " 'really',\n",
       " 'missin',\n",
       " 'the',\n",
       " 'family',\n",
       " 'today',\n",
       " 'baddd',\n",
       " 'my',\n",
       " 'sources',\n",
       " 'say',\n",
       " 'no',\n",
       " 'i',\n",
       " 'am',\n",
       " 'sooo',\n",
       " 'tired',\n",
       " 'hey',\n",
       " 'you',\n",
       " 'change',\n",
       " 'your',\n",
       " 'twitter',\n",
       " 'account',\n",
       " 'and',\n",
       " 'you',\n",
       " 'didnt',\n",
       " 'even',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'thank',\n",
       " 'yyyyyyyyyoooooooooouuuuu',\n",
       " 'lucky',\n",
       " 'kidi',\n",
       " 'so',\n",
       " 'wanna',\n",
       " 'see',\n",
       " 'loserville',\n",
       " 'pity',\n",
       " 'im',\n",
       " 'in',\n",
       " 'oz',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " 'waiting',\n",
       " 'for',\n",
       " 'my',\n",
       " 'ride',\n",
       " 'sick',\n",
       " 'with',\n",
       " 'a',\n",
       " 'flu',\n",
       " 'like',\n",
       " 'thing',\n",
       " 'still',\n",
       " 'no',\n",
       " 'reply',\n",
       " 'from',\n",
       " 'about',\n",
       " 'my',\n",
       " 'simfinger',\n",
       " 'problem',\n",
       " 'so',\n",
       " 'no',\n",
       " 'irape',\n",
       " 'parody',\n",
       " 'video',\n",
       " 'until',\n",
       " 'i',\n",
       " 'get',\n",
       " 'a',\n",
       " 'response',\n",
       " 'sorry',\n",
       " 'guys',\n",
       " 'happy',\n",
       " 'star',\n",
       " 'wars',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for sublist in data['temp_list1'] for item in sublist] # I kinda understand it now !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'have', 'responded', 'if', 'i', 'were', 'going'],\n",
       " ['sooo', 'sad', 'i', 'will', 'miss', 'you', 'here', 'in', 'san', 'diego'],\n",
       " ['my', 'boss', 'is', 'bullying', 'me'],\n",
       " ['what', 'interview', 'leave', 'me', 'alone'],\n",
       " ['sons',\n",
       "  'of',\n",
       "  'why',\n",
       "  'couldnt',\n",
       "  'they',\n",
       "  'put',\n",
       "  'them',\n",
       "  'on',\n",
       "  'the',\n",
       "  'releases',\n",
       "  'we',\n",
       "  'already',\n",
       "  'bought'],\n",
       " ['some',\n",
       "  'shameless',\n",
       "  'plugging',\n",
       "  'for',\n",
       "  'the',\n",
       "  'best',\n",
       "  'rangers',\n",
       "  'forum',\n",
       "  'on',\n",
       "  'earth'],\n",
       " ['feedings',\n",
       "  'for',\n",
       "  'the',\n",
       "  'baby',\n",
       "  'are',\n",
       "  'fun',\n",
       "  'when',\n",
       "  'he',\n",
       "  'is',\n",
       "  'all',\n",
       "  'smiles',\n",
       "  'and',\n",
       "  'coos'],\n",
       " ['soooo', 'high'],\n",
       " ['both', 'of', 'you'],\n",
       " ['journey',\n",
       "  'wow',\n",
       "  'u',\n",
       "  'just',\n",
       "  'became',\n",
       "  'cooler',\n",
       "  'hehe',\n",
       "  'is',\n",
       "  'that',\n",
       "  'possible'],\n",
       " ['as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'i',\n",
       "  'love',\n",
       "  'to',\n",
       "  'be',\n",
       "  'hopeful',\n",
       "  'i',\n",
       "  'reckon',\n",
       "  'the',\n",
       "  'chances',\n",
       "  'are',\n",
       "  'minimal',\n",
       "  'p',\n",
       "  'im',\n",
       "  'never',\n",
       "  'gonna',\n",
       "  'get',\n",
       "  'my',\n",
       "  'cake',\n",
       "  'and',\n",
       "  'stuff'],\n",
       " ['i',\n",
       "  'really',\n",
       "  'really',\n",
       "  'like',\n",
       "  'the',\n",
       "  'song',\n",
       "  'love',\n",
       "  'story',\n",
       "  'by',\n",
       "  'taylor',\n",
       "  'swift'],\n",
       " ['my', 'sharpie', 'is', 'running', 'dangerously', 'low', 'on', 'ink'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'music',\n",
       "  'tonight',\n",
       "  'but',\n",
       "  'i',\n",
       "  'lost',\n",
       "  'my',\n",
       "  'voice'],\n",
       " ['test', 'test', 'from', 'the', 'lg'],\n",
       " ['uh', 'oh', 'i', 'am', 'sunburned'],\n",
       " ['sok', 'trying', 'to', 'plot', 'alternatives', 'as', 'we', 'speak', 'sigh'],\n",
       " ['ive',\n",
       "  'been',\n",
       "  'sick',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'few',\n",
       "  'days',\n",
       "  'and',\n",
       "  'thus',\n",
       "  'my',\n",
       "  'hair',\n",
       "  'looks',\n",
       "  'wierd',\n",
       "  'if',\n",
       "  'i',\n",
       "  'didnt',\n",
       "  'have',\n",
       "  'a',\n",
       "  'hat',\n",
       "  'on',\n",
       "  'it',\n",
       "  'would',\n",
       "  'look'],\n",
       " ['is', 'back', 'home', 'now', 'gonna', 'miss', 'every', 'one'],\n",
       " ['hes', 'just', 'not', 'that', 'into', 'you'],\n",
       " ['oh',\n",
       "  'marly',\n",
       "  'im',\n",
       "  'so',\n",
       "  'sorry',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'you',\n",
       "  'find',\n",
       "  'her',\n",
       "  'soon'],\n",
       " ['playing',\n",
       "  'ghost',\n",
       "  'online',\n",
       "  'is',\n",
       "  'really',\n",
       "  'interesting',\n",
       "  'the',\n",
       "  'new',\n",
       "  'updates',\n",
       "  'are',\n",
       "  'kirin',\n",
       "  'pet',\n",
       "  'and',\n",
       "  'metamorph',\n",
       "  'for',\n",
       "  'third',\n",
       "  'job',\n",
       "  'cant',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'dragon',\n",
       "  'pet'],\n",
       " ['is',\n",
       "  'cleaning',\n",
       "  'the',\n",
       "  'house',\n",
       "  'for',\n",
       "  'her',\n",
       "  'family',\n",
       "  'who',\n",
       "  'is',\n",
       "  'comming',\n",
       "  'later',\n",
       "  'today'],\n",
       " ['gotta',\n",
       "  'restart',\n",
       "  'my',\n",
       "  'computer',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'was',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'put',\n",
       "  'an',\n",
       "  'end',\n",
       "  'to',\n",
       "  'the',\n",
       "  'constant',\n",
       "  'rebootiness'],\n",
       " ['see',\n",
       "  'wat',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'bout',\n",
       "  'friidays',\n",
       "  'its',\n",
       "  'called',\n",
       "  'lose',\n",
       "  'friday',\n",
       "  'smh'],\n",
       " ['the',\n",
       "  'free',\n",
       "  'fillin',\n",
       "  'app',\n",
       "  'on',\n",
       "  'my',\n",
       "  'ipod',\n",
       "  'is',\n",
       "  'fun',\n",
       "  'im',\n",
       "  'addicted'],\n",
       " ['im', 'sorry'],\n",
       " ['on', 'the', 'way', 'to', 'malaysiano', 'internet', 'access', 'to', 'twit'],\n",
       " ['juss',\n",
       "  'came',\n",
       "  'backk',\n",
       "  'from',\n",
       "  'berkeleyy',\n",
       "  'omg',\n",
       "  'its',\n",
       "  'madd',\n",
       "  'fun',\n",
       "  'out',\n",
       "  'there',\n",
       "  'havent',\n",
       "  'been',\n",
       "  'out',\n",
       "  'there',\n",
       "  'in',\n",
       "  'a',\n",
       "  'minute',\n",
       "  'whassqoodd'],\n",
       " ['went',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'and',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'power',\n",
       "  'cut',\n",
       "  'in',\n",
       "  'noida',\n",
       "  'power',\n",
       "  'back',\n",
       "  'up',\n",
       "  'not',\n",
       "  'working',\n",
       "  'too'],\n",
       " ['im',\n",
       "  'going',\n",
       "  'home',\n",
       "  'now',\n",
       "  'have',\n",
       "  'you',\n",
       "  'seen',\n",
       "  'my',\n",
       "  'new',\n",
       "  'twitter',\n",
       "  'design',\n",
       "  'quiteheavenly',\n",
       "  'isn'],\n",
       " ['i',\n",
       "  'hope',\n",
       "  'unni',\n",
       "  'will',\n",
       "  'make',\n",
       "  'the',\n",
       "  'audition',\n",
       "  'fighting',\n",
       "  'dahye',\n",
       "  'unni'],\n",
       " ['if',\n",
       "  'it',\n",
       "  'is',\n",
       "  'any',\n",
       "  'consolation',\n",
       "  'i',\n",
       "  'got',\n",
       "  'my',\n",
       "  'bmi',\n",
       "  'tested',\n",
       "  'hahaha',\n",
       "  'it',\n",
       "  'says',\n",
       "  'i',\n",
       "  'am',\n",
       "  'obesed',\n",
       "  'well',\n",
       "  'so',\n",
       "  'much',\n",
       "  'for',\n",
       "  'being',\n",
       "  'unhappy',\n",
       "  'for',\n",
       "  'about',\n",
       "  'minutes'],\n",
       " ['thats', 'very', 'funny', 'cute', 'kids'],\n",
       " ['ahhh',\n",
       "  'i',\n",
       "  'slept',\n",
       "  'through',\n",
       "  'the',\n",
       "  'game',\n",
       "  'im',\n",
       "  'gonna',\n",
       "  'try',\n",
       "  'my',\n",
       "  'best',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'tomorrow',\n",
       "  'though',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'we',\n",
       "  'play',\n",
       "  'army'],\n",
       " ['thats',\n",
       "  'it',\n",
       "  'its',\n",
       "  'the',\n",
       "  'end',\n",
       "  'tears',\n",
       "  'for',\n",
       "  'fears',\n",
       "  'vs',\n",
       "  'eric',\n",
       "  'prydz',\n",
       "  'dj',\n",
       "  'hero'],\n",
       " ['born',\n",
       "  'and',\n",
       "  'raised',\n",
       "  'in',\n",
       "  'nyc',\n",
       "  'and',\n",
       "  'living',\n",
       "  'in',\n",
       "  'texas',\n",
       "  'for',\n",
       "  'the',\n",
       "  'past',\n",
       "  'years',\n",
       "  'i',\n",
       "  'still',\n",
       "  'miss',\n",
       "  'ny'],\n",
       " ['just',\n",
       "  'in',\n",
       "  'case',\n",
       "  'you',\n",
       "  'wonder',\n",
       "  'we',\n",
       "  'are',\n",
       "  'really',\n",
       "  'busy',\n",
       "  'today',\n",
       "  'and',\n",
       "  'this',\n",
       "  'coming',\n",
       "  'with',\n",
       "  'with',\n",
       "  'adding',\n",
       "  'tons',\n",
       "  'of',\n",
       "  'new',\n",
       "  'blogs',\n",
       "  'and',\n",
       "  'updates',\n",
       "  'stay',\n",
       "  'tuned'],\n",
       " ['im',\n",
       "  'soooooo',\n",
       "  'sleeeeepy',\n",
       "  'the',\n",
       "  'last',\n",
       "  'day',\n",
       "  'o',\n",
       "  'school',\n",
       "  'was',\n",
       "  'todaysniffle'],\n",
       " ['a',\n",
       "  'little',\n",
       "  'happy',\n",
       "  'for',\n",
       "  'the',\n",
       "  'wine',\n",
       "  'jeje',\n",
       "  'ok',\n",
       "  'itsm',\n",
       "  'my',\n",
       "  'free',\n",
       "  'time',\n",
       "  'so',\n",
       "  'who',\n",
       "  'cares',\n",
       "  'jaja',\n",
       "  'i',\n",
       "  'love',\n",
       "  'this',\n",
       "  'day'],\n",
       " ['car',\n",
       "  'not',\n",
       "  'happy',\n",
       "  'big',\n",
       "  'big',\n",
       "  'dent',\n",
       "  'in',\n",
       "  'boot',\n",
       "  'hoping',\n",
       "  'theyre',\n",
       "  'not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'write',\n",
       "  'it',\n",
       "  'off',\n",
       "  'crossing',\n",
       "  'fingers',\n",
       "  'and',\n",
       "  'waiting'],\n",
       " ['im',\n",
       "  'an',\n",
       "  'avid',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'magazine',\n",
       "  'and',\n",
       "  'i',\n",
       "  'love',\n",
       "  'your',\n",
       "  'magazines'],\n",
       " ['mayday'],\n",
       " ['ratt',\n",
       "  'rocked',\n",
       "  'nashville',\n",
       "  'toniteone',\n",
       "  'thing',\n",
       "  'sucked',\n",
       "  'no',\n",
       "  'encore',\n",
       "  'like',\n",
       "  'in',\n",
       "  'the',\n",
       "  'they',\n",
       "  'still',\n",
       "  'have',\n",
       "  'a',\n",
       "  'fun',\n",
       "  'show',\n",
       "  'pearcy',\n",
       "  'has',\n",
       "  'that',\n",
       "  'hott',\n",
       "  'bad',\n",
       "  'boy',\n",
       "  'look'],\n",
       " ['i',\n",
       "  'love',\n",
       "  'to',\n",
       "  'but',\n",
       "  'im',\n",
       "  'only',\n",
       "  'available',\n",
       "  'from',\n",
       "  'and',\n",
       "  'where',\n",
       "  'dear',\n",
       "  'would',\n",
       "  'love',\n",
       "  'to',\n",
       "  'help',\n",
       "  'convert',\n",
       "  'her',\n",
       "  'vids'],\n",
       " ['the',\n",
       "  'girl',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hair',\n",
       "  'salon',\n",
       "  'asked',\n",
       "  'me',\n",
       "  'shall',\n",
       "  'i',\n",
       "  'trim',\n",
       "  'your',\n",
       "  'eyebrows',\n",
       "  'how',\n",
       "  'old',\n",
       "  'do',\n",
       "  'i',\n",
       "  'feel'],\n",
       " ['egh',\n",
       "  'blah',\n",
       "  'and',\n",
       "  'boooooooooooo',\n",
       "  'i',\n",
       "  'dunno',\n",
       "  'wanna',\n",
       "  'go',\n",
       "  'to',\n",
       "  'work',\n",
       "  'hangovers',\n",
       "  'suckkkkkk',\n",
       "  'im',\n",
       "  'a',\n",
       "  'drunk',\n",
       "  'mess'],\n",
       " ['visiting', 'my', 'friendster', 'and', 'facebook'],\n",
       " ['i',\n",
       "  'donbt',\n",
       "  'like',\n",
       "  'to',\n",
       "  'peel',\n",
       "  'prawns',\n",
       "  'i',\n",
       "  'also',\n",
       "  'dont',\n",
       "  'like',\n",
       "  'going',\n",
       "  'shopping',\n",
       "  'running',\n",
       "  'out',\n",
       "  'of',\n",
       "  'money',\n",
       "  'and',\n",
       "  'crawling',\n",
       "  'round',\n",
       "  'the',\n",
       "  'car',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'more'],\n",
       " ['which',\n",
       "  'case',\n",
       "  'i',\n",
       "  'got',\n",
       "  'a',\n",
       "  'new',\n",
       "  'one',\n",
       "  'last',\n",
       "  'week',\n",
       "  'and',\n",
       "  'im',\n",
       "  'not',\n",
       "  'thrilled',\n",
       "  'at',\n",
       "  'all',\n",
       "  'with',\n",
       "  'mine'],\n",
       " ['then',\n",
       "  'you',\n",
       "  'should',\n",
       "  'check',\n",
       "  'out',\n",
       "  'and',\n",
       "  'connect',\n",
       "  'with',\n",
       "  'other',\n",
       "  'tweeple',\n",
       "  'who',\n",
       "  'hate',\n",
       "  'twitter'],\n",
       " ['also',\n",
       "  'bored',\n",
       "  'at',\n",
       "  'school',\n",
       "  'its',\n",
       "  'my',\n",
       "  'third',\n",
       "  'freelesson',\n",
       "  'freistunde'],\n",
       " ['hm', 'both', 'of', 'us', 'i', 'guess'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'u',\n",
       "  'have',\n",
       "  'dissappointed',\n",
       "  'me',\n",
       "  'that',\n",
       "  'past',\n",
       "  'few',\n",
       "  'days'],\n",
       " ['romance', 'zero', 'is', 'funny'],\n",
       " ['id',\n",
       "  'rather',\n",
       "  'do',\n",
       "  'the',\n",
       "  'early',\n",
       "  'runbut',\n",
       "  'i',\n",
       "  'am',\n",
       "  'a',\n",
       "  'morning',\n",
       "  'runner'],\n",
       " ['bah',\n",
       "  'a',\n",
       "  'coworker',\n",
       "  'ran',\n",
       "  'into',\n",
       "  'work',\n",
       "  'late',\n",
       "  'and',\n",
       "  'her',\n",
       "  'bag',\n",
       "  'smacked',\n",
       "  'into',\n",
       "  'my',\n",
       "  'knee',\n",
       "  'it',\n",
       "  'really',\n",
       "  'hurts',\n",
       "  'now'],\n",
       " ['will', 'be', 'back', 'later'],\n",
       " ['aw', 'torn', 'ace', 'of', 'hearts', 'hunchback'],\n",
       " ['what', 'fun', 'are', 'you', 'speaking', 'of'],\n",
       " ['i',\n",
       "  'lost',\n",
       "  'all',\n",
       "  'my',\n",
       "  'friends',\n",
       "  'im',\n",
       "  'alone',\n",
       "  'and',\n",
       "  'sleepyi',\n",
       "  'wanna',\n",
       "  'go',\n",
       "  'home'],\n",
       " ['haha', 'yes'],\n",
       " ['i', 'give', 'in', 'to', 'easily'],\n",
       " ['what',\n",
       "  'better',\n",
       "  'way',\n",
       "  'to',\n",
       "  'spoil',\n",
       "  'mum',\n",
       "  'than',\n",
       "  'to',\n",
       "  'let',\n",
       "  'her',\n",
       "  'kick',\n",
       "  'back',\n",
       "  'and',\n",
       "  'relax',\n",
       "  'over',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'meal',\n",
       "  'and',\n",
       "  'a',\n",
       "  'bottle',\n",
       "  'of',\n",
       "  'her',\n",
       "  'favorite',\n",
       "  'wine',\n",
       "  'our',\n",
       "  'wine',\n",
       "  'was',\n",
       "  'a',\n",
       "  'red'],\n",
       " ['mannnn', 'got', 'an', 'iphone', 'im', 'jealous'],\n",
       " ['is', 'at', 'a', 'photoshoot'],\n",
       " ['hes',\n",
       "  'awesome',\n",
       "  'have',\n",
       "  'you',\n",
       "  'worked',\n",
       "  'with',\n",
       "  'him',\n",
       "  'before',\n",
       "  'hes',\n",
       "  'a',\n",
       "  'good',\n",
       "  'friend'],\n",
       " ['yay',\n",
       "  'playing',\n",
       "  'a',\n",
       "  'show',\n",
       "  'tonight',\n",
       "  'boo',\n",
       "  'its',\n",
       "  'gonna',\n",
       "  'soggy',\n",
       "  'and',\n",
       "  'im',\n",
       "  'at',\n",
       "  'work',\n",
       "  'right',\n",
       "  'before',\n",
       "  'playing'],\n",
       " ['chilliin'],\n",
       " ['if', 'you', 'know', 'such', 'agent', 'do', 'let', 'me', 'know'],\n",
       " ['i', 'still', 'smell', 'of', 'smoke', 'kitchenfire'],\n",
       " ['a',\n",
       "  'celticslakers',\n",
       "  'rematch',\n",
       "  'sounds',\n",
       "  'better',\n",
       "  'dont',\n",
       "  'you',\n",
       "  'think',\n",
       "  'lol'],\n",
       " ['anyone',\n",
       "  'have',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'keane',\n",
       "  'ticket',\n",
       "  'i',\n",
       "  'promise',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'you',\n",
       "  'a',\n",
       "  'drink',\n",
       "  'and',\n",
       "  'take',\n",
       "  'rad',\n",
       "  'pics',\n",
       "  'for',\n",
       "  'your',\n",
       "  'fb',\n",
       "  'blog',\n",
       "  'flickr',\n",
       "  'etc'],\n",
       " ['you',\n",
       "  'can',\n",
       "  'ride',\n",
       "  'one',\n",
       "  'you',\n",
       "  'can',\n",
       "  'catch',\n",
       "  'one',\n",
       "  'but',\n",
       "  'its',\n",
       "  'not',\n",
       "  'summer',\n",
       "  'til',\n",
       "  'you',\n",
       "  'pop',\n",
       "  'open',\n",
       "  'one'],\n",
       " ['she',\n",
       "  'is',\n",
       "  'good',\n",
       "  'so',\n",
       "  'gorjuz',\n",
       "  'yea',\n",
       "  'i',\n",
       "  'kno',\n",
       "  'i',\n",
       "  'asked',\n",
       "  'her',\n",
       "  'yesterday',\n",
       "  'when',\n",
       "  'we',\n",
       "  'were',\n",
       "  'at',\n",
       "  'tha',\n",
       "  'hospital',\n",
       "  'if',\n",
       "  'she',\n",
       "  'talked',\n",
       "  'to',\n",
       "  'u',\n",
       "  'and',\n",
       "  'she',\n",
       "  'said',\n",
       "  'no'],\n",
       " ['ok',\n",
       "  'im',\n",
       "  'out',\n",
       "  'of',\n",
       "  'here',\n",
       "  'for',\n",
       "  'now',\n",
       "  'just',\n",
       "  'popped',\n",
       "  'in',\n",
       "  'to',\n",
       "  'say',\n",
       "  'hi',\n",
       "  'and',\n",
       "  'check',\n",
       "  'on',\n",
       "  'things',\n",
       "  'ill',\n",
       "  'probably',\n",
       "  'head',\n",
       "  'to',\n",
       "  'the',\n",
       "  'guttah',\n",
       "  'later',\n",
       "  'on',\n",
       "  'tonight'],\n",
       " ['wow', 'i', 'am', 'really', 'missin', 'the', 'family', 'today', 'baddd'],\n",
       " ['my', 'sources', 'say', 'no'],\n",
       " ['i', 'am', 'sooo', 'tired'],\n",
       " ['hey',\n",
       "  'you',\n",
       "  'change',\n",
       "  'your',\n",
       "  'twitter',\n",
       "  'account',\n",
       "  'and',\n",
       "  'you',\n",
       "  'didnt',\n",
       "  'even',\n",
       "  'tell',\n",
       "  'me'],\n",
       " ['thank', 'yyyyyyyyyoooooooooouuuuu'],\n",
       " ['lucky',\n",
       "  'kidi',\n",
       "  'so',\n",
       "  'wanna',\n",
       "  'see',\n",
       "  'loserville',\n",
       "  'pity',\n",
       "  'im',\n",
       "  'in',\n",
       "  'oz'],\n",
       " ['fell', 'asleep', 'waiting', 'for', 'my', 'ride'],\n",
       " ['sick', 'with', 'a', 'flu', 'like', 'thing'],\n",
       " ['still',\n",
       "  'no',\n",
       "  'reply',\n",
       "  'from',\n",
       "  'about',\n",
       "  'my',\n",
       "  'simfinger',\n",
       "  'problem',\n",
       "  'so',\n",
       "  'no',\n",
       "  'irape',\n",
       "  'parody',\n",
       "  'video',\n",
       "  'until',\n",
       "  'i',\n",
       "  'get',\n",
       "  'a',\n",
       "  'response',\n",
       "  'sorry',\n",
       "  'guys'],\n",
       " ['happy',\n",
       "  'star',\n",
       "  'wars',\n",
       "  'day',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'enjoy',\n",
       "  'the',\n",
       "  'holiday',\n",
       "  'uk'],\n",
       " ['miles',\n",
       "  'from',\n",
       "  'you',\n",
       "  'im',\n",
       "  'in',\n",
       "  'essex',\n",
       "  'so',\n",
       "  'give',\n",
       "  'me',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'warning',\n",
       "  'so',\n",
       "  'i',\n",
       "  'can',\n",
       "  'arrive',\n",
       "  'in',\n",
       "  'time',\n",
       "  'to',\n",
       "  'get',\n",
       "  'at',\n",
       "  'least',\n",
       "  'one',\n",
       "  'of',\n",
       "  'those',\n",
       "  'free',\n",
       "  'beers'],\n",
       " ['his',\n",
       "  'snoring',\n",
       "  'is',\n",
       "  'so',\n",
       "  'annoying',\n",
       "  'n',\n",
       "  'it',\n",
       "  'keeps',\n",
       "  'me',\n",
       "  'from',\n",
       "  'sleeping',\n",
       "  'like',\n",
       "  'right',\n",
       "  'now',\n",
       "  'lol',\n",
       "  'but',\n",
       "  'i',\n",
       "  'honestly',\n",
       "  'wud',\n",
       "  'miss',\n",
       "  'it',\n",
       "  'if',\n",
       "  'it',\n",
       "  'eva',\n",
       "  'left',\n",
       "  'i',\n",
       "  'love',\n",
       "  'him'],\n",
       " ['i',\n",
       "  'miss',\n",
       "  'you',\n",
       "  'bby',\n",
       "  'wish',\n",
       "  'you',\n",
       "  'were',\n",
       "  'going',\n",
       "  'tomorrow',\n",
       "  'to',\n",
       "  'make',\n",
       "  'me',\n",
       "  'do',\n",
       "  'good'],\n",
       " ['well',\n",
       "  'what',\n",
       "  'im',\n",
       "  'working',\n",
       "  'on',\n",
       "  'isnt',\n",
       "  'quite',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'post',\n",
       "  'about',\n",
       "  'publicly',\n",
       "  'still',\n",
       "  'beta',\n",
       "  'testing',\n",
       "  'but',\n",
       "  'its',\n",
       "  'a',\n",
       "  'cool',\n",
       "  'new',\n",
       "  'script',\n",
       "  'i',\n",
       "  'coded'],\n",
       " ['sweeeeet', 'san', 'fran', 'is', 'awesome', 'love', 'it', 'there'],\n",
       " ['mounce', 'yes', 'and', 'it', 'lasts', 'way', 'past', 'my', 'bedtime'],\n",
       " ['hi', 'how', 'are', 'you', 'doing', 'just', 'joined', 'twitter'],\n",
       " ['waiting',\n",
       "  'for',\n",
       "  'sleeping',\n",
       "  'pills',\n",
       "  'to',\n",
       "  'kick',\n",
       "  'in',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'so',\n",
       "  'tired',\n",
       "  'at',\n",
       "  'work',\n",
       "  'tomorrow'],\n",
       " ['eating',\n",
       "  'ice',\n",
       "  'cream',\n",
       "  'and',\n",
       "  'then',\n",
       "  'getting',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'graduation'],\n",
       " ['happy', 'mothers', 'day', 'to', 'all', 'you', 'mums', 'out', 'there'],\n",
       " ['caseys',\n",
       "  'gone',\n",
       "  'but',\n",
       "  'why',\n",
       "  'so',\n",
       "  'she',\n",
       "  'piddled',\n",
       "  'a',\n",
       "  'little',\n",
       "  'on',\n",
       "  'the',\n",
       "  'carpet',\n",
       "  'shes',\n",
       "  'prolly',\n",
       "  'freaked',\n",
       "  'cause',\n",
       "  'its',\n",
       "  'new',\n",
       "  'can',\n",
       "  'we',\n",
       "  'get',\n",
       "  'her',\n",
       "  'back'],\n",
       " ['hemp', 'cloth', 'is', 'marvelous', 'but', 'unfortunately', 'no'],\n",
       " ['gonna',\n",
       "  'read',\n",
       "  'a',\n",
       "  'story',\n",
       "  'bout',\n",
       "  'adam',\n",
       "  'lambert',\n",
       "  'online',\n",
       "  'then',\n",
       "  'bed',\n",
       "  'nighty',\n",
       "  'night'],\n",
       " ['we', 'saw', 'that', 'in', 'none', 'the', 'baddies', 'the', 'best'],\n",
       " ['and', 'im', 'on', 'the', 'beach', 'pretty'],\n",
       " ['certainly', 'not', 'cheers', 'than', 'huh'],\n",
       " ['week',\n",
       "  'post',\n",
       "  'myhorrible',\n",
       "  'traumatic',\n",
       "  'jumping',\n",
       "  'cholla',\n",
       "  'accidentchollas',\n",
       "  'next',\n",
       "  'dirty',\n",
       "  'trickpieces',\n",
       "  'are',\n",
       "  'starting',\n",
       "  'to',\n",
       "  'emerge',\n",
       "  'from',\n",
       "  'my',\n",
       "  'hand',\n",
       "  'ouch'],\n",
       " ['i',\n",
       "  'realy',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'out',\n",
       "  'cause',\n",
       "  'its',\n",
       "  'so',\n",
       "  'nice',\n",
       "  'but',\n",
       "  'everybodys',\n",
       "  'busy'],\n",
       " ['awesome',\n",
       "  'im',\n",
       "  'down',\n",
       "  'in',\n",
       "  'ocean',\n",
       "  'beach',\n",
       "  'if',\n",
       "  'you',\n",
       "  'know',\n",
       "  'where',\n",
       "  'that',\n",
       "  'is',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  'yourbiggestfan',\n",
       "  'im',\n",
       "  'a',\n",
       "  'real',\n",
       "  'big',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'yours'],\n",
       " ['at',\n",
       "  'least',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'over',\n",
       "  'time',\n",
       "  'lets',\n",
       "  'go',\n",
       "  'pens'],\n",
       " ['cool',\n",
       "  'i',\n",
       "  'wear',\n",
       "  'black',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'time',\n",
       "  'when',\n",
       "  'i',\n",
       "  'go',\n",
       "  'out'],\n",
       " ['haha',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'work',\n",
       "  'blip',\n",
       "  'apart',\n",
       "  'from',\n",
       "  'the',\n",
       "  'obvious',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'reblipping',\n",
       "  'my',\n",
       "  'song',\n",
       "  'have',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'day'],\n",
       " ['have',\n",
       "  'a',\n",
       "  'safe',\n",
       "  'trip',\n",
       "  'joshy',\n",
       "  'pooyoull',\n",
       "  'knock',\n",
       "  'them',\n",
       "  'dead',\n",
       "  'at',\n",
       "  'your',\n",
       "  'speech'],\n",
       " ['woof', 'i', 'wish', 'i', 'was', 'allowed', 'to', 'go'],\n",
       " ['if',\n",
       "  'u',\n",
       "  'have',\n",
       "  'a',\n",
       "  'friendster',\n",
       "  'add',\n",
       "  'me',\n",
       "  'my',\n",
       "  'email',\n",
       "  'adress',\n",
       "  'add',\n",
       "  'me',\n",
       "  'add',\n",
       "  'me',\n",
       "  'leave',\n",
       "  'some',\n",
       "  'comment'],\n",
       " ['has', 'tickets'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  'afrin',\n",
       "  'nasal',\n",
       "  'spray',\n",
       "  'also',\n",
       "  'i',\n",
       "  'got',\n",
       "  'a',\n",
       "  'giant',\n",
       "  'teacup',\n",
       "  'tonight'],\n",
       " ['acsm',\n",
       "  'its',\n",
       "  'unfathomable',\n",
       "  'i',\n",
       "  'think',\n",
       "  'the',\n",
       "  'other',\n",
       "  'one',\n",
       "  'and',\n",
       "  'the',\n",
       "  'is',\n",
       "  'one',\n",
       "  'that',\n",
       "  'should',\n",
       "  'be',\n",
       "  'kept',\n",
       "  'to',\n",
       "  'the',\n",
       "  'comfort',\n",
       "  'of',\n",
       "  'our',\n",
       "  'bedrooms',\n",
       "  'yes'],\n",
       " ['aww',\n",
       "  'i',\n",
       "  'love',\n",
       "  'my',\n",
       "  'daddy',\n",
       "  'he',\n",
       "  'works',\n",
       "  'days',\n",
       "  'a',\n",
       "  'week',\n",
       "  'almost',\n",
       "  'all',\n",
       "  'day',\n",
       "  'and',\n",
       "  'still',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'sf',\n",
       "  'with',\n",
       "  'all',\n",
       "  'of',\n",
       "  'us'],\n",
       " ['so',\n",
       "  'many',\n",
       "  'tests',\n",
       "  'todayyy',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'feel',\n",
       "  'confident',\n",
       "  'about',\n",
       "  'anyy'],\n",
       " ['graduation',\n",
       "  'is',\n",
       "  'done',\n",
       "  'im',\n",
       "  'a',\n",
       "  'little',\n",
       "  'sad',\n",
       "  'anyone',\n",
       "  'want',\n",
       "  'to',\n",
       "  'hang',\n",
       "  'out'],\n",
       " ['hahaa', 'your', 'awesomee'],\n",
       " ['holy', 'smokes', 'star', 'trek', 'was', 'freaking', 'awesomeeeee'],\n",
       " ['i',\n",
       "  'hate',\n",
       "  'fallout',\n",
       "  'it',\n",
       "  'keeps',\n",
       "  'making',\n",
       "  'me',\n",
       "  'jump',\n",
       "  'im',\n",
       "  'also',\n",
       "  'low',\n",
       "  'on',\n",
       "  'health',\n",
       "  'money',\n",
       "  'ammo',\n",
       "  'and',\n",
       "  'food',\n",
       "  'dont',\n",
       "  'worry',\n",
       "  'ill',\n",
       "  'get',\n",
       "  'through',\n",
       "  'it'],\n",
       " ['i',\n",
       "  'had',\n",
       "  'it',\n",
       "  'on',\n",
       "  'my',\n",
       "  'itunes',\n",
       "  'but',\n",
       "  'then',\n",
       "  'i',\n",
       "  'lost',\n",
       "  'all',\n",
       "  'my',\n",
       "  'songs'],\n",
       " ['whats',\n",
       "  'with',\n",
       "  'the',\n",
       "  'gloomy',\n",
       "  'weather',\n",
       "  'the',\n",
       "  'sun',\n",
       "  'must',\n",
       "  'be',\n",
       "  'too',\n",
       "  'tired',\n",
       "  'to',\n",
       "  'come',\n",
       "  'out',\n",
       "  'and',\n",
       "  'play',\n",
       "  'heading',\n",
       "  'to',\n",
       "  'victoria',\n",
       "  'gardens',\n",
       "  'for',\n",
       "  'some',\n",
       "  'impulse',\n",
       "  'buys',\n",
       "  'haha'],\n",
       " ['not',\n",
       "  'looking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'next',\n",
       "  'week',\n",
       "  'maths',\n",
       "  'geography',\n",
       "  'english',\n",
       "  'and',\n",
       "  'french',\n",
       "  'exams',\n",
       "  'totalling',\n",
       "  'hours'],\n",
       " ['poor',\n",
       "  'you',\n",
       "  'get',\n",
       "  'outside',\n",
       "  'and',\n",
       "  'sleep',\n",
       "  'in',\n",
       "  'the',\n",
       "  'garden',\n",
       "  'the',\n",
       "  'sun',\n",
       "  'will',\n",
       "  'do',\n",
       "  'you',\n",
       "  'good',\n",
       "  'but',\n",
       "  'dont',\n",
       "  'forget',\n",
       "  'suncream'],\n",
       " ['not', 'well'],\n",
       " ['not', 'a', 'prob', 'hun'],\n",
       " ['at',\n",
       "  'dads',\n",
       "  'watching',\n",
       "  'some',\n",
       "  'mtv',\n",
       "  'and',\n",
       "  'am',\n",
       "  'going',\n",
       "  'on',\n",
       "  'in',\n",
       "  'a',\n",
       "  'minutee'],\n",
       " ['absolutely'],\n",
       " ['whats', 'the', 'matter', 'chickadee'],\n",
       " ['hey',\n",
       "  'mia',\n",
       "  'totally',\n",
       "  'adore',\n",
       "  'your',\n",
       "  'music',\n",
       "  'when',\n",
       "  'will',\n",
       "  'your',\n",
       "  'cd',\n",
       "  'be',\n",
       "  'out'],\n",
       " ['shopping',\n",
       "  'cleaning',\n",
       "  'bmfing',\n",
       "  'webcam',\n",
       "  'chatting',\n",
       "  'with',\n",
       "  'nephews',\n",
       "  'nothing',\n",
       "  'spesh',\n",
       "  'but',\n",
       "  'a',\n",
       "  'good',\n",
       "  'bank',\n",
       "  'holiday',\n",
       "  'monday',\n",
       "  'nonetheless'],\n",
       " ['o',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'him',\n",
       "  'something',\n",
       "  'lmao',\n",
       "  'i',\n",
       "  'love',\n",
       "  'him',\n",
       "  'too'],\n",
       " ['those',\n",
       "  'splinters',\n",
       "  'look',\n",
       "  'very',\n",
       "  'painfulbut',\n",
       "  'you',\n",
       "  'were',\n",
       "  'being',\n",
       "  'very',\n",
       "  'heroic',\n",
       "  'saving',\n",
       "  'mr',\n",
       "  'pickle'],\n",
       " ['why', 'are', 'you', 'sad'],\n",
       " ['nice',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'tweeting',\n",
       "  'its',\n",
       "  'sunday',\n",
       "  'may',\n",
       "  'and',\n",
       "  'were',\n",
       "  'celebrating',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'here',\n",
       "  'today',\n",
       "  'so',\n",
       "  'be',\n",
       "  'nice',\n",
       "  'to',\n",
       "  'yer',\n",
       "  'mom'],\n",
       " ['decided',\n",
       "  'trans',\n",
       "  'frm',\n",
       "  'relaxed',\n",
       "  'natural',\n",
       "  'hair',\n",
       "  'but',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'my',\n",
       "  'whole',\n",
       "  'head',\n",
       "  'looked',\n",
       "  'like',\n",
       "  'my',\n",
       "  'roots',\n",
       "  'age',\n",
       "  'of',\n",
       "  'the',\n",
       "  'instant',\n",
       "  'gratification'],\n",
       " ['namaskar',\n",
       "  'namaste',\n",
       "  'r',\n",
       "  'both',\n",
       "  'the',\n",
       "  'same',\n",
       "  'marathi',\n",
       "  'people',\n",
       "  'say',\n",
       "  'namaskar',\n",
       "  'its',\n",
       "  'a',\n",
       "  'marathi',\n",
       "  'word',\n",
       "  'should',\n",
       "  'i',\n",
       "  'naaaah'],\n",
       " ['congrats',\n",
       "  'i',\n",
       "  'cuss',\n",
       "  'like',\n",
       "  'that',\n",
       "  'in',\n",
       "  'a',\n",
       "  'matter',\n",
       "  'of',\n",
       "  'minutes',\n",
       "  'but',\n",
       "  'didnt',\n",
       "  'know',\n",
       "  'until',\n",
       "  'now',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'reward',\n",
       "  'for',\n",
       "  'it'],\n",
       " ['humous', 'and', 'doritos', 'oh', 'yes'],\n",
       " ['missed',\n",
       "  'all',\n",
       "  'the',\n",
       "  'awesome',\n",
       "  'weather',\n",
       "  'because',\n",
       "  'she',\n",
       "  'was',\n",
       "  'in',\n",
       "  'a',\n",
       "  'movie'],\n",
       " ['today',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'normal',\n",
       "  'day',\n",
       "  'for',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'we',\n",
       "  'had',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'pilots',\n",
       "  'from',\n",
       "  'a',\n",
       "  'large',\n",
       "  'airline',\n",
       "  'come',\n",
       "  'in',\n",
       "  'last',\n",
       "  'night',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  'too',\n",
       "  'much',\n",
       "  'drink'],\n",
       " ['these',\n",
       "  'kids',\n",
       "  'are',\n",
       "  'terrible',\n",
       "  'if',\n",
       "  'i',\n",
       "  'was',\n",
       "  'in',\n",
       "  'good',\n",
       "  'evans',\n",
       "  'id',\n",
       "  'call',\n",
       "  'childline'],\n",
       " ['unfortunatley',\n",
       "  'aerlingus',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'fly',\n",
       "  'to',\n",
       "  'copenhagen',\n",
       "  'so',\n",
       "  'were',\n",
       "  'have',\n",
       "  'to',\n",
       "  'fly',\n",
       "  'ryanair',\n",
       "  'to',\n",
       "  'billund',\n",
       "  'and',\n",
       "  'drive',\n",
       "  'up',\n",
       "  'to',\n",
       "  'copenhagen',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'days'],\n",
       " ['whats',\n",
       "  'sad',\n",
       "  'is',\n",
       "  'that',\n",
       "  'i',\n",
       "  'actually',\n",
       "  'had',\n",
       "  'to',\n",
       "  'google',\n",
       "  'that',\n",
       "  'term',\n",
       "  'that',\n",
       "  'sucks',\n",
       "  'tho'],\n",
       " ['hate', 'fighting'],\n",
       " ['i',\n",
       "  'watched',\n",
       "  'that',\n",
       "  'too',\n",
       "  'i',\n",
       "  'didnt',\n",
       "  'want',\n",
       "  'her',\n",
       "  'to',\n",
       "  'win',\n",
       "  'but',\n",
       "  'she',\n",
       "  'put',\n",
       "  'up',\n",
       "  'a',\n",
       "  'good',\n",
       "  'fightlol'],\n",
       " ['carwarmed', 'sprite', 'tastes', 'like', 'sore', 'throat'],\n",
       " ['just', 'came', 'in', 'cross', 'country', 'and', 'beat', 'dumbo'],\n",
       " ['candle', 'wax', 'is', 'very', 'enjoyable'],\n",
       " ['shes',\n",
       "  'unassuming',\n",
       "  'and',\n",
       "  'unpretentious',\n",
       "  'shes',\n",
       "  'just',\n",
       "  'as',\n",
       "  'i',\n",
       "  'suppose',\n",
       "  'thats',\n",
       "  'why',\n",
       "  'shes',\n",
       "  'so',\n",
       "  'endearingbecause',\n",
       "  'we',\n",
       "  'can',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'her'],\n",
       " ['tomorrow',\n",
       "  'valerias',\n",
       "  'lunch',\n",
       "  'going',\n",
       "  'to',\n",
       "  'get',\n",
       "  'my',\n",
       "  'hair',\n",
       "  'done',\n",
       "  'but',\n",
       "  'im',\n",
       "  'arraving',\n",
       "  'late',\n",
       "  'got',\n",
       "  'my',\n",
       "  'cousins',\n",
       "  'babtizm',\n",
       "  'or',\n",
       "  'whatever',\n",
       "  'you',\n",
       "  'spell',\n",
       "  'it'],\n",
       " ['goooooddd',\n",
       "  'morning',\n",
       "  'tweets',\n",
       "  'week',\n",
       "  'three',\n",
       "  'of',\n",
       "  'my',\n",
       "  'workout',\n",
       "  'did',\n",
       "  'i',\n",
       "  'mention',\n",
       "  'i',\n",
       "  'got',\n",
       "  'my',\n",
       "  'new',\n",
       "  'glasses',\n",
       "  'yesterday'],\n",
       " ['me', 'too', 'i', 'hate', 'my', 'computer', 'so', 'much'],\n",
       " ['fine',\n",
       "  'going',\n",
       "  'to',\n",
       "  'do',\n",
       "  'my',\n",
       "  'big',\n",
       "  'walk',\n",
       "  'today',\n",
       "  'or',\n",
       "  'so',\n",
       "  'miles'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'red',\n",
       "  'cruisers',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'like',\n",
       "  'the',\n",
       "  'other',\n",
       "  'ones',\n",
       "  'lmfao'],\n",
       " ['mmmmmmmm', 'it', 'in', 'the', 'morning'],\n",
       " ['me', 'neither'],\n",
       " ['has',\n",
       "  'about',\n",
       "  'hours',\n",
       "  'work',\n",
       "  'to',\n",
       "  'do',\n",
       "  'on',\n",
       "  'a',\n",
       "  'sunday',\n",
       "  'boo',\n",
       "  'i',\n",
       "  'will',\n",
       "  'find',\n",
       "  'time',\n",
       "  'for',\n",
       "  'a',\n",
       "  'two',\n",
       "  'hour',\n",
       "  'lunchbreak',\n",
       "  'though',\n",
       "  'yeah'],\n",
       " ['bugger', 'forgot', 'i', 'still', 'have', 'washing', 'in', 'my', 'machine'],\n",
       " ['laurie',\n",
       "  'sending',\n",
       "  'love',\n",
       "  'blessings',\n",
       "  'healing',\n",
       "  'thoughts',\n",
       "  'to',\n",
       "  'you',\n",
       "  'family',\n",
       "  'peace'],\n",
       " ['my', 'back', 'hurtsreally', 'bad'],\n",
       " ['ah', 'yes', 'i', 'know', 'that', 'feeling'],\n",
       " ['night', 'of', 'the', 'cookers', 'with', 'my', 'dad'],\n",
       " ['my',\n",
       "  'modem',\n",
       "  'has',\n",
       "  'been',\n",
       "  'offline',\n",
       "  'for',\n",
       "  'a',\n",
       "  'week',\n",
       "  'now',\n",
       "  'god',\n",
       "  'bless',\n",
       "  'the',\n",
       "  'network',\n",
       "  'tim',\n",
       "  'just',\n",
       "  'left',\n",
       "  'again',\n",
       "  'may',\n",
       "  'schedule',\n",
       "  'has',\n",
       "  'been',\n",
       "  'brutal'],\n",
       " ['nope', 'i', 'am', 'in', 'coquitlam'],\n",
       " ['had',\n",
       "  'parent',\n",
       "  'teacher',\n",
       "  'thing',\n",
       "  'yesterday',\n",
       "  'so',\n",
       "  'boring',\n",
       "  'going',\n",
       "  'to',\n",
       "  'skl',\n",
       "  'on',\n",
       "  'saturday',\n",
       "  'lol'],\n",
       " ['lichfield',\n",
       "  'tweetup',\n",
       "  'sounds',\n",
       "  'like',\n",
       "  'fun',\n",
       "  'hope',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'and',\n",
       "  'everyone',\n",
       "  'else',\n",
       "  'there'],\n",
       " ['big',\n",
       "  'booming',\n",
       "  'thunder',\n",
       "  'storm',\n",
       "  'almost',\n",
       "  'here',\n",
       "  'maybe',\n",
       "  'we',\n",
       "  'can',\n",
       "  'all',\n",
       "  'go',\n",
       "  'home',\n",
       "  'early',\n",
       "  'ah',\n",
       "  'probably',\n",
       "  'not'],\n",
       " ['few', 'bevvies', 'in', 'twngreat', 'on', 'a', 'day', 'off'],\n",
       " ['first',\n",
       "  'night',\n",
       "  'in',\n",
       "  'myers',\n",
       "  'just',\n",
       "  'not',\n",
       "  'the',\n",
       "  'same',\n",
       "  'wout',\n",
       "  'lydia',\n",
       "  'but',\n",
       "  'im',\n",
       "  'actually',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'this',\n",
       "  'summer'],\n",
       " ['good', 'morning'],\n",
       " ['its', 'the', 'best', 'show', 'ever'],\n",
       " ['url',\n",
       "  'in',\n",
       "  'previous',\n",
       "  'post',\n",
       "  'to',\n",
       "  'timer',\n",
       "  'job',\n",
       "  'should',\n",
       "  'be',\n",
       "  'id',\n",
       "  'removed',\n",
       "  'space',\n",
       "  'which',\n",
       "  'messed',\n",
       "  'up',\n",
       "  'url',\n",
       "  'es'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'iv',\n",
       "  'hurt',\n",
       "  'my',\n",
       "  'tooth',\n",
       "  'and',\n",
       "  'eilish',\n",
       "  'and',\n",
       "  'cassie',\n",
       "  'are',\n",
       "  'having',\n",
       "  'a',\n",
       "  'drawing',\n",
       "  'competiton',\n",
       "  'to',\n",
       "  'draw',\n",
       "  'cookies',\n",
       "  'and',\n",
       "  'pineapples',\n",
       "  'haha',\n",
       "  'l'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'know',\n",
       "  'when',\n",
       "  'the',\n",
       "  'auditions',\n",
       "  'are',\n",
       "  'mander',\n",
       "  'text',\n",
       "  'orreply',\n",
       "  'please'],\n",
       " ['or', 'even', 'nooooo', 'not', 'the', 'secret', 'namerebecca', 'please'],\n",
       " ['i',\n",
       "  'miss',\n",
       "  'my',\n",
       "  'neice',\n",
       "  'cant',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'see',\n",
       "  'her',\n",
       "  'bad',\n",
       "  'n',\n",
       "  'grown',\n",
       "  'lol'],\n",
       " ['i', 'need', 'to', 'get', 'my', 'computer', 'fixed'],\n",
       " ['really', 'hopes', 'her', 'cars', 'illness', 'is', 'not', 'terminal'],\n",
       " ['all',\n",
       "  'the',\n",
       "  'cool',\n",
       "  'people',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'find',\n",
       "  'for',\n",
       "  'following',\n",
       "  'today',\n",
       "  'are',\n",
       "  'english',\n",
       "  'and',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'the',\n",
       "  'english',\n",
       "  'dont',\n",
       "  'tweet'],\n",
       " ['no', 'siri', 'woulda', 'put', 'honeybut', 'i', 'dont', 'have', 'any'],\n",
       " ['who',\n",
       "  'watched',\n",
       "  'xmen',\n",
       "  'origins',\n",
       "  'wolverine',\n",
       "  'i',\n",
       "  'totally',\n",
       "  'loved',\n",
       "  'it',\n",
       "  'haha'],\n",
       " ['i',\n",
       "  'voted',\n",
       "  'do',\n",
       "  'u',\n",
       "  'have',\n",
       "  'a',\n",
       "  'personal',\n",
       "  'myspace',\n",
       "  'i',\n",
       "  'keep',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'fakes',\n",
       "  'i',\n",
       "  'you',\n",
       "  'u',\n",
       "  'helped',\n",
       "  'me',\n",
       "  'thru',\n",
       "  'the',\n",
       "  'hrdest',\n",
       "  'time',\n",
       "  'of',\n",
       "  'my',\n",
       "  'life',\n",
       "  'x'],\n",
       " ['im', 'sad', 'that', 'i', 'missed', 'you', 'guys', 'last', 'night'],\n",
       " ['finally',\n",
       "  'got',\n",
       "  'a',\n",
       "  'call',\n",
       "  'for',\n",
       "  'marriage',\n",
       "  'counseling',\n",
       "  'days',\n",
       "  'late'],\n",
       " ['ok', 'then'],\n",
       " ['why', 'baby'],\n",
       " ['today',\n",
       "  'was',\n",
       "  'the',\n",
       "  'last',\n",
       "  'day',\n",
       "  'of',\n",
       "  'high',\n",
       "  'school',\n",
       "  'for',\n",
       "  'me',\n",
       "  'and',\n",
       "  'i',\n",
       "  'ended',\n",
       "  'up',\n",
       "  'going',\n",
       "  'home',\n",
       "  'sick',\n",
       "  'stupid',\n",
       "  'dead',\n",
       "  'rats'],\n",
       " ['were',\n",
       "  'having',\n",
       "  'an',\n",
       "  'impromptu',\n",
       "  'pool',\n",
       "  'party',\n",
       "  'except',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'swim',\n",
       "  'so',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'get',\n",
       "  'in'],\n",
       " ['lost', 'my', 'tooth', 'whilst', 'i', 'was', 'eating', 'gumoww'],\n",
       " ['happy', 'year'],\n",
       " ['oh',\n",
       "  'i',\n",
       "  'hella',\n",
       "  'forgot',\n",
       "  'to',\n",
       "  'say',\n",
       "  'my',\n",
       "  'official',\n",
       "  'good',\n",
       "  'morning',\n",
       "  'like',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'it',\n",
       "  'here',\n",
       "  'it',\n",
       "  'go',\n",
       "  'goooooooooooood',\n",
       "  'morrrrrrrrning',\n",
       "  'twitterville',\n",
       "  'lol'],\n",
       " ['phew',\n",
       "  'will',\n",
       "  'make',\n",
       "  'a',\n",
       "  'note',\n",
       "  'in',\n",
       "  'case',\n",
       "  'anyone',\n",
       "  'else',\n",
       "  'runs',\n",
       "  'into',\n",
       "  'the',\n",
       "  'same',\n",
       "  'issue'],\n",
       " ['what', 'about', 'me', 'i', 'vote', 'every', 'day', 'for', 'you'],\n",
       " ['im',\n",
       "  'starving',\n",
       "  'this',\n",
       "  'diet',\n",
       "  'is',\n",
       "  'killing',\n",
       "  'me',\n",
       "  'but',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'eat',\n",
       "  'after'],\n",
       " ['i', 'talk', 'to', 'you'],\n",
       " ['im', 'soo', 'boredim', 'deffo', 'missing', 'my', 'music', 'channels'],\n",
       " ['nite', 'nite', 'bday', 'girl', 'have', 'fun', 'at', 'concert'],\n",
       " ['had',\n",
       "  'nicotine',\n",
       "  'replacement',\n",
       "  'patch',\n",
       "  'on',\n",
       "  'for',\n",
       "  'hours',\n",
       "  'so',\n",
       "  'far',\n",
       "  'so',\n",
       "  'good',\n",
       "  'but',\n",
       "  'i',\n",
       "  'did',\n",
       "  'sleep',\n",
       "  'for',\n",
       "  'most',\n",
       "  'of',\n",
       "  'those',\n",
       "  'hours',\n",
       "  'getting',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'twitchy',\n",
       "  'now'],\n",
       " ['sanderson',\n",
       "  'whats',\n",
       "  'with',\n",
       "  'twatter',\n",
       "  'lately',\n",
       "  'either',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'get',\n",
       "  'on',\n",
       "  'or',\n",
       "  'the',\n",
       "  'replies',\n",
       "  'dont',\n",
       "  'turn',\n",
       "  'up'],\n",
       " ['should',\n",
       "  'be',\n",
       "  'sleeping',\n",
       "  'lost',\n",
       "  'my',\n",
       "  'voice',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'day',\n",
       "  'ago'],\n",
       " ['hate', 'when', 'my', 'parked', 'car', 'gets', 'hit'],\n",
       " ['ive', 'heard', 'this', 'fall', 'im', 'waiting', 'too'],\n",
       " ['more', 'nightmares', 'huggles'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'such',\n",
       "  'a',\n",
       "  'creeper',\n",
       "  'i',\n",
       "  'feel',\n",
       "  'disappointed',\n",
       "  'because',\n",
       "  'of',\n",
       "  'it',\n",
       "  'my',\n",
       "  'cyberstalking',\n",
       "  'skills',\n",
       "  'the',\n",
       "  'internet',\n",
       "  'no',\n",
       "  'more',\n",
       "  'privacy'],\n",
       " ['going', 'to', 'bed', 'its', 'late', 'and', 'i', 'have', 'headache'],\n",
       " ['happy', 'mothers', 'day', 'to', 'all', 'moms', 'out', 'there'],\n",
       " ['grabbing', 'coffee', 'from', 'then', 'making', 'mom', 'breakfast'],\n",
       " ['im',\n",
       "  'thinking',\n",
       "  'that',\n",
       "  'im',\n",
       "  'going',\n",
       "  'to',\n",
       "  'have',\n",
       "  'fun',\n",
       "  'tonightand',\n",
       "  'maybe',\n",
       "  'some',\n",
       "  'changes',\n",
       "  'are',\n",
       "  'coming'],\n",
       " ['thanks', 'before', 'the', 'major', 'chop'],\n",
       " ['haha',\n",
       "  'i',\n",
       "  'know',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'handle',\n",
       "  'the',\n",
       "  'fame',\n",
       "  'and',\n",
       "  'thank',\n",
       "  'you'],\n",
       " ['just', 'got', 'up', 'and', 'updated', 'my', 'ipod'],\n",
       " ['yes',\n",
       "  'sober',\n",
       "  'hahaha',\n",
       "  'tanghaling',\n",
       "  'tapat',\n",
       "  'dude',\n",
       "  'haha',\n",
       "  'wild',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'knowwww',\n",
       "  'plan',\n",
       "  'plan',\n",
       "  'before',\n",
       "  'you',\n",
       "  'go',\n",
       "  'to',\n",
       "  'us'],\n",
       " ['we',\n",
       "  'never',\n",
       "  'miss',\n",
       "  'icarly',\n",
       "  'my',\n",
       "  'son',\n",
       "  'has',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'crush',\n",
       "  'on',\n",
       "  'miranda'],\n",
       " ['saw',\n",
       "  'james',\n",
       "  'carville',\n",
       "  'in',\n",
       "  'the',\n",
       "  'store',\n",
       "  'today',\n",
       "  'his',\n",
       "  'head',\n",
       "  'is',\n",
       "  'really',\n",
       "  'that',\n",
       "  'bald'],\n",
       " ['yellow', 'for'],\n",
       " ['which',\n",
       "  'means',\n",
       "  'youre',\n",
       "  'just',\n",
       "  'going',\n",
       "  'to',\n",
       "  'have',\n",
       "  'to',\n",
       "  'come',\n",
       "  'back',\n",
       "  'to',\n",
       "  'vancouver',\n",
       "  'and',\n",
       "  'have',\n",
       "  'it',\n",
       "  'our',\n",
       "  'way',\n",
       "  'hahah'],\n",
       " ['feeling', 'smooth', 'like', 'chrome'],\n",
       " ['ew', 'traffic'],\n",
       " ['downloading',\n",
       "  'songs',\n",
       "  'while',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'sneak',\n",
       "  'a',\n",
       "  'lil',\n",
       "  'homework',\n",
       "  'in',\n",
       "  'too',\n",
       "  'which',\n",
       "  'should',\n",
       "  'be',\n",
       "  'my',\n",
       "  'main',\n",
       "  'priority',\n",
       "  'not',\n",
       "  'songs',\n",
       "  'lol'],\n",
       " ['rara', 'your', 'not', 'alonei', 'need', 'coffee', 'too'],\n",
       " ['sounds', 'like', 'me'],\n",
       " ['bad',\n",
       "  'day',\n",
       "  'the',\n",
       "  'day',\n",
       "  'you',\n",
       "  'realize',\n",
       "  'what',\n",
       "  'mess',\n",
       "  'youve',\n",
       "  'put',\n",
       "  'me',\n",
       "  'through',\n",
       "  'will',\n",
       "  'be',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'happiest',\n",
       "  'days',\n",
       "  'of',\n",
       "  'my',\n",
       "  'life'],\n",
       " ['walking',\n",
       "  'to',\n",
       "  'class',\n",
       "  'i',\n",
       "  'hate',\n",
       "  'not',\n",
       "  'having',\n",
       "  'a',\n",
       "  'bikeespecially',\n",
       "  'mine'],\n",
       " ['nesmith'],\n",
       " ['failed',\n",
       "  'inspection',\n",
       "  'did',\n",
       "  'you',\n",
       "  'know',\n",
       "  'you',\n",
       "  'can',\n",
       "  'pass',\n",
       "  'wooven',\n",
       "  'but',\n",
       "  'not',\n",
       "  'woantitip',\n",
       "  'bracket',\n",
       "  'which',\n",
       "  'is',\n",
       "  'only',\n",
       "  'sold',\n",
       "  'woven',\n",
       "  'this',\n",
       "  'is',\n",
       "  'worse',\n",
       "  'than',\n",
       "  'taxes'],\n",
       " ['jonas',\n",
       "  'brothers',\n",
       "  'live',\n",
       "  'to',\n",
       "  'party',\n",
       "  'its',\n",
       "  'rocking',\n",
       "  'so',\n",
       "  'hard',\n",
       "  'i',\n",
       "  'love',\n",
       "  'the',\n",
       "  'song'],\n",
       " ['happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'to',\n",
       "  'all',\n",
       "  'the',\n",
       "  'mothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world'],\n",
       " ['through',\n",
       "  'the',\n",
       "  'google',\n",
       "  'wave',\n",
       "  'demo',\n",
       "  'that',\n",
       "  'looks',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'fun',\n",
       "  'would',\n",
       "  'love',\n",
       "  'to',\n",
       "  'test',\n",
       "  'it',\n",
       "  'though'],\n",
       " ['sleepy',\n",
       "  'tabz',\n",
       "  'is',\n",
       "  'heading',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'fun',\n",
       "  'night',\n",
       "  'listened',\n",
       "  'through',\n",
       "  'the',\n",
       "  'next',\n",
       "  'episode',\n",
       "  'of',\n",
       "  'jossd'],\n",
       " ['the',\n",
       "  'exception',\n",
       "  'for',\n",
       "  'a',\n",
       "  'short',\n",
       "  'dude',\n",
       "  'larenz',\n",
       "  'fineass',\n",
       "  'tate',\n",
       "  'yum'],\n",
       " ['screw',\n",
       "  'the',\n",
       "  'reviews',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'wolverine',\n",
       "  'was',\n",
       "  'awesome',\n",
       "  'but',\n",
       "  'not',\n",
       "  'enough',\n",
       "  'dominic',\n",
       "  'monaghan',\n",
       "  'for',\n",
       "  'my',\n",
       "  'liking'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'followed',\n",
       "  'us',\n",
       "  'recently',\n",
       "  'please',\n",
       "  'dont',\n",
       "  'be',\n",
       "  'offended',\n",
       "  'that',\n",
       "  'we',\n",
       "  'havent',\n",
       "  'followed',\n",
       "  'back',\n",
       "  'we',\n",
       "  'hit',\n",
       "  'our',\n",
       "  'limit',\n",
       "  'hopefully',\n",
       "  'we',\n",
       "  'will',\n",
       "  'be',\n",
       "  'free',\n",
       "  'soon'],\n",
       " ['yes', 'i', 'work', 'to'],\n",
       " ['hmmm',\n",
       "  'maybe',\n",
       "  'thats',\n",
       "  'what',\n",
       "  'they',\n",
       "  'meant',\n",
       "  'they',\n",
       "  'eluded',\n",
       "  'to',\n",
       "  'something',\n",
       "  'brand',\n",
       "  'new',\n",
       "  'but',\n",
       "  'you',\n",
       "  'know',\n",
       "  'how',\n",
       "  'the',\n",
       "  'media',\n",
       "  'is'],\n",
       " ['done',\n",
       "  'at',\n",
       "  'the',\n",
       "  'spa',\n",
       "  'now',\n",
       "  'meeting',\n",
       "  'vic',\n",
       "  'for',\n",
       "  'some',\n",
       "  'late',\n",
       "  'lunch'],\n",
       " ['happy',\n",
       "  'monday',\n",
       "  'up',\n",
       "  'and',\n",
       "  'about',\n",
       "  'going',\n",
       "  'to',\n",
       "  'tavares',\n",
       "  'today',\n",
       "  'hope',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'a',\n",
       "  'blessed',\n",
       "  'day'],\n",
       " ['always', 'have', 'wanted', 'to', 'go', 'to', 'oz'],\n",
       " ['thx'],\n",
       " ['cool', 'luv', 'it'],\n",
       " ['thats',\n",
       "  'why',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'thereto',\n",
       "  'represent',\n",
       "  'the',\n",
       "  'blackberries'],\n",
       " ['okay',\n",
       "  'so',\n",
       "  'im',\n",
       "  'dedicating',\n",
       "  'my',\n",
       "  'tweet',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'im',\n",
       "  'going',\n",
       "  'to',\n",
       "  'the',\n",
       "  'apple',\n",
       "  'store',\n",
       "  'because',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'crack',\n",
       "  'on',\n",
       "  'the',\n",
       "  'glass',\n",
       "  'screen'],\n",
       " ['if',\n",
       "  'only',\n",
       "  'we',\n",
       "  'could',\n",
       "  'ever',\n",
       "  'actually',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'here',\n",
       "  'and',\n",
       "  'do',\n",
       "  'that'],\n",
       " ['let', 'me', 'know', 'how', 'that', 'turns', 'out'],\n",
       " ['was',\n",
       "  'that',\n",
       "  'sass',\n",
       "  'i',\n",
       "  'detect',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'it',\n",
       "  'isnt',\n",
       "  'back',\n",
       "  'sass',\n",
       "  'haha'],\n",
       " ['yeah', 'i', 'was', 'thinking', 'about', 'that', 'ahaha'],\n",
       " ['sports',\n",
       "  'bar',\n",
       "  'shatranjanpoli',\n",
       "  'rest',\n",
       "  'ph',\n",
       "  'all',\n",
       "  'sports',\n",
       "  'bar',\n",
       "  'andheri',\n",
       "  'w',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'whether',\n",
       "  'that',\n",
       "  'helps',\n",
       "  'google',\n",
       "  'ki',\n",
       "  'jai',\n",
       "  'ho'],\n",
       " ['im', 'not', 'sleeping', 'at', 'all', 'until', 'accepts', 'my', 'appology'],\n",
       " ['wolverine',\n",
       "  'was',\n",
       "  'boss',\n",
       "  'seriously',\n",
       "  'and',\n",
       "  'william',\n",
       "  'was',\n",
       "  'in',\n",
       "  'it',\n",
       "  'what',\n",
       "  'the'],\n",
       " ['i', 'live', 'for', 'pain', 'bring', 'it', 'on'],\n",
       " ['okay', 'im', 'out', 'for', 'a', 'while', 'back', 'later'],\n",
       " ['powerblog',\n",
       "  'what',\n",
       "  'is',\n",
       "  'this',\n",
       "  'powerblog',\n",
       "  'challenge',\n",
       "  'you',\n",
       "  'keep',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'im',\n",
       "  'a',\n",
       "  'newbie',\n",
       "  'follower'],\n",
       " ['almost',\n",
       "  'died',\n",
       "  'laptop',\n",
       "  'screen',\n",
       "  'was',\n",
       "  'set',\n",
       "  'to',\n",
       "  'brightness',\n",
       "  'after',\n",
       "  'i',\n",
       "  'reinstalled',\n",
       "  'windows',\n",
       "  'vista',\n",
       "  'got',\n",
       "  'a',\n",
       "  'headache',\n",
       "  'now',\n",
       "  'insanedefaults'],\n",
       " ['waiting',\n",
       "  'for',\n",
       "  'tish',\n",
       "  'to',\n",
       "  'get',\n",
       "  'off',\n",
       "  'got',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'my',\n",
       "  'moms',\n",
       "  'crv',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'her',\n",
       "  'up',\n",
       "  'all',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'and',\n",
       "  'duckie',\n",
       "  'first',\n",
       "  'time'],\n",
       " ['trying',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'on',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'with',\n",
       "  'the',\n",
       "  'friends',\n",
       "  'not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'well',\n",
       "  'lol',\n",
       "  'p',\n",
       "  'no',\n",
       "  'bible',\n",
       "  'study',\n",
       "  'which',\n",
       "  'means',\n",
       "  'day',\n",
       "  'cake',\n",
       "  'buy',\n",
       "  'my',\n",
       "  'own'],\n",
       " ['going',\n",
       "  'to',\n",
       "  'shower',\n",
       "  'because',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'want',\n",
       "  'to',\n",
       "  'smell',\n",
       "  'at',\n",
       "  'school',\n",
       "  'tomorrow'],\n",
       " ['sigh', 'you', 'know', 'i', 'am'],\n",
       " ['discovered',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'a',\n",
       "  'bug',\n",
       "  'in',\n",
       "  'the',\n",
       "  'new',\n",
       "  'netplayer',\n",
       "  'build',\n",
       "  'publishing',\n",
       "  'bug',\n",
       "  'fix',\n",
       "  'now',\n",
       "  'hopefully',\n",
       "  'new',\n",
       "  'beta',\n",
       "  'by',\n",
       "  'tomorrow'],\n",
       " ['here',\n",
       "  'are',\n",
       "  'free',\n",
       "  'twitter',\n",
       "  'tools',\n",
       "  'will',\n",
       "  'get',\n",
       "  'you',\n",
       "  'followers'],\n",
       " ['just',\n",
       "  'got',\n",
       "  'home',\n",
       "  'from',\n",
       "  'work',\n",
       "  'and',\n",
       "  'is',\n",
       "  'chugging',\n",
       "  'down',\n",
       "  'a',\n",
       "  'big',\n",
       "  'bottle',\n",
       "  'of',\n",
       "  'apple',\n",
       "  'juice'],\n",
       " ['yes',\n",
       "  'it',\n",
       "  'does',\n",
       "  'please',\n",
       "  'dont',\n",
       "  'go',\n",
       "  'if',\n",
       "  'you',\n",
       "  'die',\n",
       "  'i',\n",
       "  'will',\n",
       "  'cry',\n",
       "  'which',\n",
       "  'normally',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'small',\n",
       "  'animals',\n",
       "  'getting',\n",
       "  'harmed'],\n",
       " ['writing',\n",
       "  'report',\n",
       "  'cards',\n",
       "  'soooo',\n",
       "  'tired',\n",
       "  'but',\n",
       "  'what',\n",
       "  'an',\n",
       "  'amazing',\n",
       "  'day',\n",
       "  'check',\n",
       "  'it',\n",
       "  'out',\n",
       "  'on',\n",
       "  'fb',\n",
       "  'soon'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'only',\n",
       "  'once',\n",
       "  'for',\n",
       "  'my',\n",
       "  'big',\n",
       "  'brotherand',\n",
       "  'im',\n",
       "  'done',\n",
       "  'now'],\n",
       " ['good',\n",
       "  'news',\n",
       "  'finally',\n",
       "  'finished',\n",
       "  'my',\n",
       "  'easactive',\n",
       "  'workout',\n",
       "  'that',\n",
       "  'has',\n",
       "  'been',\n",
       "  'paused',\n",
       "  'for',\n",
       "  'hours',\n",
       "  'bad',\n",
       "  'news',\n",
       "  'my',\n",
       "  'resistance',\n",
       "  'band',\n",
       "  'is',\n",
       "  'torn'],\n",
       " ['well',\n",
       "  'good',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'what',\n",
       "  'a',\n",
       "  'wonderful',\n",
       "  'day',\n",
       "  'in',\n",
       "  'the',\n",
       "  'neighborhood',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'all',\n",
       "  'those',\n",
       "  'that',\n",
       "  'are',\n",
       "  'now',\n",
       "  'following',\n",
       "  'another',\n",
       "  'this',\n",
       "  'morning'],\n",
       " ['ftsk',\n",
       "  'and',\n",
       "  'mercy',\n",
       "  'mercedes',\n",
       "  'were',\n",
       "  'amazing',\n",
       "  'tonight',\n",
       "  'as',\n",
       "  'always'],\n",
       " ['hope', 'he', 'is', 'ok'],\n",
       " ['cant',\n",
       "  'school',\n",
       "  'just',\n",
       "  'be',\n",
       "  'done',\n",
       "  'already',\n",
       "  'it',\n",
       "  'hurts',\n",
       "  'too',\n",
       "  'much',\n",
       "  'seeing',\n",
       "  'him',\n",
       "  'every',\n",
       "  'day'],\n",
       " ['i',\n",
       "  'waited',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'wind',\n",
       "  'blowing',\n",
       "  'through',\n",
       "  'the',\n",
       "  'tumbleweed',\n",
       "  'are',\n",
       "  'none',\n",
       "  'of',\n",
       "  'you',\n",
       "  'old',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'know',\n",
       "  'what',\n",
       "  'to',\n",
       "  'do',\n",
       "  'when',\n",
       "  'someone',\n",
       "  'says',\n",
       "  'crackerack'],\n",
       " ['hell', 'yeah'],\n",
       " ['him',\n",
       "  'shirt',\n",
       "  'at',\n",
       "  'dinner',\n",
       "  'do',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'does',\n",
       "  'it',\n",
       "  'actually',\n",
       "  'have',\n",
       "  'ville',\n",
       "  'on',\n",
       "  'it'],\n",
       " ['i', 'know'],\n",
       " ['huh', 'what', 'the', 'smelly', 'noooo', 'i', 'love', 'alex', 'vixon'],\n",
       " ['went',\n",
       "  'to',\n",
       "  'a',\n",
       "  'party',\n",
       "  'last',\n",
       "  'night',\n",
       "  'dindin',\n",
       "  'and',\n",
       "  'i',\n",
       "  'showed',\n",
       "  'up',\n",
       "  'in',\n",
       "  'matching',\n",
       "  'outfits',\n",
       "  'great',\n",
       "  'minds',\n",
       "  'think',\n",
       "  'alike',\n",
       "  'anyway',\n",
       "  'happy',\n",
       "  'birthday',\n",
       "  'ate',\n",
       "  'lara'],\n",
       " ['happy',\n",
       "  'bday',\n",
       "  'just',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'on',\n",
       "  'this',\n",
       "  'side',\n",
       "  'of',\n",
       "  'earth',\n",
       "  'so',\n",
       "  'wishes',\n",
       "  'are',\n",
       "  'bit',\n",
       "  'late'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  'for',\n",
       "  'teaching',\n",
       "  'me',\n",
       "  'values',\n",
       "  'and',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'better',\n",
       "  'person',\n",
       "  'each',\n",
       "  'day',\n",
       "  'i',\n",
       "  'love',\n",
       "  'so',\n",
       "  'much',\n",
       "  'youre',\n",
       "  'the',\n",
       "  'best',\n",
       "  'mum',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world'],\n",
       " ['happy', 'mothers', 'day'],\n",
       " ['laughs',\n",
       "  'im',\n",
       "  'glad',\n",
       "  'that',\n",
       "  'you',\n",
       "  'have',\n",
       "  'self',\n",
       "  'confidence',\n",
       "  'its',\n",
       "  'a',\n",
       "  'wonderful',\n",
       "  'trait',\n",
       "  'to',\n",
       "  'have',\n",
       "  'ill',\n",
       "  'applaud',\n",
       "  'extra',\n",
       "  'loud',\n",
       "  'for',\n",
       "  'it',\n",
       "  'okay'],\n",
       " ['thanks'],\n",
       " ['twittering', 'after', 'days'],\n",
       " ['getting',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'week',\n",
       "  'its',\n",
       "  'too',\n",
       "  'nice',\n",
       "  'today',\n",
       "  'to',\n",
       "  'be',\n",
       "  'stuck',\n",
       "  'inside',\n",
       "  'working'],\n",
       " ['i', 'am', 'tres', 'depressed'],\n",
       " ['felt',\n",
       "  'like',\n",
       "  'behaved',\n",
       "  'like',\n",
       "  'my',\n",
       "  'son',\n",
       "  'ate',\n",
       "  'to',\n",
       "  'compensate',\n",
       "  'pigged',\n",
       "  'out',\n",
       "  'on',\n",
       "  'homeroasted',\n",
       "  'sugar',\n",
       "  'almonds',\n",
       "  'painful',\n",
       "  'tum',\n",
       "  'threw',\n",
       "  'up',\n",
       "  'still',\n",
       "  'feel',\n",
       "  'sick'],\n",
       " ['happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'people',\n",
       "  'i',\n",
       "  'love',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'still'],\n",
       " ['im', 'sorry', 'to', 'hear', 'that'],\n",
       " ['thats',\n",
       "  'awesome',\n",
       "  'dude',\n",
       "  'yay',\n",
       "  'for',\n",
       "  'surprise',\n",
       "  'celebrities',\n",
       "  'i',\n",
       "  'got',\n",
       "  'to',\n",
       "  'meet',\n",
       "  'him',\n",
       "  'a',\n",
       "  'few',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'he',\n",
       "  'was',\n",
       "  'soooo',\n",
       "  'friendly'],\n",
       " ['it',\n",
       "  'makes',\n",
       "  'me',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'a',\n",
       "  'girl',\n",
       "  'talk',\n",
       "  'or',\n",
       "  'tweet',\n",
       "  'about',\n",
       "  'the',\n",
       "  'nba',\n",
       "  'but',\n",
       "  'could',\n",
       "  'you',\n",
       "  'give',\n",
       "  'my',\n",
       "  'nuggets',\n",
       "  'some',\n",
       "  'love'],\n",
       " ['is', 'getting', 'the', 'hang', 'of', 'twitter'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'your',\n",
       "  'neck',\n",
       "  'is',\n",
       "  'jacked',\n",
       "  'up',\n",
       "  'when',\n",
       "  'you',\n",
       "  'are',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'parking',\n",
       "  'bc',\n",
       "  'you',\n",
       "  'cant',\n",
       "  'turn',\n",
       "  'you',\n",
       "  'head',\n",
       "  'to',\n",
       "  'parallel',\n",
       "  'park',\n",
       "  'in',\n",
       "  'the',\n",
       "  'free',\n",
       "  'spaces'],\n",
       " ['i', 'want', 'it', 'back', 'now'],\n",
       " ['going',\n",
       "  'to',\n",
       "  'miss',\n",
       "  'my',\n",
       "  'roomie',\n",
       "  'we',\n",
       "  'will',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'be',\n",
       "  'roomies',\n",
       "  'starting',\n",
       "  'tomorrow'],\n",
       " ['bathing', 'with', 'two', 'little', 'angels', 'keyla', 'and', 'janice'],\n",
       " ['yep',\n",
       "  'finished',\n",
       "  'chocked',\n",
       "  'full',\n",
       "  'of',\n",
       "  'spelling',\n",
       "  'and',\n",
       "  'grammatical',\n",
       "  'errors',\n",
       "  'but',\n",
       "  'im',\n",
       "  'cleaning',\n",
       "  'it',\n",
       "  'up',\n",
       "  'tomorrow',\n",
       "  'and',\n",
       "  'popping',\n",
       "  'it',\n",
       "  'up',\n",
       "  'hehe'],\n",
       " ['hahahha',\n",
       "  'lol',\n",
       "  'true',\n",
       "  'that',\n",
       "  'i',\n",
       "  'always',\n",
       "  'remember',\n",
       "  'my',\n",
       "  'bd',\n",
       "  'but',\n",
       "  'i',\n",
       "  'can',\n",
       "  'never',\n",
       "  'remember',\n",
       "  'what',\n",
       "  'date',\n",
       "  'or',\n",
       "  'even',\n",
       "  'day',\n",
       "  'it',\n",
       "  'is'],\n",
       " ['family', 'is', 'herehanging', 'with', 'them'],\n",
       " ['watching',\n",
       "  'ellen',\n",
       "  'love',\n",
       "  'her',\n",
       "  'then',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'dishes',\n",
       "  'and',\n",
       "  'tanning',\n",
       "  'its',\n",
       "  'gorgeous',\n",
       "  'out'],\n",
       " ['whats', 'goin', 'on', 'hun', 'im', 'worried', 'about', 'you'],\n",
       " ['im', 'not', 'bannished', 'but', 'i', 'am', 'at', 'work', 'till'],\n",
       " ['morning',\n",
       "  'if',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'see',\n",
       "  'it',\n",
       "  'ill',\n",
       "  'let',\n",
       "  'you',\n",
       "  'know',\n",
       "  'right',\n",
       "  'now',\n",
       "  'im',\n",
       "  'going',\n",
       "  'to',\n",
       "  'go',\n",
       "  'see',\n",
       "  'wolverine'],\n",
       " ['red', 'top', 'tabloids', 'build', 'em', 'up', 'knock', 'em', 'down'],\n",
       " ['tonight', 'in', 'party', 'w', 'my', 'girls', 'minus', 'vita'],\n",
       " ['why',\n",
       "  'not',\n",
       "  'now',\n",
       "  'you',\n",
       "  'made',\n",
       "  'me',\n",
       "  'sad',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'youd',\n",
       "  'be',\n",
       "  'jumping',\n",
       "  'for',\n",
       "  'joy'],\n",
       " ['simple', 'my', 'a'],\n",
       " ['the',\n",
       "  'pics',\n",
       "  'i',\n",
       "  'just',\n",
       "  'uploaded',\n",
       "  'are',\n",
       "  'the',\n",
       "  'baby',\n",
       "  'pics',\n",
       "  'of',\n",
       "  'my',\n",
       "  'cats',\n",
       "  'missy',\n",
       "  'is',\n",
       "  'now',\n",
       "  'an',\n",
       "  'adult',\n",
       "  'and',\n",
       "  'a',\n",
       "  'pretty',\n",
       "  'little',\n",
       "  'kitty',\n",
       "  'but',\n",
       "  'batty',\n",
       "  'is',\n",
       "  'in',\n",
       "  'kitten',\n",
       "  'heaven',\n",
       "  'now'],\n",
       " ['i', 'saw', 'the', 'play', 'of', 'it', 'here', 'it', 'was', 'amazing'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'glad',\n",
       "  'to',\n",
       "  'break',\n",
       "  'my',\n",
       "  'twitter',\n",
       "  'virginity',\n",
       "  'with',\n",
       "  'you',\n",
       "  'two'],\n",
       " ['dinner', 'with', 'the', 'fam', 'i', 'have', 'missed', 'them'],\n",
       " ['live',\n",
       "  'thats',\n",
       "  'what',\n",
       "  'i',\n",
       "  'want',\n",
       "  'more',\n",
       "  'the',\n",
       "  'better',\n",
       "  'bound',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'few',\n",
       "  'bad',\n",
       "  'eggs',\n",
       "  'though',\n",
       "  'but',\n",
       "  'they',\n",
       "  'will',\n",
       "  'soon',\n",
       "  'learn'],\n",
       " ['hell', 'yeah', 'kellynn', 'got', 'a', 'twitter', 'finally'],\n",
       " ['i', 'know', 'it', 'was', 'worth', 'a', 'shot', 'though'],\n",
       " ['just',\n",
       "  'opened',\n",
       "  'a',\n",
       "  'facebook',\n",
       "  'account',\n",
       "  'im',\n",
       "  'a',\n",
       "  'little',\n",
       "  'confused',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'really',\n",
       "  'get',\n",
       "  'it',\n",
       "  'twitter',\n",
       "  'seems',\n",
       "  'much',\n",
       "  'better'],\n",
       " ['ship', 'im', 'stuck'],\n",
       " ['dustbin', 'baby', 'on', 'at', 'cannot', 'wait', 'x'],\n",
       " ['not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'dwell',\n",
       "  'on',\n",
       "  'it',\n",
       "  'it',\n",
       "  'happened',\n",
       "  'its',\n",
       "  'passed',\n",
       "  'just',\n",
       "  'a',\n",
       "  'shame',\n",
       "  'as',\n",
       "  'he',\n",
       "  'was',\n",
       "  'so',\n",
       "  'supportive',\n",
       "  'such',\n",
       "  'is',\n",
       "  'life',\n",
       "  'x'],\n",
       " ['it',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'the',\n",
       "  'office',\n",
       "  'tv',\n",
       "  'does',\n",
       "  'get',\n",
       "  'mlb',\n",
       "  'network',\n",
       "  'and',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'mlbn',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'televising',\n",
       "  'the',\n",
       "  'detbal',\n",
       "  'game',\n",
       "  'today',\n",
       "  'wieters'],\n",
       " ['home',\n",
       "  'empty',\n",
       "  'handed',\n",
       "  'no',\n",
       "  'comics',\n",
       "  'found',\n",
       "  'today',\n",
       "  'i',\n",
       "  'shall',\n",
       "  'now',\n",
       "  'indulge',\n",
       "  'in',\n",
       "  'my',\n",
       "  'cupcakes',\n",
       "  'from',\n",
       "  'magnolia',\n",
       "  'bakery'],\n",
       " ['laying',\n",
       "  'in',\n",
       "  'bed',\n",
       "  'til',\n",
       "  'workkk',\n",
       "  'oh',\n",
       "  'the',\n",
       "  'life',\n",
       "  'definitely',\n",
       "  'pinched',\n",
       "  'a',\n",
       "  'nerve'],\n",
       " ['today', 'is', 'a', 'busy', 'day', 'exhausting'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'going',\n",
       "  'to',\n",
       "  'go',\n",
       "  'on',\n",
       "  'sunday',\n",
       "  'but',\n",
       "  'now',\n",
       "  'ive',\n",
       "  'got',\n",
       "  'too',\n",
       "  'much',\n",
       "  'going',\n",
       "  'on',\n",
       "  'that',\n",
       "  'weekend'],\n",
       " ['sorry', 'to', 'hear', 'ur', 'flight', 'got', 'cancelled', 'that', 'blows'],\n",
       " ['ohh',\n",
       "  'my',\n",
       "  'tooth',\n",
       "  'is',\n",
       "  'hurts',\n",
       "  'ohh',\n",
       "  'im',\n",
       "  'sad',\n",
       "  'it',\n",
       "  'very',\n",
       "  'hurts'],\n",
       " ['before',\n",
       "  'i',\n",
       "  'get',\n",
       "  'too',\n",
       "  'distracted',\n",
       "  'id',\n",
       "  'like',\n",
       "  'to',\n",
       "  'thank',\n",
       "  'my',\n",
       "  'new',\n",
       "  'followers',\n",
       "  'for',\n",
       "  'taking',\n",
       "  'the',\n",
       "  'trouble',\n",
       "  'to',\n",
       "  'follow',\n",
       "  'me',\n",
       "  'and',\n",
       "  'to',\n",
       "  'my',\n",
       "  'others',\n",
       "  'feelin',\n",
       "  'the',\n",
       "  'love'],\n",
       " ['u',\n",
       "  'think',\n",
       "  'u',\n",
       "  'have',\n",
       "  'bills',\n",
       "  'haii',\n",
       "  'just',\n",
       "  'finished',\n",
       "  'paying',\n",
       "  'mine',\n",
       "  'thats',\n",
       "  'y',\n",
       "  'im',\n",
       "  'broke'],\n",
       " ['not',\n",
       "  'sure',\n",
       "  'it',\n",
       "  'didnt',\n",
       "  'say',\n",
       "  'it',\n",
       "  'was',\n",
       "  'big',\n",
       "  'i',\n",
       "  'jst',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'pics',\n",
       "  'of',\n",
       "  'u',\n",
       "  'on',\n",
       "  'ur',\n",
       "  'last',\n",
       "  'bday',\n",
       "  'you',\n",
       "  'looked',\n",
       "  'so',\n",
       "  'pretty',\n",
       "  'i',\n",
       "  'miss',\n",
       "  'you'],\n",
       " ['sore',\n",
       "  'throat',\n",
       "  'planning',\n",
       "  'the',\n",
       "  'tet',\n",
       "  'outing',\n",
       "  'to',\n",
       "  'marwell',\n",
       "  'thoughgood',\n",
       "  'times'],\n",
       " ['mcfly',\n",
       "  'gig',\n",
       "  'last',\n",
       "  'nightt',\n",
       "  'omg',\n",
       "  'it',\n",
       "  'was',\n",
       "  'amazin',\n",
       "  'didnt',\n",
       "  'sit',\n",
       "  'down',\n",
       "  'through',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'thing',\n",
       "  'mcfly',\n",
       "  'did',\n",
       "  'you',\n",
       "  'see',\n",
       "  'me',\n",
       "  'and',\n",
       "  'ma',\n",
       "  'best',\n",
       "  'mate',\n",
       "  'we',\n",
       "  'were',\n",
       "  'in',\n",
       "  'tutus'],\n",
       " ['days',\n",
       "  'without',\n",
       "  'sleep',\n",
       "  'and',\n",
       "  'now',\n",
       "  'a',\n",
       "  'migraine',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'life',\n",
       "  'was',\n",
       "  'meant',\n",
       "  'to',\n",
       "  'be',\n",
       "  'relaxing'],\n",
       " ['there'],\n",
       " ['sucks'],\n",
       " ['whens', 'the', 'sway', 'sway', 'winner', 'announced'],\n",
       " ['k', 'will', 'check', 'it', 'out'],\n",
       " ['doing', 'pretty', 'well', 'up', 'and', 'wide', 'awake'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'wake',\n",
       "  'up',\n",
       "  'early',\n",
       "  'and',\n",
       "  'get',\n",
       "  'a',\n",
       "  'coffee',\n",
       "  'tomorrow',\n",
       "  'today',\n",
       "  'its',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'busyy',\n",
       "  'day',\n",
       "  'but',\n",
       "  'have',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'writing',\n",
       "  'booo',\n",
       "  'whoo'],\n",
       " ['i', 'miss', 'daddy', 'and', 'mommy'],\n",
       " ['my',\n",
       "  'dog',\n",
       "  'is',\n",
       "  'officially',\n",
       "  'depressed',\n",
       "  'that',\n",
       "  'my',\n",
       "  'brothers',\n",
       "  'dogs',\n",
       "  'are',\n",
       "  'gone',\n",
       "  'he',\n",
       "  'doesnt',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'outside',\n",
       "  'and',\n",
       "  'when',\n",
       "  'we',\n",
       "  'did',\n",
       "  'he',\n",
       "  'play',\n",
       "  'halfheartedly'],\n",
       " ['i',\n",
       "  'just',\n",
       "  'realized',\n",
       "  'that',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'forward',\n",
       "  'text',\n",
       "  'msgs',\n",
       "  'with',\n",
       "  'my',\n",
       "  'iphone'],\n",
       " ['my',\n",
       "  'frist',\n",
       "  'post',\n",
       "  'off',\n",
       "  'to',\n",
       "  'find',\n",
       "  'a',\n",
       "  'new',\n",
       "  'car',\n",
       "  'for',\n",
       "  'my',\n",
       "  'parents',\n",
       "  'exciting'],\n",
       " ['argh',\n",
       "  'noo',\n",
       "  'missed',\n",
       "  'the',\n",
       "  'killers',\n",
       "  'on',\n",
       "  'wossy',\n",
       "  'that',\n",
       "  'sucks',\n",
       "  'missed',\n",
       "  'out',\n",
       "  'on',\n",
       "  'brandon',\n",
       "  'total',\n",
       "  'failure',\n",
       "  'anyone',\n",
       "  'know',\n",
       "  'if',\n",
       "  'its',\n",
       "  'repeated',\n",
       "  'must',\n",
       "  'investigate'],\n",
       " ['seriously',\n",
       "  'bored',\n",
       "  'without',\n",
       "  'anyone',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'but',\n",
       "  'not',\n",
       "  'tired',\n",
       "  'enough',\n",
       "  'for',\n",
       "  'sleep'],\n",
       " ['i', 'am', 'lost', 'please', 'help', 'me', 'find', 'a', 'good', 'home'],\n",
       " ['its',\n",
       "  'a',\n",
       "  'peter',\n",
       "  'gordon',\n",
       "  'morning',\n",
       "  'and',\n",
       "  'i',\n",
       "  'go',\n",
       "  'to',\n",
       "  'pieces',\n",
       "  'and',\n",
       "  'i',\n",
       "  'wanna',\n",
       "  'hide',\n",
       "  'go',\n",
       "  'to',\n",
       "  'pieces',\n",
       "  'and',\n",
       "  'i',\n",
       "  'almost',\n",
       "  'die',\n",
       "  'ever'],\n",
       " ['ok',\n",
       "  'so',\n",
       "  'ive',\n",
       "  'now',\n",
       "  'got',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'of',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'back',\n",
       "  'after',\n",
       "  'lifting',\n",
       "  'all',\n",
       "  'drum',\n",
       "  'hardware',\n",
       "  'into',\n",
       "  'my',\n",
       "  'car',\n",
       "  'downer'],\n",
       " ['lmao', 'smh', 'that', 'one', 'threw', 'me', 'off'],\n",
       " ['oh', 'nice', 'going'],\n",
       " ['is', 'getting', 'ready', 'for', 'work', 'working', 'all', 'weekend'],\n",
       " ['gonna',\n",
       "  'celebrate',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'with',\n",
       "  'the',\n",
       "  'family',\n",
       "  'but',\n",
       "  'gonna',\n",
       "  'start',\n",
       "  'the',\n",
       "  'partying',\n",
       "  'tonite'],\n",
       " ['i', 'agree', 'with', 'you'],\n",
       " ['i',\n",
       "  'only',\n",
       "  'do',\n",
       "  'computers',\n",
       "  'am',\n",
       "  'hopeless',\n",
       "  'at',\n",
       "  'everything',\n",
       "  'else'],\n",
       " ['degrees',\n",
       "  'gross',\n",
       "  'skies',\n",
       "  'and',\n",
       "  'thunderstormsperfect',\n",
       "  'match',\n",
       "  'for',\n",
       "  'my',\n",
       "  'mood',\n",
       "  'lol'],\n",
       " ['aww', 'thanks'],\n",
       " ['sorry', 'rb', 'is', 'on', 'for', 'me'],\n",
       " ['i', 'saw', 'amazing', 'heeels', 'but', 'they', 'were', 'too', 'big'],\n",
       " ['i',\n",
       "  'just',\n",
       "  'stuck',\n",
       "  'my',\n",
       "  'finger',\n",
       "  'down',\n",
       "  'my',\n",
       "  'throat',\n",
       "  'and',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'bumps',\n",
       "  'on',\n",
       "  'my',\n",
       "  'tongue',\n",
       "  'throat'],\n",
       " ['dang', 'last', 'url', 'went', 'down'],\n",
       " ['ohoh',\n",
       "  'i',\n",
       "  'missed',\n",
       "  'all',\n",
       "  'ur',\n",
       "  'tweets',\n",
       "  'im',\n",
       "  'gonna',\n",
       "  'have',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'awake',\n",
       "  'all',\n",
       "  'night',\n",
       "  'to',\n",
       "  'see',\n",
       "  'the',\n",
       "  'announcement',\n",
       "  'now',\n",
       "  'time',\n",
       "  'difference'],\n",
       " ['damnit',\n",
       "  'all',\n",
       "  'that',\n",
       "  'sucks',\n",
       "  'you',\n",
       "  'were',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'id',\n",
       "  'drag',\n",
       "  'back',\n",
       "  'lol'],\n",
       " ['my', 'boss', 'shes', 'moving', 'to', 'nyc'],\n",
       " ['this', 'is', 'sooo', 'crazy', 'i', 'have', 'fever'],\n",
       " ['is',\n",
       "  'spending',\n",
       "  'her',\n",
       "  'saturday',\n",
       "  'morning',\n",
       "  'taking',\n",
       "  'notes',\n",
       "  'for',\n",
       "  'a',\n",
       "  'research',\n",
       "  'essay',\n",
       "  'because',\n",
       "  'some',\n",
       "  'stupid',\n",
       "  'recalled',\n",
       "  'the',\n",
       "  'book',\n",
       "  'im',\n",
       "  'using',\n",
       "  'not',\n",
       "  'fair'],\n",
       " ['i', 'think', 'i', 'need', 'some', 'new', 'friends'],\n",
       " ['looking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'your',\n",
       "  'gig',\n",
       "  'in',\n",
       "  'ireland',\n",
       "  'see',\n",
       "  'ya',\n",
       "  'there'],\n",
       " ['please', 'review', 'sunehre', 'ad', 'placement'],\n",
       " ['aww', 'you', 'loooove', 'me'],\n",
       " ['is', 'hungry', 'twitter', 'i', 'want', 'food'],\n",
       " ['awesome', 'lucky', 'you'],\n",
       " ['yea',\n",
       "  'i',\n",
       "  'should',\n",
       "  'know',\n",
       "  'but',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'everything',\n",
       "  'ps',\n",
       "  'send',\n",
       "  'me',\n",
       "  'direct',\n",
       "  'messages',\n",
       "  'telling',\n",
       "  'haha'],\n",
       " ['haha', 'im', 'jewish', 'i', 'love', 'that', 'one'],\n",
       " ['had',\n",
       "  'a',\n",
       "  'great',\n",
       "  'time',\n",
       "  'out',\n",
       "  'in',\n",
       "  'the',\n",
       "  'beer',\n",
       "  'garden',\n",
       "  'wit',\n",
       "  'the',\n",
       "  'boyos',\n",
       "  'i',\n",
       "  'think',\n",
       "  'the',\n",
       "  'sun',\n",
       "  'got',\n",
       "  'to',\n",
       "  'me',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'though',\n",
       "  'feel',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'ill'],\n",
       " ['lm', 'on', 'days', 'too', 'matt', 'no', 'fun', 'this', 'weekend'],\n",
       " ['u',\n",
       "  'really',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'so',\n",
       "  'maybe',\n",
       "  'ur',\n",
       "  'rightlol',\n",
       "  'btw',\n",
       "  'what',\n",
       "  'phone',\n",
       "  'u',\n",
       "  'using',\n",
       "  'think',\n",
       "  'u',\n",
       "  'told',\n",
       "  'me',\n",
       "  'might',\n",
       "  'have',\n",
       "  'an',\n",
       "  'app',\n",
       "  'for',\n",
       "  'u'],\n",
       " ['i', 'feel', 'your', 'pain', 'mine', 'is', 'the', 'same', 'way'],\n",
       " ['comes', 'home', 'in', 'two', 'days'],\n",
       " ['sadly', 'no', 'it', 'didnt', 'come', 'with', 'one'],\n",
       " ['cant', 'wait', 'to', 'see', 'my', 'boy', 'tomorrow'],\n",
       " ['ehhh',\n",
       "  'no',\n",
       "  'just',\n",
       "  'a',\n",
       "  'check',\n",
       "  'up',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'dentist',\n",
       "  'app',\n",
       "  'next',\n",
       "  'week',\n",
       "  'though',\n",
       "  'getting',\n",
       "  'my',\n",
       "  'molar',\n",
       "  'pulledroot',\n",
       "  'canal'],\n",
       " ['aww', 'i', 'miss', 'driving', 'down', 'elmwood'],\n",
       " ['omg',\n",
       "  'wango',\n",
       "  'tango',\n",
       "  'was',\n",
       "  'awsome',\n",
       "  'i',\n",
       "  'love',\n",
       "  'my',\n",
       "  'baby',\n",
       "  'for',\n",
       "  'taking',\n",
       "  'me'],\n",
       " ['version',\n",
       "  'of',\n",
       "  'our',\n",
       "  'live',\n",
       "  'interactive',\n",
       "  'transsiberian',\n",
       "  'ticket',\n",
       "  'planner',\n",
       "  'is',\n",
       "  'launched',\n",
       "  'its',\n",
       "  'very',\n",
       "  'cool'],\n",
       " ['i', 'really', 'wish', 'i', 'could', 'go'],\n",
       " ['yeah',\n",
       "  'real',\n",
       "  'hard',\n",
       "  'but',\n",
       "  'i',\n",
       "  'know',\n",
       "  'youll',\n",
       "  'get',\n",
       "  'by',\n",
       "  'with',\n",
       "  'it',\n",
       "  'smile'],\n",
       " ['im',\n",
       "  'in',\n",
       "  'december',\n",
       "  'thats',\n",
       "  'not',\n",
       "  'good',\n",
       "  'at',\n",
       "  'all',\n",
       "  'next',\n",
       "  'big',\n",
       "  'birthday',\n",
       "  'is',\n",
       "  'after',\n",
       "  'it',\n",
       "  'flys',\n",
       "  'by',\n",
       "  'for',\n",
       "  'sure'],\n",
       " ['this', 'has', 'made', 'my', 'night', 'way', 'too', 'funny'],\n",
       " ['woo', 'cavs', 'happy', 'mothers', 'day'],\n",
       " ['i',\n",
       "  'make',\n",
       "  'that',\n",
       "  'same',\n",
       "  'face',\n",
       "  'when',\n",
       "  'i',\n",
       "  'get',\n",
       "  'home',\n",
       "  'and',\n",
       "  'your',\n",
       "  'mom',\n",
       "  'is',\n",
       "  'watching',\n",
       "  'soaps'],\n",
       " ['i', 'have', 'to', 'go', 'to', 'work', 'now'],\n",
       " ['i',\n",
       "  'cant',\n",
       "  'believe',\n",
       "  'you',\n",
       "  'went',\n",
       "  'and',\n",
       "  'got',\n",
       "  'boba',\n",
       "  'without',\n",
       "  'me'],\n",
       " ['and', 'to', 'you', 'too', 'how', 'are', 'you', 'today'],\n",
       " ['thanks',\n",
       "  'for',\n",
       "  'the',\n",
       "  'warm',\n",
       "  'welcome',\n",
       "  'we',\n",
       "  'didnt',\n",
       "  'make',\n",
       "  'plans',\n",
       "  'because',\n",
       "  'our',\n",
       "  'arrival',\n",
       "  'time',\n",
       "  'was',\n",
       "  'so',\n",
       "  'up',\n",
       "  'in',\n",
       "  'the',\n",
       "  'air'],\n",
       " ['days', 'and', 'counting'],\n",
       " ['sorry',\n",
       "  'friends',\n",
       "  'im',\n",
       "  'swamped',\n",
       "  'with',\n",
       "  'deadlines',\n",
       "  'right',\n",
       "  'now',\n",
       "  'and',\n",
       "  'we',\n",
       "  'have',\n",
       "  'family',\n",
       "  'visiting',\n",
       "  'to',\n",
       "  'boot',\n",
       "  'no',\n",
       "  'charades',\n",
       "  'for',\n",
       "  'me'],\n",
       " ['brainfreeze'],\n",
       " ['just',\n",
       "  'discovered',\n",
       "  'a',\n",
       "  'shortcoming',\n",
       "  'of',\n",
       "  'gravity',\n",
       "  'when',\n",
       "  'you',\n",
       "  'use',\n",
       "  'twitpic',\n",
       "  'integrated',\n",
       "  'it',\n",
       "  'doesnt',\n",
       "  'subtract',\n",
       "  'the',\n",
       "  'pic',\n",
       "  'url',\n",
       "  'from',\n",
       "  'the',\n",
       "  'character',\n",
       "  'limit'],\n",
       " ['my', 'sunburn', 'is', 'peeling'],\n",
       " ['perky',\n",
       "  'purple',\n",
       "  'nail',\n",
       "  'polish',\n",
       "  'isnt',\n",
       "  'as',\n",
       "  'perky',\n",
       "  'when',\n",
       "  'its',\n",
       "  'chipped'],\n",
       " ['before',\n",
       "  'they',\n",
       "  'put',\n",
       "  'a',\n",
       "  'camera',\n",
       "  'in',\n",
       "  'the',\n",
       "  'smokers',\n",
       "  'pit',\n",
       "  'i',\n",
       "  'can',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'vandalize',\n",
       "  'that',\n",
       "  'door',\n",
       "  'without',\n",
       "  'being',\n",
       "  'caught'],\n",
       " ['laying',\n",
       "  'alone',\n",
       "  'since',\n",
       "  'mooks',\n",
       "  'soo',\n",
       "  'comfy',\n",
       "  'in',\n",
       "  'his',\n",
       "  'fn',\n",
       "  'play',\n",
       "  'pen',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'it',\n",
       "  'was',\n",
       "  'ill',\n",
       "  'at',\n",
       "  'first',\n",
       "  'now',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'no',\n",
       "  'one',\n",
       "  'to',\n",
       "  'cuddle',\n",
       "  'with'],\n",
       " ['i', 'hate', 'the', 'dentist'],\n",
       " ['nothing', 'aimed', 'at', 'you', 'just', 'joining', 'insorry'],\n",
       " ['im', 'taking', 'a', 'twitter', 'break', 'cell', 'is', 'dying'],\n",
       " ['qood', 'morninq'],\n",
       " ['writing',\n",
       "  'my',\n",
       "  'english',\n",
       "  'original',\n",
       "  'writing',\n",
       "  'storyyyyy',\n",
       "  'and',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'a',\n",
       "  'little',\n",
       "  'respect',\n",
       "  'by',\n",
       "  'erasure',\n",
       "  'aaaaaah'],\n",
       " ['needs', 'more', 'followers'],\n",
       " ['i', 'wish', 'i', 'could', 'get', 'my', 'nails', 'done', 'stupid', 'job'],\n",
       " ['the',\n",
       "  'little',\n",
       "  'wormy',\n",
       "  'from',\n",
       "  'labyrinth',\n",
       "  'sadly',\n",
       "  'passed',\n",
       "  'away',\n",
       "  'today',\n",
       "  'but',\n",
       "  'its',\n",
       "  'ok',\n",
       "  'as',\n",
       "  'hes',\n",
       "  'still',\n",
       "  'around',\n",
       "  'in',\n",
       "  'a',\n",
       "  'happy',\n",
       "  'ghost',\n",
       "  'form',\n",
       "  'aww'],\n",
       " ['the',\n",
       "  'no',\n",
       "  'pants',\n",
       "  'idea',\n",
       "  'could',\n",
       "  'be',\n",
       "  'the',\n",
       "  'new',\n",
       "  'attempt',\n",
       "  'worldwide',\n",
       "  'to',\n",
       "  'attract',\n",
       "  'business',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'airlines'],\n",
       " ['have', 'a', 'good', 'one'],\n",
       " ['yep',\n",
       "  'infact',\n",
       "  'she',\n",
       "  'is',\n",
       "  'popular',\n",
       "  'miss',\n",
       "  'india',\n",
       "  'talented',\n",
       "  'film',\n",
       "  'actress',\n",
       "  'and',\n",
       "  'lot',\n",
       "  'more'],\n",
       " ['dosent', 'want', 'to', 'go', 'to', 'work', 'tomorrow'],\n",
       " ['daniel', 'has', 'won', 'dsds', 'his', 'voice', 'is', 'great'],\n",
       " ['i',\n",
       "  'wish',\n",
       "  'the',\n",
       "  'birthday',\n",
       "  'massacre',\n",
       "  'would',\n",
       "  'come',\n",
       "  'to',\n",
       "  'australia',\n",
       "  'i',\n",
       "  'think',\n",
       "  'they',\n",
       "  'said',\n",
       "  'theyre',\n",
       "  'thinking',\n",
       "  'about',\n",
       "  'it',\n",
       "  'tho'],\n",
       " ['was', 'hoping', 'to', 'go', 'to', 'red', 'lobster', 'this', 'weekend'],\n",
       " ['xatl',\n",
       "  'u',\n",
       "  'mean',\n",
       "  'jack',\n",
       "  'barakats',\n",
       "  'wow',\n",
       "  'so',\n",
       "  'have',\n",
       "  'u',\n",
       "  'ever',\n",
       "  'gone',\n",
       "  'to',\n",
       "  'his',\n",
       "  'house',\n",
       "  'hehe',\n",
       "  'i',\n",
       "  'mean',\n",
       "  'ur',\n",
       "  'ssoo',\n",
       "  'lucky',\n",
       "  'to',\n",
       "  'have',\n",
       "  'the',\n",
       "  'address'],\n",
       " ['i', 'sure', 'do', 'hope', 'it', 'becomes', 'this', 'afternoon'],\n",
       " ['it', 'means', 'that', 'you', 'are', 'now', 'famous', 'congrats'],\n",
       " ['my',\n",
       "  'phone',\n",
       "  'passed',\n",
       "  'away',\n",
       "  'yesterday',\n",
       "  'he',\n",
       "  'jumped',\n",
       "  'off',\n",
       "  'the',\n",
       "  'table',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'phone'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'such',\n",
       "  'fantastic',\n",
       "  'friends',\n",
       "  'including',\n",
       "  'several',\n",
       "  'ones',\n",
       "  'met',\n",
       "  'through',\n",
       "  'here',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'being',\n",
       "  'in',\n",
       "  'my',\n",
       "  'life',\n",
       "  'you',\n",
       "  'are',\n",
       "  'such',\n",
       "  'amazing',\n",
       "  'people'],\n",
       " ['tamlyn', 'wishes', 'she', 'was', 'as', 'cool', 'as', 'my', 'sock', 'draw'],\n",
       " ['so',\n",
       "  'no',\n",
       "  'rice',\n",
       "  'or',\n",
       "  'crusty',\n",
       "  'bread',\n",
       "  'with',\n",
       "  'the',\n",
       "  'chili',\n",
       "  'aawww'],\n",
       " ['we', 'are', 'of', 'like', 'minds', 'this', 'evening', 'my', 'dear'],\n",
       " ['come', 'and', 'save', 'me', 'from', 'my', 'packing', 'please'],\n",
       " ['yes',\n",
       "  'i',\n",
       "  'love',\n",
       "  'tea',\n",
       "  'if',\n",
       "  'that',\n",
       "  'makes',\n",
       "  'me',\n",
       "  'typically',\n",
       "  'english',\n",
       "  'then',\n",
       "  'so',\n",
       "  'be',\n",
       "  'it'],\n",
       " ['a', 'mouth', 'for', 'sure'],\n",
       " ['i',\n",
       "  'finally',\n",
       "  'just',\n",
       "  'have',\n",
       "  'hour',\n",
       "  'of',\n",
       "  'history',\n",
       "  'at',\n",
       "  'pm',\n",
       "  'but',\n",
       "  'i',\n",
       "  'went',\n",
       "  'to',\n",
       "  'my',\n",
       "  'highschool',\n",
       "  'at',\n",
       "  'am',\n",
       "  'to',\n",
       "  'make',\n",
       "  'some',\n",
       "  'homework',\n",
       "  'with',\n",
       "  'a',\n",
       "  'friend'],\n",
       " ['pancakes', 'with', 'lemon', 'and', 'sugar', 'thanks'],\n",
       " ['si', 'no', 'bueno', 'i', 'guess', 'i', 'just', 'dont', 'entertain', 'him'],\n",
       " ['im',\n",
       "  'so',\n",
       "  'hunrgy',\n",
       "  'right',\n",
       "  'now',\n",
       "  'and',\n",
       "  'these',\n",
       "  'heels',\n",
       "  'kill',\n",
       "  'me',\n",
       "  'i',\n",
       "  'can',\n",
       "  'hardly',\n",
       "  'walk',\n",
       "  'in',\n",
       "  'them'],\n",
       " ['both',\n",
       "  'electronic',\n",
       "  'keys',\n",
       "  'stopped',\n",
       "  'working',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'keyhole',\n",
       "  'cant',\n",
       "  'get',\n",
       "  'in',\n",
       "  'my',\n",
       "  'car',\n",
       "  'so',\n",
       "  'much',\n",
       "  'for',\n",
       "  'technology'],\n",
       " ['yay',\n",
       "  'three',\n",
       "  'followers',\n",
       "  'good',\n",
       "  'to',\n",
       "  'know',\n",
       "  'more',\n",
       "  'than',\n",
       "  'one',\n",
       "  'person',\n",
       "  'in',\n",
       "  'this',\n",
       "  'big',\n",
       "  'wide',\n",
       "  'world',\n",
       "  'likes',\n",
       "  'fishies'],\n",
       " ['my', 'name', 'is', 'tony', 'not', 'hey', 'poor', 'tony'],\n",
       " ['goodmorning'],\n",
       " ['took',\n",
       "  'a',\n",
       "  'shift',\n",
       "  'tomorrow',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'really',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'working',\n",
       "  'right',\n",
       "  'now'],\n",
       " ['i',\n",
       "  'love',\n",
       "  'mine',\n",
       "  'too',\n",
       "  'happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'to',\n",
       "  'your',\n",
       "  'mom',\n",
       "  'john',\n",
       "  'taylor',\n",
       "  'much',\n",
       "  'love',\n",
       "  'to',\n",
       "  'you',\n",
       "  'too'],\n",
       " ['saw',\n",
       "  'a',\n",
       "  'black',\n",
       "  'snake',\n",
       "  'in',\n",
       "  'the',\n",
       "  'garden',\n",
       "  'went',\n",
       "  'back',\n",
       "  'for',\n",
       "  'a',\n",
       "  'picture',\n",
       "  'and',\n",
       "  'it',\n",
       "  'was',\n",
       "  'gone'],\n",
       " ['we', 'bought', 'ludi', 'her', 'own', 'rug', 'dogs', 'are', 'the', 'best'],\n",
       " ['no',\n",
       "  'waterfront',\n",
       "  'anymore',\n",
       "  'faccia',\n",
       "  'luna',\n",
       "  'and',\n",
       "  'clarendon',\n",
       "  'will',\n",
       "  'have',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['loves',\n",
       "  'her',\n",
       "  'mum',\n",
       "  'very',\n",
       "  'much',\n",
       "  'happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'to',\n",
       "  'all',\n",
       "  'the',\n",
       "  'wonderful',\n",
       "  'mothers',\n",
       "  'out',\n",
       "  'there'],\n",
       " ['slipped', 'up', 'and', 'caught', 'the', 'flu', 'feeling', 'like', 'poop'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'an',\n",
       "  'urge',\n",
       "  'to',\n",
       "  'play',\n",
       "  'wow',\n",
       "  'but',\n",
       "  'i',\n",
       "  'have',\n",
       "  'to',\n",
       "  'wait',\n",
       "  'weeks',\n",
       "  'til',\n",
       "  'im',\n",
       "  'at',\n",
       "  'my',\n",
       "  'dads',\n",
       "  'til',\n",
       "  'mcfly',\n",
       "  'im',\n",
       "  'so',\n",
       "  'excited',\n",
       "  'l'],\n",
       " ['ok',\n",
       "  'the',\n",
       "  'passengers',\n",
       "  'no',\n",
       "  'one',\n",
       "  'is',\n",
       "  'alive',\n",
       "  'theyre',\n",
       "  'all',\n",
       "  'dead',\n",
       "  'you',\n",
       "  'just',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'it',\n",
       "  'til',\n",
       "  'the',\n",
       "  'end',\n",
       "  'then',\n",
       "  'you',\n",
       "  'cry'],\n",
       " ['discovered',\n",
       "  'and',\n",
       "  'are',\n",
       "  'sharing',\n",
       "  'on',\n",
       "  'g',\n",
       "  'reader',\n",
       "  'with',\n",
       "  'me',\n",
       "  'and',\n",
       "  'didnt',\n",
       "  'even',\n",
       "  'know',\n",
       "  'it',\n",
       "  'sigh',\n",
       "  'im',\n",
       "  'such',\n",
       "  'a',\n",
       "  'g',\n",
       "  'reader',\n",
       "  'newb'],\n",
       " ['is',\n",
       "  'chilled',\n",
       "  'out',\n",
       "  'tonite',\n",
       "  'so',\n",
       "  'cannot',\n",
       "  'spew',\n",
       "  'venom',\n",
       "  'or',\n",
       "  'write',\n",
       "  'funny',\n",
       "  'seems',\n",
       "  'like',\n",
       "  'these',\n",
       "  'are',\n",
       "  'the',\n",
       "  'only',\n",
       "  'styles',\n",
       "  'she',\n",
       "  'has'],\n",
       " ['if', 'u', 'do', 'please', 'pray', 'me', 'lord', 'knows', 'i', 'need', 'it'],\n",
       " ['aaaaaw', 'i', 'want', 'to', 'live', 'in', 'the', 'usa'],\n",
       " ['morning', 'tweeple'],\n",
       " ['hey', 'i', 'didnt', 'get', 'any'],\n",
       " ['now',\n",
       "  'you',\n",
       "  'only',\n",
       "  'have',\n",
       "  'hours',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'rest',\n",
       "  'if',\n",
       "  'you',\n",
       "  'need',\n",
       "  'it'],\n",
       " ['that',\n",
       "  'makes',\n",
       "  'my',\n",
       "  'day',\n",
       "  'so',\n",
       "  'much',\n",
       "  'better',\n",
       "  'its',\n",
       "  'been',\n",
       "  'a',\n",
       "  'rough',\n",
       "  'one',\n",
       "  'did',\n",
       "  'i',\n",
       "  'mention',\n",
       "  'i',\n",
       "  'love',\n",
       "  'the',\n",
       "  'new',\n",
       "  'photo'],\n",
       " ['i',\n",
       "  'dont',\n",
       "  'want',\n",
       "  'to',\n",
       "  'sit',\n",
       "  'at',\n",
       "  'home',\n",
       "  'on',\n",
       "  'prom',\n",
       "  'night',\n",
       "  'someone',\n",
       "  'hang',\n",
       "  'out',\n",
       "  'with',\n",
       "  'me'],\n",
       " ['is',\n",
       "  'heading',\n",
       "  'home',\n",
       "  'from',\n",
       "  'foot',\n",
       "  'surgery',\n",
       "  'and',\n",
       "  'wishing',\n",
       "  'she',\n",
       "  'had',\n",
       "  'a',\n",
       "  'boyfriend',\n",
       "  'to',\n",
       "  'come',\n",
       "  'over',\n",
       "  'and',\n",
       "  'cuddle',\n",
       "  'with'],\n",
       " ['concert', 'tonight', 'chackin', 'out', 'and', 'not', 'coming', 'tomorrow'],\n",
       " ['what',\n",
       "  'happened',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'you',\n",
       "  'were',\n",
       "  'coming',\n",
       "  'back',\n",
       "  'today'],\n",
       " ['lol', 'dammit', 'well', 'then', 'next', 'time', 'then'],\n",
       " ['lol', 'just', 'dont', 'ever', 'forget', 'me'],\n",
       " ['still', 'jealous'],\n",
       " ['me', 'at', 'forever', 'ethan', 'couldnt', 'be', 'there'],\n",
       " ['now',\n",
       "  'im',\n",
       "  'sad',\n",
       "  'but',\n",
       "  'im',\n",
       "  'not',\n",
       "  'giving',\n",
       "  'in',\n",
       "  'firsti',\n",
       "  'didnt',\n",
       "  'do',\n",
       "  'nothing'],\n",
       " ['this',\n",
       "  'week',\n",
       "  'of',\n",
       "  'mine',\n",
       "  'was',\n",
       "  'not',\n",
       "  'easy',\n",
       "  'but',\n",
       "  'finally',\n",
       "  'its',\n",
       "  'over'],\n",
       " ['wow',\n",
       "  'what',\n",
       "  'a',\n",
       "  'beautiful',\n",
       "  'picture',\n",
       "  'and',\n",
       "  'by',\n",
       "  'the',\n",
       "  'wayi',\n",
       "  'am',\n",
       "  'straightjust',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'let',\n",
       "  'you',\n",
       "  'know',\n",
       "  'bella'],\n",
       " ['in',\n",
       "  'arch',\n",
       "  'drawing',\n",
       "  'checking',\n",
       "  'out',\n",
       "  'mvccs',\n",
       "  'cad',\n",
       "  'degree',\n",
       "  'looks',\n",
       "  'good',\n",
       "  'to',\n",
       "  'me'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'people',\n",
       "  'and',\n",
       "  'then',\n",
       "  'there',\n",
       "  'are',\n",
       "  'pencils',\n",
       "  'some',\n",
       "  'are',\n",
       "  'sharp',\n",
       "  'some',\n",
       "  'are',\n",
       "  'not',\n",
       "  'and',\n",
       "  'some',\n",
       "  'can',\n",
       "  'be',\n",
       "  'sharpened',\n",
       "  'my',\n",
       "  'pencil',\n",
       "  'philosophy'],\n",
       " ['just',\n",
       "  'about',\n",
       "  'to',\n",
       "  'go',\n",
       "  'home',\n",
       "  'im',\n",
       "  'usually',\n",
       "  'mr',\n",
       "  'positive',\n",
       "  'but',\n",
       "  'this',\n",
       "  'has',\n",
       "  'been',\n",
       "  'one',\n",
       "  'of',\n",
       "  'those',\n",
       "  'daze',\n",
       "  'well',\n",
       "  'mins',\n",
       "  'until',\n",
       "  'tomorrow'],\n",
       " ['but', 'you', 'always', 'have', 'lee', 'lets', 'go', 'to', 'paris'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'come',\n",
       "  'keep',\n",
       "  'me',\n",
       "  'company',\n",
       "  'whilst',\n",
       "  'mums',\n",
       "  'at',\n",
       "  'her',\n",
       "  'friends',\n",
       "  'for',\n",
       "  'the',\n",
       "  'night',\n",
       "  'its',\n",
       "  'such',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'evening'],\n",
       " ['cooking',\n",
       "  'with',\n",
       "  'my',\n",
       "  'dad',\n",
       "  'having',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'fun',\n",
       "  'in',\n",
       "  'the',\n",
       "  'kitchen',\n",
       "  'together'],\n",
       " ['bouncing', 'rush', 'makes', 'me', 'feel', 'nauseous'],\n",
       " ['off',\n",
       "  'to',\n",
       "  'woolsery',\n",
       "  'this',\n",
       "  'morning',\n",
       "  'to',\n",
       "  'hopefully',\n",
       "  'see',\n",
       "  'north',\n",
       "  'molton',\n",
       "  'clinch',\n",
       "  'the',\n",
       "  'north',\n",
       "  'devon',\n",
       "  'league',\n",
       "  'title',\n",
       "  'lovely',\n",
       "  'day',\n",
       "  'for',\n",
       "  'it'],\n",
       " ['playing', 'singstar', 'without', 'my', 'fave', 'duetter'],\n",
       " ['youre',\n",
       "  'missing',\n",
       "  'out',\n",
       "  'bb',\n",
       "  'im',\n",
       "  'such',\n",
       "  'a',\n",
       "  'cereal',\n",
       "  'nut',\n",
       "  'i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'like',\n",
       "  'every',\n",
       "  'kind',\n",
       "  'available'],\n",
       " ['thats',\n",
       "  'just',\n",
       "  'weird',\n",
       "  'oh',\n",
       "  'and',\n",
       "  'what',\n",
       "  'was',\n",
       "  'it',\n",
       "  'you',\n",
       "  'were',\n",
       "  'drawing',\n",
       "  'for',\n",
       "  'me'],\n",
       " ['just',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'o',\n",
       "  'mums',\n",
       "  'singing',\n",
       "  'to',\n",
       "  'her',\n",
       "  'new',\n",
       "  'gnr',\n",
       "  'cd',\n",
       "  'replacement',\n",
       "  'i',\n",
       "  'bought',\n",
       "  'because',\n",
       "  'im',\n",
       "  'a',\n",
       "  'good',\n",
       "  'daughter'],\n",
       " ['the',\n",
       "  'birds',\n",
       "  'are',\n",
       "  'out',\n",
       "  'oh',\n",
       "  'man',\n",
       "  'thats',\n",
       "  'not',\n",
       "  'cool',\n",
       "  'i',\n",
       "  'didnt',\n",
       "  'sleep',\n",
       "  'yet',\n",
       "  'for',\n",
       "  'the',\n",
       "  'night'],\n",
       " ['miles',\n",
       "  'down',\n",
       "  'only',\n",
       "  'to',\n",
       "  'go',\n",
       "  'thats',\n",
       "  'ok',\n",
       "  'on',\n",
       "  'the',\n",
       "  'radio',\n",
       "  'alwas',\n",
       "  'helps'],\n",
       " ['my',\n",
       "  'street',\n",
       "  'fighter',\n",
       "  'iv',\n",
       "  'skills',\n",
       "  'are',\n",
       "  'lacking',\n",
       "  'cant',\n",
       "  'beat',\n",
       "  'seth',\n",
       "  'on',\n",
       "  'easy'],\n",
       " ['fil', 'with', 'cool', 'people', 'like', 'me'],\n",
       " ['good',\n",
       "  'morning',\n",
       "  'work',\n",
       "  'and',\n",
       "  'then',\n",
       "  'its',\n",
       "  'espns',\n",
       "  'sunday',\n",
       "  'night',\n",
       "  'baseball',\n",
       "  'hopefully',\n",
       "  'it',\n",
       "  'wont',\n",
       "  'get',\n",
       "  'rained',\n",
       "  'out'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'its',\n",
       "  'under',\n",
       "  'a',\n",
       "  'honeymoon',\n",
       "  'by',\n",
       "  'the',\n",
       "  'good',\n",
       "  'life',\n",
       "  'either',\n",
       "  'that',\n",
       "  'or',\n",
       "  'its',\n",
       "  'under',\n",
       "  'a',\n",
       "  'honey',\n",
       "  'moon',\n",
       "  'by',\n",
       "  'joseph',\n",
       "  'arthur'],\n",
       " ['my',\n",
       "  'son',\n",
       "  'got',\n",
       "  'stung',\n",
       "  'by',\n",
       "  'a',\n",
       "  'bug',\n",
       "  'for',\n",
       "  'the',\n",
       "  'first',\n",
       "  'time',\n",
       "  'his',\n",
       "  'little',\n",
       "  'finger',\n",
       "  'is',\n",
       "  'slightly',\n",
       "  'swollen'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'hours',\n",
       "  'ago',\n",
       "  'i',\n",
       "  'came',\n",
       "  'in',\n",
       "  'and',\n",
       "  'its',\n",
       "  'only',\n",
       "  'now',\n",
       "  'i',\n",
       "  'realised',\n",
       "  'when',\n",
       "  'i',\n",
       "  'went',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'something',\n",
       "  'online'],\n",
       " ['oh',\n",
       "  'just',\n",
       "  'referring',\n",
       "  'to',\n",
       "  'our',\n",
       "  'lil',\n",
       "  'exchange',\n",
       "  'on',\n",
       "  'lj',\n",
       "  'with',\n",
       "  'regards',\n",
       "  'to',\n",
       "  'twitter',\n",
       "  'archive',\n",
       "  'postings'],\n",
       " ['bumping',\n",
       "  'dj',\n",
       "  'opus',\n",
       "  'in',\n",
       "  'the',\n",
       "  'drunk',\n",
       "  'in',\n",
       "  'the',\n",
       "  'car',\n",
       "  'lmao',\n",
       "  'dont',\n",
       "  'act',\n",
       "  'like',\n",
       "  'u',\n",
       "  'dont',\n",
       "  'know'],\n",
       " ['why',\n",
       "  'kiss',\n",
       "  'the',\n",
       "  'feet',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  'who',\n",
       "  'kick',\n",
       "  'you',\n",
       "  'when',\n",
       "  'you',\n",
       "  'can',\n",
       "  'be',\n",
       "  'anything',\n",
       "  'that',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'morning',\n",
       "  'everyone',\n",
       "  'hope',\n",
       "  'you',\n",
       "  'have',\n",
       "  'the',\n",
       "  'best',\n",
       "  'day',\n",
       "  'ever'],\n",
       " ['heres',\n",
       "  'a',\n",
       "  'brief',\n",
       "  'preview',\n",
       "  'omg',\n",
       "  'james',\n",
       "  'is',\n",
       "  'creepy',\n",
       "  'in',\n",
       "  'that',\n",
       "  'role',\n",
       "  'im',\n",
       "  'scared',\n",
       "  'of',\n",
       "  'him'],\n",
       " ['im',\n",
       "  'missing',\n",
       "  'crab',\n",
       "  'legs',\n",
       "  'and',\n",
       "  'attending',\n",
       "  'my',\n",
       "  'going',\n",
       "  'away',\n",
       "  'instead'],\n",
       " ['hicks', 'are', 'mean'],\n",
       " ['gettn',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'take',\n",
       "  'a',\n",
       "  'trip',\n",
       "  'to',\n",
       "  'jersey',\n",
       "  'my',\n",
       "  'dads',\n",
       "  'not',\n",
       "  'doing',\n",
       "  'so',\n",
       "  'good',\n",
       "  'he',\n",
       "  'needs',\n",
       "  'a',\n",
       "  'new',\n",
       "  'heartwhoeva',\n",
       "  'sees',\n",
       "  'this',\n",
       "  'please',\n",
       "  'say',\n",
       "  'a',\n",
       "  'prayer',\n",
       "  'for',\n",
       "  'my',\n",
       "  'dad'],\n",
       " ['back',\n",
       "  'soon',\n",
       "  'need',\n",
       "  'to',\n",
       "  'run',\n",
       "  'to',\n",
       "  'the',\n",
       "  'shops',\n",
       "  'and',\n",
       "  'cut',\n",
       "  'the',\n",
       "  'grass'],\n",
       " ['im',\n",
       "  'up',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'plan',\n",
       "  'to',\n",
       "  'transform',\n",
       "  'my',\n",
       "  'bedroom',\n",
       "  'today',\n",
       "  'random'],\n",
       " ['home',\n",
       "  'until',\n",
       "  'tomorrow',\n",
       "  'did',\n",
       "  'my',\n",
       "  'running',\n",
       "  'and',\n",
       "  'spinning',\n",
       "  'now',\n",
       "  'time',\n",
       "  'for',\n",
       "  'chiropractor',\n",
       "  'laundry',\n",
       "  'shopping',\n",
       "  'and',\n",
       "  'visiting',\n",
       "  'family',\n",
       "  'missing',\n",
       "  'nathan'],\n",
       " ['thats', 'another', 'sponsor'],\n",
       " ['and',\n",
       "  'most',\n",
       "  'of',\n",
       "  'us',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'stuck',\n",
       "  'in',\n",
       "  'an',\n",
       "  'office',\n",
       "  'some',\n",
       "  'without',\n",
       "  'windows'],\n",
       " ['no', 'its', 'not', 'sad', 'should', 'make', 'you', 'proud'],\n",
       " ['sorry', 'well', 'try', 'to', 'keep', 'it', 'down'],\n",
       " ['is', 'home', 'alone', 'doing', 'hw'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'a',\n",
       "  'quarter',\n",
       "  'of',\n",
       "  'families',\n",
       "  'under',\n",
       "  'six',\n",
       "  'live',\n",
       "  'in',\n",
       "  'poverty'],\n",
       " ['the', 'plan', 'to', 'not', 'spend', 'money', 'is', 'not', 'going', 'well'],\n",
       " ['uploading', 'all', 'my', 'bamboozle', 'pictures', 'of', 'facebook'],\n",
       " ['congratulations',\n",
       "  'you',\n",
       "  'guys',\n",
       "  'finish',\n",
       "  'a',\n",
       "  'month',\n",
       "  'early',\n",
       "  'than',\n",
       "  'we',\n",
       "  'do',\n",
       "  'booo'],\n",
       " ['actually',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'was',\n",
       "  'back',\n",
       "  'in',\n",
       "  'tahoe',\n",
       "  'i',\n",
       "  'miss',\n",
       "  'it',\n",
       "  'there'],\n",
       " ['woke', 'upi', 'wanna', 'stay', 'in', 'my', 'bed'],\n",
       " ['but',\n",
       "  'my',\n",
       "  'bday',\n",
       "  'is',\n",
       "  'june',\n",
       "  'this',\n",
       "  'is',\n",
       "  'wack',\n",
       "  'and',\n",
       "  'ihavent',\n",
       "  'seen',\n",
       "  'any',\n",
       "  'promotions',\n",
       "  'for',\n",
       "  'my',\n",
       "  'bday',\n",
       "  'party',\n",
       "  'someone',\n",
       "  'better',\n",
       "  'finagle',\n",
       "  'this',\n",
       "  'asap'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'great',\n",
       "  'if',\n",
       "  'those',\n",
       "  'vips',\n",
       "  'were',\n",
       "  'for',\n",
       "  'some',\n",
       "  'acts',\n",
       "  'id',\n",
       "  'enjoy',\n",
       "  'seeing',\n",
       "  'but',\n",
       "  'noooo'],\n",
       " ['marie',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'could',\n",
       "  'make',\n",
       "  'it',\n",
       "  'too',\n",
       "  'i',\n",
       "  'hate',\n",
       "  'my',\n",
       "  'commute',\n",
       "  'sometimes'],\n",
       " ['workin',\n",
       "  'a',\n",
       "  'long',\n",
       "  'day',\n",
       "  'today',\n",
       "  'hopefully',\n",
       "  'i',\n",
       "  'can',\n",
       "  'make',\n",
       "  'some',\n",
       "  'good',\n",
       "  'tips'],\n",
       " ['but',\n",
       "  'it',\n",
       "  'all',\n",
       "  'went',\n",
       "  'too',\n",
       "  'quick',\n",
       "  'and',\n",
       "  'there',\n",
       "  'wasnt',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'lol'],\n",
       " ['hates', 'headaches', 'maybe', 'im', 'not', 'ready', 'to', 'rock'],\n",
       " ['thanks', 'for', 'the', 'support'],\n",
       " ['theres',\n",
       "  'really',\n",
       "  'no',\n",
       "  'android',\n",
       "  'twitter',\n",
       "  'app',\n",
       "  'of',\n",
       "  'tweeties',\n",
       "  'calibre'],\n",
       " ['had',\n",
       "  'a',\n",
       "  'good',\n",
       "  'day',\n",
       "  'driving',\n",
       "  'up',\n",
       "  'mountains',\n",
       "  'visiting',\n",
       "  'katie',\n",
       "  'eating',\n",
       "  'chips',\n",
       "  'fudge',\n",
       "  'and',\n",
       "  'stocking',\n",
       "  'up',\n",
       "  'on',\n",
       "  'lovely',\n",
       "  'smelling',\n",
       "  'soaps'],\n",
       " ['nyappy', 'mothers', 'day', 'to', 'your', 'moms'],\n",
       " ['yeah',\n",
       "  'and',\n",
       "  'im',\n",
       "  'gonna',\n",
       "  'take',\n",
       "  'ur',\n",
       "  'picture',\n",
       "  'off',\n",
       "  'my',\n",
       "  'ipod',\n",
       "  'baby'],\n",
       " ['traumatizing',\n",
       "  'moment',\n",
       "  'of',\n",
       "  'my',\n",
       "  'childhood',\n",
       "  'my',\n",
       "  'dogs',\n",
       "  'massacred',\n",
       "  'baby',\n",
       "  'bunnies',\n",
       "  'and',\n",
       "  'my',\n",
       "  'brother',\n",
       "  'and',\n",
       "  'i',\n",
       "  'got',\n",
       "  'out',\n",
       "  'the',\n",
       "  'bb',\n",
       "  'gun'],\n",
       " ['lol',\n",
       "  'same',\n",
       "  'herewish',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'microsize',\n",
       "  'everythinglol'],\n",
       " ['organization',\n",
       "  'itil',\n",
       "  'forget',\n",
       "  'about',\n",
       "  'people',\n",
       "  'and',\n",
       "  'so',\n",
       "  'they',\n",
       "  'fail',\n",
       "  'preaching',\n",
       "  'to',\n",
       "  'the',\n",
       "  'converted',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'people'],\n",
       " ['libertine', 'um', 'glad', 'you', 'enjoyed', 'it'],\n",
       " ['about',\n",
       "  'to',\n",
       "  'have',\n",
       "  'dinner',\n",
       "  'and',\n",
       "  'then',\n",
       "  'an',\n",
       "  'evening',\n",
       "  'of',\n",
       "  'playing',\n",
       "  'cards',\n",
       "  'already',\n",
       "  'packed',\n",
       "  'and',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'head',\n",
       "  'home',\n",
       "  'tomorrow',\n",
       "  'do',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'go',\n",
       "  'home'],\n",
       " ['im',\n",
       "  'allergic',\n",
       "  'to',\n",
       "  'cats',\n",
       "  'my',\n",
       "  'tonsils',\n",
       "  'get',\n",
       "  'swollen',\n",
       "  'and',\n",
       "  'they',\n",
       "  'hurt',\n",
       "  'what',\n",
       "  'do',\n",
       "  'i',\n",
       "  'dooo'],\n",
       " ['he',\n",
       "  'says',\n",
       "  'he',\n",
       "  'feels',\n",
       "  'mama',\n",
       "  'tucking',\n",
       "  'him',\n",
       "  'in',\n",
       "  'at',\n",
       "  'night',\n",
       "  'hes',\n",
       "  'lonely',\n",
       "  'but',\n",
       "  'getting',\n",
       "  'by',\n",
       "  'tomorrow',\n",
       "  'will',\n",
       "  'be',\n",
       "  'tough'],\n",
       " ['i', 'miss', 'her', 'alot', 'and', 'its', 'only', 'been', 'one', 'day'],\n",
       " ['sounds',\n",
       "  'like',\n",
       "  'you',\n",
       "  'all',\n",
       "  'had',\n",
       "  'a',\n",
       "  'great',\n",
       "  'night',\n",
       "  'im',\n",
       "  'glad',\n",
       "  'it',\n",
       "  'was',\n",
       "  'successful'],\n",
       " ['thanks', 'for', 'sharing', 'that'],\n",
       " ['you',\n",
       "  'should',\n",
       "  'say',\n",
       "  'mlia',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'fml',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'you',\n",
       "  'find',\n",
       "  'it',\n",
       "  'soon'],\n",
       " ['garden',\n",
       "  'going',\n",
       "  'well',\n",
       "  'almost',\n",
       "  'all',\n",
       "  'the',\n",
       "  'corn',\n",
       "  'and',\n",
       "  'peas',\n",
       "  'are',\n",
       "  'up',\n",
       "  'no',\n",
       "  'onions',\n",
       "  'or',\n",
       "  'beets',\n",
       "  'up',\n",
       "  'yet',\n",
       "  'though'],\n",
       " ['nah', 'jkin', 'hes', 'hot', 'so', 'bored', 'now'],\n",
       " ['ahhh',\n",
       "  'im',\n",
       "  'sqeaky',\n",
       "  'clean',\n",
       "  'and',\n",
       "  'fresh',\n",
       "  'even',\n",
       "  'though',\n",
       "  'im',\n",
       "  'wearing',\n",
       "  'dirty',\n",
       "  'clothes',\n",
       "  'i',\n",
       "  'love',\n",
       "  'two',\n",
       "  'and',\n",
       "  'a',\n",
       "  'half',\n",
       "  'men',\n",
       "  'its',\n",
       "  'amazing'],\n",
       " ['yes', 'i', 'have', 'read', 'them', 'many', 'times'],\n",
       " ['cuz', 'you', 'play', 'a', 'grown', 'up', 'on', 'twitter'],\n",
       " ['i', 'am', 'living', 'in', 'ignorance'],\n",
       " ['nope',\n",
       "  'it',\n",
       "  'is',\n",
       "  'telling',\n",
       "  'you',\n",
       "  'that',\n",
       "  'you',\n",
       "  'want',\n",
       "  'cameo',\n",
       "  'creams'],\n",
       " ['awwww', 'were', 'gonna', 'miss', 'you'],\n",
       " ['we',\n",
       "  'quite',\n",
       "  'like',\n",
       "  'worthing',\n",
       "  'its',\n",
       "  'a',\n",
       "  'relaxing',\n",
       "  'place',\n",
       "  'with',\n",
       "  'nice',\n",
       "  'coffee',\n",
       "  'shops',\n",
       "  'and',\n",
       "  'fresh',\n",
       "  'air',\n",
       "  'and',\n",
       "  'not',\n",
       "  'too',\n",
       "  'many',\n",
       "  'oiks'],\n",
       " ['terrible',\n",
       "  'haha',\n",
       "  'that',\n",
       "  'was',\n",
       "  'new',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'he',\n",
       "  'couldnt',\n",
       "  'do',\n",
       "  'it',\n",
       "  'should',\n",
       "  'have',\n",
       "  'cost',\n",
       "  'his',\n",
       "  'part',\n",
       "  'what',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'spock',\n",
       "  'is',\n",
       "  'that'],\n",
       " ['today',\n",
       "  'was',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'day',\n",
       "  'i',\n",
       "  'had',\n",
       "  'fun',\n",
       "  'with',\n",
       "  'and',\n",
       "  'this',\n",
       "  'evening'],\n",
       " ['betos',\n",
       "  'pizzeria',\n",
       "  'is',\n",
       "  'on',\n",
       "  'banksville',\n",
       "  'rd',\n",
       "  'in',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'the',\n",
       "  'beachview',\n",
       "  'area',\n",
       "  'sorry',\n",
       "  'to',\n",
       "  'answer',\n",
       "  'like',\n",
       "  'years',\n",
       "  'later'],\n",
       " ['sigh',\n",
       "  'my',\n",
       "  'sisters',\n",
       "  'bein',\n",
       "  'strange',\n",
       "  'she',\n",
       "  'came',\n",
       "  'all',\n",
       "  'the',\n",
       "  'way',\n",
       "  'from',\n",
       "  'copenhagen',\n",
       "  'to',\n",
       "  'london',\n",
       "  'and',\n",
       "  'now',\n",
       "  'her',\n",
       "  'phones',\n",
       "  'turned',\n",
       "  'off',\n",
       "  'i',\n",
       "  'wanna',\n",
       "  'see',\n",
       "  'her',\n",
       "  'dammit'],\n",
       " ['it', 'was', 'amazing'],\n",
       " ['barbs',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'figure',\n",
       "  'out',\n",
       "  'y',\n",
       "  'the',\n",
       "  'dsl',\n",
       "  'aint',\n",
       "  'connecting',\n",
       "  'i',\n",
       "  'need',\n",
       "  'my',\n",
       "  'google',\n",
       "  'going',\n",
       "  'home',\n",
       "  'to',\n",
       "  'my',\n",
       "  'computer',\n",
       "  'if',\n",
       "  'it',\n",
       "  'dont',\n",
       "  'start',\n",
       "  'working',\n",
       "  'soon',\n",
       "  'smh'],\n",
       " ['im',\n",
       "  'sick',\n",
       "  'and',\n",
       "  'sad',\n",
       "  'missing',\n",
       "  'out',\n",
       "  'on',\n",
       "  'martini',\n",
       "  'lounge',\n",
       "  'tonight'],\n",
       " ['seems',\n",
       "  'really',\n",
       "  'quiet',\n",
       "  'tonightam',\n",
       "  'jealous',\n",
       "  'of',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'clearly',\n",
       "  'having',\n",
       "  'a',\n",
       "  'more',\n",
       "  'exciting',\n",
       "  'life',\n",
       "  'than',\n",
       "  'me',\n",
       "  'off',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'i',\n",
       "  'think'],\n",
       " ['really',\n",
       "  'wishes',\n",
       "  'he',\n",
       "  'had',\n",
       "  'some',\n",
       "  'spare',\n",
       "  'cash',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'the',\n",
       "  'new',\n",
       "  'punch',\n",
       "  'out',\n",
       "  'for',\n",
       "  'wii'],\n",
       " ['aw', 'not', 'going', 'to', 'toronto', 'anymore'],\n",
       " ['so',\n",
       "  'sorry',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'about',\n",
       "  'your',\n",
       "  'mom',\n",
       "  'that',\n",
       "  'really',\n",
       "  'sucks'],\n",
       " ['i',\n",
       "  'feel',\n",
       "  'for',\n",
       "  'you',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'its',\n",
       "  'a',\n",
       "  'smooth',\n",
       "  'flight',\n",
       "  'be',\n",
       "  'safe',\n",
       "  'mucho',\n",
       "  'amor',\n",
       "  'from',\n",
       "  'boston'],\n",
       " ['cant',\n",
       "  'sleepso',\n",
       "  'im',\n",
       "  'watching',\n",
       "  'hgtv',\n",
       "  'im',\n",
       "  'afraid',\n",
       "  'infomercials',\n",
       "  'are',\n",
       "  'about',\n",
       "  'to',\n",
       "  'take',\n",
       "  'over'],\n",
       " ['im',\n",
       "  'getting',\n",
       "  'me',\n",
       "  'my',\n",
       "  'family',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'kaylees',\n",
       "  'graduation',\n",
       "  'its',\n",
       "  'gonna',\n",
       "  'make',\n",
       "  'me',\n",
       "  'so',\n",
       "  'sad'],\n",
       " ['sweet', 'dreams'],\n",
       " ['hay', 'wats', 'ur', 'aim', 'we', 'should', 'chat'],\n",
       " ['okay',\n",
       "  'kool',\n",
       "  'i',\n",
       "  'might',\n",
       "  'be',\n",
       "  'touring',\n",
       "  'all',\n",
       "  'summer',\n",
       "  'long',\n",
       "  'but',\n",
       "  'we',\n",
       "  'can',\n",
       "  'make',\n",
       "  'it',\n",
       "  'happen'],\n",
       " ['in',\n",
       "  'pain',\n",
       "  'my',\n",
       "  'big',\n",
       "  'toe',\n",
       "  'got',\n",
       "  'stomped',\n",
       "  'on',\n",
       "  'during',\n",
       "  'the',\n",
       "  'hokey',\n",
       "  'cokeu',\n",
       "  'its',\n",
       "  'throbbing',\n",
       "  'anyone',\n",
       "  'have',\n",
       "  'any',\n",
       "  'suggestions',\n",
       "  'to',\n",
       "  'heal',\n",
       "  'it'],\n",
       " ['time',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'op',\n",
       "  'then',\n",
       "  'some',\n",
       "  'dead',\n",
       "  'like',\n",
       "  'me',\n",
       "  'then',\n",
       "  'sleep'],\n",
       " ['having',\n",
       "  'dinner',\n",
       "  'with',\n",
       "  'my',\n",
       "  'grandma',\n",
       "  'since',\n",
       "  'i',\n",
       "  'couldnt',\n",
       "  'be',\n",
       "  'with',\n",
       "  'my',\n",
       "  'mum'],\n",
       " ['haha',\n",
       "  'thanks',\n",
       "  'its',\n",
       "  'for',\n",
       "  'history',\n",
       "  'and',\n",
       "  'its',\n",
       "  'on',\n",
       "  'how',\n",
       "  'the',\n",
       "  'invention',\n",
       "  'of',\n",
       "  'television',\n",
       "  'has',\n",
       "  'influence',\n",
       "  'america',\n",
       "  'lol'],\n",
       " ['yea', 'so', 'wassup'],\n",
       " ['stupid', 'jobs', 'idk', 'what', 'to', 'do'],\n",
       " ['shopped', 'til', 'i', 'droppedcome', 'bac', 'sunshine', 'i', 'miss', 'u'],\n",
       " ['like', 'your', 'pics', 'lucky', 'girl', 'again'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  'ive',\n",
       "  'had',\n",
       "  'anxiety',\n",
       "  'issues',\n",
       "  'for',\n",
       "  'years',\n",
       "  'so',\n",
       "  'i',\n",
       "  'think',\n",
       "  'if',\n",
       "  'i',\n",
       "  'can',\n",
       "  'make',\n",
       "  'it',\n",
       "  'through',\n",
       "  'the',\n",
       "  'first',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'days',\n",
       "  'then',\n",
       "  'i',\n",
       "  'will',\n",
       "  'be',\n",
       "  'fine'],\n",
       " ['around',\n",
       "  'hours',\n",
       "  'left',\n",
       "  'until',\n",
       "  'a',\n",
       "  'day',\n",
       "  'weekend',\n",
       "  'and',\n",
       "  'i',\n",
       "  'have',\n",
       "  'waaaay',\n",
       "  'too',\n",
       "  'much',\n",
       "  'work',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['feeling',\n",
       "  'loved',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'got',\n",
       "  'me',\n",
       "  'a',\n",
       "  'nikon',\n",
       "  'cool',\n",
       "  'pix',\n",
       "  'for',\n",
       "  'my',\n",
       "  'birthday'],\n",
       " ['there',\n",
       "  'were',\n",
       "  'attempts',\n",
       "  'to',\n",
       "  'somehow',\n",
       "  'extend',\n",
       "  'inner',\n",
       "  'classes',\n",
       "  'which',\n",
       "  'would',\n",
       "  'be',\n",
       "  'close',\n",
       "  'to',\n",
       "  'closure',\n",
       "  'cant',\n",
       "  'find',\n",
       "  'the',\n",
       "  'ref',\n",
       "  'atm'],\n",
       " ['yes',\n",
       "  'join',\n",
       "  'us',\n",
       "  'all',\n",
       "  'we',\n",
       "  'require',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cupcake',\n",
       "  'donation'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'such',\n",
       "  'a',\n",
       "  'hard',\n",
       "  'time',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'new',\n",
       "  'people',\n",
       "  'i',\n",
       "  'am',\n",
       "  'pretty',\n",
       "  'sure',\n",
       "  'i',\n",
       "  'didnt',\n",
       "  'make',\n",
       "  'a',\n",
       "  'good',\n",
       "  'impression'],\n",
       " ['haha',\n",
       "  'yup',\n",
       "  'but',\n",
       "  'still',\n",
       "  'have',\n",
       "  'a',\n",
       "  'terrible',\n",
       "  'headache',\n",
       "  'and',\n",
       "  'super',\n",
       "  'swollen',\n",
       "  'and',\n",
       "  'puffy',\n",
       "  'eyes',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'im',\n",
       "  'going',\n",
       "  'out',\n",
       "  'todayugh'],\n",
       " ['cant', 'access', 'your', 'site'],\n",
       " ['and', 'the', 'sun', 'is', 'shinningat', 'last'],\n",
       " ['we',\n",
       "  'are',\n",
       "  'on',\n",
       "  'the',\n",
       "  'slowest',\n",
       "  'train',\n",
       "  'ever',\n",
       "  'it',\n",
       "  'stops',\n",
       "  'everywhere',\n",
       "  'missed',\n",
       "  'a',\n",
       "  'quick',\n",
       "  'train',\n",
       "  'by',\n",
       "  'a',\n",
       "  'few',\n",
       "  'minutes'],\n",
       " ['nup',\n",
       "  'no',\n",
       "  'cd',\n",
       "  'either',\n",
       "  'just',\n",
       "  'a',\n",
       "  'whole',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'zeros',\n",
       "  'and',\n",
       "  'ones',\n",
       "  'you',\n",
       "  'can',\n",
       "  'have',\n",
       "  'for',\n",
       "  'free'],\n",
       " ['my', 'graduation', 'day', 'and', 'i', 'feel', 'like', 'a', 'failure'],\n",
       " ['ops', 'that', 'lol', 'wasnt', 'supposed', 'to', 'got', 'to', 'twitter'],\n",
       " ['i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'ive',\n",
       "  'ever',\n",
       "  'been',\n",
       "  'so',\n",
       "  'tierd',\n",
       "  'in',\n",
       "  'my',\n",
       "  'lifeughgoodnightso',\n",
       "  'sleeping',\n",
       "  'in',\n",
       "  'tomorrow'],\n",
       " ['what', 'are', 'u', 'going', 'to', 'do', 'today', 'my', 'girl'],\n",
       " ['why', 'doesnt', 'he', 'want', 'me', 'anymore'],\n",
       " ['bad', 'hair', 'day'],\n",
       " ['headache'],\n",
       " ['sorry', 'guys', 'i', 'didnt', 'sign', 'in', 'for', 'a', 'while', 'sorry'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'just',\n",
       "  'okayokay',\n",
       "  'like',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sane',\n",
       "  'population',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'i',\n",
       "  'hate',\n",
       "  'mondays'],\n",
       " ['mozarts', 'requiem'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'am',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'in',\n",
       "  'love',\n",
       "  'with',\n",
       "  'his',\n",
       "  'creations',\n",
       "  'and',\n",
       "  'wit',\n",
       "  'but',\n",
       "  'not',\n",
       "  'that',\n",
       "  'physically',\n",
       "  'attracted',\n",
       "  'to',\n",
       "  'him',\n",
       "  'although',\n",
       "  'he',\n",
       "  'has',\n",
       "  'great',\n",
       "  'style'],\n",
       " ['amichael',\n",
       "  'hey',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'another',\n",
       "  'great',\n",
       "  'day',\n",
       "  'im',\n",
       "  'going',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'now',\n",
       "  'ill',\n",
       "  'chat',\n",
       "  'with',\n",
       "  'you',\n",
       "  'tomorrow',\n",
       "  'sweet',\n",
       "  'dreams'],\n",
       " ['i',\n",
       "  'bet',\n",
       "  'its',\n",
       "  'cool',\n",
       "  'down',\n",
       "  'in',\n",
       "  'sr',\n",
       "  'huh',\n",
       "  'its',\n",
       "  'not',\n",
       "  'here',\n",
       "  'i',\n",
       "  'havent',\n",
       "  'stopped',\n",
       "  'sweating',\n",
       "  'since',\n",
       "  'noon',\n",
       "  'when',\n",
       "  'dad',\n",
       "  'and',\n",
       "  'i',\n",
       "  'were',\n",
       "  'packing'],\n",
       " ['ohshnapsss',\n",
       "  'is',\n",
       "  'she',\n",
       "  'pissed',\n",
       "  'at',\n",
       "  'blair',\n",
       "  'as',\n",
       "  'usual',\n",
       "  'hahah',\n",
       "  'yeeeah',\n",
       "  'i',\n",
       "  'bake',\n",
       "  'cookies'],\n",
       " ['no',\n",
       "  'bueno',\n",
       "  'hollykins',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'feel',\n",
       "  'better',\n",
       "  'asap',\n",
       "  'ps',\n",
       "  'i',\n",
       "  'miss',\n",
       "  'you',\n",
       "  'you',\n",
       "  'done',\n",
       "  'with',\n",
       "  'uni',\n",
       "  'soon',\n",
       "  'arent',\n",
       "  'you',\n",
       "  'soproudofyou'],\n",
       " ['cool',\n",
       "  'you',\n",
       "  'and',\n",
       "  'your',\n",
       "  'mother',\n",
       "  'have',\n",
       "  'awesome',\n",
       "  'hair',\n",
       "  'styles',\n",
       "  'wish',\n",
       "  'her',\n",
       "  'a',\n",
       "  'happy',\n",
       "  'mothers',\n",
       "  'day'],\n",
       " ['happy', 'mothers', 'day', 'mothers'],\n",
       " ['my', 'expression', 'watching', 'this', 'again'],\n",
       " ['stupid', 'bipolar', 'weather', 'ruined', 'my', 'day', 'off'],\n",
       " ['i',\n",
       "  'didnt',\n",
       "  'want',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'you',\n",
       "  'but',\n",
       "  'i',\n",
       "  'think',\n",
       "  'its',\n",
       "  'your',\n",
       "  'body',\n",
       "  'odour'],\n",
       " ['nice',\n",
       "  'beta',\n",
       "  'for',\n",
       "  'easports',\n",
       "  'still',\n",
       "  'no',\n",
       "  'news',\n",
       "  'on',\n",
       "  'the',\n",
       "  'online',\n",
       "  'for',\n",
       "  'madden'],\n",
       " ['thats',\n",
       "  'pretty',\n",
       "  'bad',\n",
       "  'quality',\n",
       "  'and',\n",
       "  'probably',\n",
       "  'the',\n",
       "  'worst',\n",
       "  'pic',\n",
       "  'u',\n",
       "  'posted',\n",
       "  'till',\n",
       "  'date'],\n",
       " ['i', 'missed', 'your', 'calls'],\n",
       " ['unfortunately',\n",
       "  'for',\n",
       "  'us',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'there',\n",
       "  'are',\n",
       "  'no',\n",
       "  'funny',\n",
       "  'people',\n",
       "  'on',\n",
       "  'twitter',\n",
       "  'should',\n",
       "  'we',\n",
       "  'move',\n",
       "  'to',\n",
       "  'fb',\n",
       "  'or',\n",
       "  'start',\n",
       "  'our',\n",
       "  'ownflitter'],\n",
       " ['just',\n",
       "  'came',\n",
       "  'back',\n",
       "  'from',\n",
       "  'karaoke',\n",
       "  'eating',\n",
       "  'dinner',\n",
       "  'with',\n",
       "  'emily',\n",
       "  'it',\n",
       "  'was',\n",
       "  'sooooo',\n",
       "  'much',\n",
       "  'fun'],\n",
       " ['discrimination',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'thing',\n",
       "  'ive',\n",
       "  'learned',\n",
       "  'to',\n",
       "  'say',\n",
       "  'no',\n",
       "  'my',\n",
       "  'children',\n",
       "  'would',\n",
       "  'say',\n",
       "  'i',\n",
       "  'mastered',\n",
       "  'that',\n",
       "  'years',\n",
       "  'ago'],\n",
       " ['sure',\n",
       "  'i',\n",
       "  'can',\n",
       "  'talkthe',\n",
       "  'fabulous',\n",
       "  'part',\n",
       "  'though',\n",
       "  'is',\n",
       "  'out',\n",
       "  'sorry',\n",
       "  'dear'],\n",
       " ['did',\n",
       "  'you',\n",
       "  'see',\n",
       "  'the',\n",
       "  'sec',\n",
       "  'clip',\n",
       "  'of',\n",
       "  'the',\n",
       "  'new',\n",
       "  'moon',\n",
       "  'trailer',\n",
       "  'its',\n",
       "  'up',\n",
       "  'on',\n",
       "  'etonlinecom',\n",
       "  'check',\n",
       "  'it',\n",
       "  'out',\n",
       "  'its',\n",
       "  'a',\n",
       "  'big',\n",
       "  'tease',\n",
       "  'though'],\n",
       " ['just',\n",
       "  'got',\n",
       "  'back',\n",
       "  'from',\n",
       "  'working',\n",
       "  'out',\n",
       "  'im',\n",
       "  'feeling',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'work',\n",
       "  'at'],\n",
       " ['ahhh', 'my', 'satz', 'blend', 'didnt', 'save'],\n",
       " ['so',\n",
       "  'why',\n",
       "  'should',\n",
       "  'that',\n",
       "  'matter',\n",
       "  'i',\n",
       "  'bet',\n",
       "  'you',\n",
       "  'would',\n",
       "  'be',\n",
       "  'great',\n",
       "  'at',\n",
       "  'it',\n",
       "  'i',\n",
       "  'do',\n",
       "  'its',\n",
       "  'what',\n",
       "  'you',\n",
       "  'love',\n",
       "  'right',\n",
       "  'why',\n",
       "  'not',\n",
       "  'go',\n",
       "  'for',\n",
       "  'it'],\n",
       " ['dh',\n",
       "  'is',\n",
       "  'just',\n",
       "  'about',\n",
       "  'finished',\n",
       "  'making',\n",
       "  'his',\n",
       "  'giant',\n",
       "  'trio',\n",
       "  'candy',\n",
       "  'bar',\n",
       "  'thank',\n",
       "  'the',\n",
       "  'heavens',\n",
       "  'his',\n",
       "  'work',\n",
       "  'mates',\n",
       "  'are',\n",
       "  'in',\n",
       "  'for',\n",
       "  'a',\n",
       "  'treat',\n",
       "  'tomorrow'],\n",
       " ['my', 'ear', 'are', 'popping'],\n",
       " ['working',\n",
       "  'on',\n",
       "  'diffusing',\n",
       "  'that',\n",
       "  'irritation',\n",
       "  'but',\n",
       "  'this',\n",
       "  'traffic',\n",
       "  'sure',\n",
       "  'isnt',\n",
       "  'helping',\n",
       "  'mother',\n",
       "  'f',\n",
       "  'its',\n",
       "  'always',\n",
       "  'real',\n",
       "  'bad',\n",
       "  'the',\n",
       "  'days',\n",
       "  'th',\n",
       "  'i',\n",
       "  'help',\n",
       "  'plan',\n",
       "  'stuff'],\n",
       " ['i',\n",
       "  'submitted',\n",
       "  'my',\n",
       "  'resume',\n",
       "  'the',\n",
       "  'same',\n",
       "  'day',\n",
       "  'and',\n",
       "  'saw',\n",
       "  'no',\n",
       "  'answer',\n",
       "  'back',\n",
       "  'oh',\n",
       "  'well'],\n",
       " ['catching',\n",
       "  'up',\n",
       "  'on',\n",
       "  'weeks',\n",
       "  'of',\n",
       "  'lost',\n",
       "  'and',\n",
       "  'greys',\n",
       "  'house',\n",
       "  'is',\n",
       "  'quiet',\n",
       "  'again'],\n",
       " ['i', 'love', 'when', 'ryans', 'a', 'housewife', 'makes', 'me', 'smile'],\n",
       " ['soooim',\n",
       "  'kinda',\n",
       "  'o',\n",
       "  'sick',\n",
       "  'n',\n",
       "  'tired',\n",
       "  'of',\n",
       "  'the',\n",
       "  'bs',\n",
       "  'that',\n",
       "  'guys',\n",
       "  'dish',\n",
       "  'out'],\n",
       " ['boo',\n",
       "  'i',\n",
       "  'was',\n",
       "  'hoping',\n",
       "  'for',\n",
       "  'a',\n",
       "  'fake',\n",
       "  'alien',\n",
       "  'story',\n",
       "  'with',\n",
       "  'a',\n",
       "  'tinfoil',\n",
       "  'covered',\n",
       "  'beachball',\n",
       "  'photo'],\n",
       " ['hey', 'phillll', 'wazzuppppp'],\n",
       " ['missed', 'out', 'on', 'westcott', 'micro', 'apollo', 'too'],\n",
       " ['great',\n",
       "  'you',\n",
       "  'can',\n",
       "  'buy',\n",
       "  'me',\n",
       "  'lunch',\n",
       "  'when',\n",
       "  'i',\n",
       "  'get',\n",
       "  'my',\n",
       "  'pay',\n",
       "  'cut',\n",
       "  'next',\n",
       "  'month'],\n",
       " ['finally', 'gone', 'to', 'the', 'beach', 'yeaaaah'],\n",
       " ['ranjan',\n",
       "  'did',\n",
       "  'i',\n",
       "  'ever',\n",
       "  'mention',\n",
       "  'what',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'and',\n",
       "  'awesome',\n",
       "  'dude',\n",
       "  'you',\n",
       "  'are'],\n",
       " ['last',\n",
       "  'weekday',\n",
       "  'of',\n",
       "  'doing',\n",
       "  'nothing',\n",
       "  'school',\n",
       "  'starts',\n",
       "  'next',\n",
       "  'week'],\n",
       " ['hello',\n",
       "  'gorgeous',\n",
       "  'girl',\n",
       "  'nice',\n",
       "  'new',\n",
       "  'pic',\n",
       "  'how',\n",
       "  'are',\n",
       "  'you',\n",
       "  'today'],\n",
       " ['ok', 'that', 'duet', 'was', 'hysterical', 'lol'],\n",
       " ['ok',\n",
       "  'i',\n",
       "  'have',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'off',\n",
       "  'all',\n",
       "  'of',\n",
       "  'my',\n",
       "  'twitter',\n",
       "  'device',\n",
       "  'updates',\n",
       "  'until',\n",
       "  'i',\n",
       "  'get',\n",
       "  'a',\n",
       "  'new',\n",
       "  'battery',\n",
       "  'phone',\n",
       "  'goes',\n",
       "  'from',\n",
       "  'fully',\n",
       "  'charged',\n",
       "  'to',\n",
       "  'dead',\n",
       "  'in',\n",
       "  'about',\n",
       "  'hours'],\n",
       " ['michelle', 'is', 'a', 'hot', 'mama', 'with', 'chichis', 'grande'],\n",
       " ['either',\n",
       "  'way',\n",
       "  'you',\n",
       "  'always',\n",
       "  'tend',\n",
       "  'to',\n",
       "  'make',\n",
       "  'my',\n",
       "  'followfriday',\n",
       "  'list',\n",
       "  'sweetie',\n",
       "  'you',\n",
       "  'do',\n",
       "  'rock',\n",
       "  'that',\n",
       "  'much'],\n",
       " ['no', 'one', 'i', 'know', 'likes', 'boiled', 'peanuts', 't'],\n",
       " ['watched',\n",
       "  'episode',\n",
       "  'of',\n",
       "  'loved',\n",
       "  'how',\n",
       "  'they',\n",
       "  'did',\n",
       "  'a',\n",
       "  'throwback',\n",
       "  'to',\n",
       "  'the',\n",
       "  'first',\n",
       "  'episode',\n",
       "  'using',\n",
       "  'the',\n",
       "  'sprinkler',\n",
       "  'theory'],\n",
       " ['im',\n",
       "  'sleepy',\n",
       "  'but',\n",
       "  'is',\n",
       "  'feeling',\n",
       "  'under',\n",
       "  'the',\n",
       "  'weather',\n",
       "  'ugh',\n",
       "  'these',\n",
       "  'tonsils',\n",
       "  'i',\n",
       "  'need',\n",
       "  'some',\n",
       "  'company',\n",
       "  'or',\n",
       "  'somebody',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'too'],\n",
       " ['please',\n",
       "  'get',\n",
       "  'a',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  'with',\n",
       "  'a',\n",
       "  'better',\n",
       "  'camera',\n",
       "  'on',\n",
       "  'it',\n",
       "  'your',\n",
       "  'pictures',\n",
       "  'are',\n",
       "  'real',\n",
       "  'bad',\n",
       "  'quality',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'those',\n",
       "  'that',\n",
       "  'miley',\n",
       "  'took'],\n",
       " ['ichigo',\n",
       "  'she',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'on',\n",
       "  'aswell',\n",
       "  'bless',\n",
       "  'i',\n",
       "  'suppose',\n",
       "  'maybe',\n",
       "  'thats',\n",
       "  'why',\n",
       "  'kids',\n",
       "  'shouldnt',\n",
       "  'be',\n",
       "  'in',\n",
       "  'it'],\n",
       " ['booziest', 'weekend', 'in', 'a', 'long', 'time', 'good', 'fun', 'though'],\n",
       " ['counting',\n",
       "  'the',\n",
       "  'hours',\n",
       "  'of',\n",
       "  'lost',\n",
       "  'sunshine',\n",
       "  'until',\n",
       "  'the',\n",
       "  'weekend'],\n",
       " ['planning',\n",
       "  'and',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'call',\n",
       "  'the',\n",
       "  'doctor',\n",
       "  'though',\n",
       "  'that',\n",
       "  'isnt',\n",
       "  'going',\n",
       "  'so',\n",
       "  'well',\n",
       "  'so',\n",
       "  'mostly',\n",
       "  'planning'],\n",
       " ['hoooray', 'im', 'hooked', 'already'],\n",
       " ['ok', 'then', 'have', 'a', 'good', 'day'],\n",
       " ['i',\n",
       "  'agree',\n",
       "  'everybody',\n",
       "  'wouldve',\n",
       "  'been',\n",
       "  'excited',\n",
       "  'and',\n",
       "  'then',\n",
       "  'it',\n",
       "  'goes',\n",
       "  'ohhhh',\n",
       "  'nooooo',\n",
       "  'ms',\n",
       "  'screws',\n",
       "  'up',\n",
       "  'again'],\n",
       " ['edge',\n",
       "  'left',\n",
       "  'me',\n",
       "  'off',\n",
       "  'the',\n",
       "  'contributors',\n",
       "  'list',\n",
       "  'in',\n",
       "  'this',\n",
       "  'months',\n",
       "  'issue',\n",
       "  'x',\n",
       "  'ffs',\n",
       "  'werd'],\n",
       " ['ooo',\n",
       "  'growl',\n",
       "  'and',\n",
       "  'yummy',\n",
       "  'time',\n",
       "  'coming',\n",
       "  'soon',\n",
       "  'for',\n",
       "  'you',\n",
       "  'too',\n",
       "  'huh',\n",
       "  'oh',\n",
       "  'yeah',\n",
       "  'i',\n",
       "  'have',\n",
       "  'been',\n",
       "  'hunting',\n",
       "  'for',\n",
       "  'a',\n",
       "  'combo',\n",
       "  'tshirt',\n",
       "  'think',\n",
       "  'i',\n",
       "  'can',\n",
       "  'find',\n",
       "  'one',\n",
       "  'no'],\n",
       " ['im', 'back', 'to', 'this', 'zindex', 'problemagain'],\n",
       " ['is', 'anyone', 'out', 'there', 'so', 'bored', 'at', 'work'],\n",
       " ['am',\n",
       "  'hating',\n",
       "  'my',\n",
       "  'life',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'theres',\n",
       "  'only',\n",
       "  'so',\n",
       "  'many',\n",
       "  'nos',\n",
       "  'my',\n",
       "  'delicate',\n",
       "  'little',\n",
       "  'mind',\n",
       "  'can',\n",
       "  'take'],\n",
       " ['check',\n",
       "  'out',\n",
       "  'and',\n",
       "  'started',\n",
       "  'new',\n",
       "  'tees',\n",
       "  'limited',\n",
       "  'edition',\n",
       "  'in',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'check',\n",
       "  'facebook',\n",
       "  'group',\n",
       "  'too'],\n",
       " ['they', 'being', 'the', 'husband', 'or', 'the', 'girl'],\n",
       " ['thinking',\n",
       "  'of',\n",
       "  'what',\n",
       "  'i',\n",
       "  'should',\n",
       "  'do',\n",
       "  'in',\n",
       "  'vegas',\n",
       "  'any',\n",
       "  'good',\n",
       "  'ideas',\n",
       "  'or',\n",
       "  'places',\n",
       "  'that',\n",
       "  'are',\n",
       "  'a',\n",
       "  'most',\n",
       "  'see'],\n",
       " ['first',\n",
       "  'day',\n",
       "  'of',\n",
       "  'summer',\n",
       "  'sucks',\n",
       "  'its',\n",
       "  'overcast',\n",
       "  'and',\n",
       "  'cold',\n",
       "  'this',\n",
       "  'isnt',\n",
       "  'summer'],\n",
       " ['hi', 'to', 'one', 'kiwi', 'artist', 'from', 'another', 'kiwi', 'artist'],\n",
       " ['says', 'happy', 'mothers', 'day', 'to', 'all', 'moms', 'out', 'there'],\n",
       " ['oooo',\n",
       "  'ok',\n",
       "  'why',\n",
       "  'havent',\n",
       "  'you',\n",
       "  'accepted',\n",
       "  'my',\n",
       "  'friends',\n",
       "  'request'],\n",
       " ['sorry',\n",
       "  'to',\n",
       "  'tweet',\n",
       "  'about',\n",
       "  'bgt',\n",
       "  'but',\n",
       "  'poor',\n",
       "  'wonderful',\n",
       "  'crazy',\n",
       "  'weird',\n",
       "  'greg',\n",
       "  'so',\n",
       "  'not',\n",
       "  'fair',\n",
       "  'the',\n",
       "  'silly',\n",
       "  'little',\n",
       "  'girl',\n",
       "  'is',\n",
       "  'never',\n",
       "  'going',\n",
       "  'to',\n",
       "  'cope',\n",
       "  'urgh',\n",
       "  'not',\n",
       "  'fair'],\n",
       " ['no'],\n",
       " ['michele',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'thatam',\n",
       "  'now',\n",
       "  'following',\n",
       "  'themlove',\n",
       "  'good',\n",
       "  'causes'],\n",
       " ['not', 'available', 'in', 'my', 'area', 'i', 'would', 'too'],\n",
       " ['its',\n",
       "  'friday',\n",
       "  'only',\n",
       "  'more',\n",
       "  'hours',\n",
       "  'until',\n",
       "  'im',\n",
       "  'freeuntil',\n",
       "  'tomorrow',\n",
       "  'oh',\n",
       "  'well'],\n",
       " ['meeting',\n",
       "  'just',\n",
       "  'in',\n",
       "  'time',\n",
       "  'that',\n",
       "  'im',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'win',\n",
       "  'something',\n",
       "  'prizes',\n",
       "  'friday'],\n",
       " ['waiting', 'for', 'having', 'cramps'],\n",
       " ['philosophy', 'final', 'today', 'thank', 'you', 'its', 'days', 'now'],\n",
       " ['s', 'plans', 'didnt', 'go', 'as', 'followed', 'but', 'its', 'ok'],\n",
       " ['what',\n",
       "  'did',\n",
       "  'you',\n",
       "  'do',\n",
       "  'let',\n",
       "  'me',\n",
       "  'guess',\n",
       "  'you',\n",
       "  'skipped',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'bought',\n",
       "  'a',\n",
       "  'new',\n",
       "  'pinkish',\n",
       "  'outfit'],\n",
       " ['where', 'is', 'the', 'rain', 'please', 'come', 'out'],\n",
       " ['my', 'pleasure'],\n",
       " ['presentation', 'for', 'senior', 'boards', 'fml'],\n",
       " ['lol', 'i', 'know', 'but', 'it', 'was', 'just', 'so', 'funny', 'ahaha'],\n",
       " ['wide', 'awake', 'and', 'grouchy', 'as'],\n",
       " ['just',\n",
       "  'when',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'things',\n",
       "  'couldnt',\n",
       "  'get',\n",
       "  'any',\n",
       "  'worse',\n",
       "  'it',\n",
       "  'just',\n",
       "  'did',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'get',\n",
       "  'even',\n",
       "  'worse',\n",
       "  'tonight',\n",
       "  'i',\n",
       "  'bet',\n",
       "  'my',\n",
       "  'life',\n",
       "  'is',\n",
       "  'a',\n",
       "  'misery'],\n",
       " ['i', 'dont', 'have', 'the', 'app', 'that', 'does', 'it'],\n",
       " ['lol',\n",
       "  'hi',\n",
       "  'emmy',\n",
       "  'latin',\n",
       "  'would',\n",
       "  'help',\n",
       "  'me',\n",
       "  'study',\n",
       "  'for',\n",
       "  'the',\n",
       "  'aptitude',\n",
       "  'tests',\n",
       "  'to',\n",
       "  'get',\n",
       "  'into',\n",
       "  'grad',\n",
       "  'school',\n",
       "  'thats',\n",
       "  'why',\n",
       "  'i',\n",
       "  'wanna',\n",
       "  'take',\n",
       "  'it'],\n",
       " ['out', 'for', 'supper', 'tonight', 'with', 'kurumi', 'in', 'minutes'],\n",
       " ['kap',\n",
       "  'but',\n",
       "  'i',\n",
       "  'think',\n",
       "  'its',\n",
       "  'cute',\n",
       "  'do',\n",
       "  'this',\n",
       "  'every',\n",
       "  'night',\n",
       "  'okay'],\n",
       " ['is',\n",
       "  'happyskool',\n",
       "  'just',\n",
       "  'let',\n",
       "  'out',\n",
       "  'today',\n",
       "  'was',\n",
       "  'my',\n",
       "  'last',\n",
       "  'day',\n",
       "  'yippee',\n",
       "  'rip',\n",
       "  'jackson',\n",
       "  'tyler',\n",
       "  'morris',\n",
       "  'always',\n",
       "  'loved',\n",
       "  'and',\n",
       "  'never',\n",
       "  'forgotten'],\n",
       " ['hi', 'mariah'],\n",
       " ['im', 'not', 'at', 'home', 'with', 'my', 'cats', 'right', 'now'],\n",
       " ['wheres', 'the', 'music', 'mannnn', 'my', 'inbox', 'is', 'still', 'empty'],\n",
       " ['what',\n",
       "  'am',\n",
       "  'i',\n",
       "  'doing',\n",
       "  'atm',\n",
       "  'oh',\n",
       "  'yeah',\n",
       "  'apple',\n",
       "  'juice',\n",
       "  'im',\n",
       "  'such',\n",
       "  'a',\n",
       "  'rebel'],\n",
       " ['im',\n",
       "  'sorry',\n",
       "  'about',\n",
       "  'you',\n",
       "  'are',\n",
       "  'still',\n",
       "  'sick',\n",
       "  'u',\n",
       "  'know',\n",
       "  'most',\n",
       "  'of',\n",
       "  'them',\n",
       "  'and',\n",
       "  'i',\n",
       "  'know',\n",
       "  'that',\n",
       "  'u',\n",
       "  'will',\n",
       "  'guess',\n",
       "  'the',\n",
       "  'pelzer',\n",
       "  'present'],\n",
       " ['nice', 'one'],\n",
       " ['exam',\n",
       "  'today',\n",
       "  'going',\n",
       "  'to',\n",
       "  'get',\n",
       "  'my',\n",
       "  'license',\n",
       "  'renewed',\n",
       "  'the',\n",
       "  'birthday',\n",
       "  'is',\n",
       "  'getting',\n",
       "  'closer'],\n",
       " ['gotta',\n",
       "  'get',\n",
       "  'creative',\n",
       "  'with',\n",
       "  'these',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'gifts',\n",
       "  'im',\n",
       "  'gonna',\n",
       "  'win',\n",
       "  'them',\n",
       "  'over',\n",
       "  'with',\n",
       "  'my',\n",
       "  'love'],\n",
       " ['thinks', 'its', 'gonna', 'rain'],\n",
       " ['aah',\n",
       "  'well',\n",
       "  'have',\n",
       "  'a',\n",
       "  'few',\n",
       "  'friends',\n",
       "  'over',\n",
       "  'there',\n",
       "  'just',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'alls',\n",
       "  'great',\n",
       "  'and',\n",
       "  'weathers',\n",
       "  'been',\n",
       "  'good'],\n",
       " ['yrbook',\n",
       "  'signing',\n",
       "  'w',\n",
       "  'evryone',\n",
       "  'was',\n",
       "  'fun',\n",
       "  'im',\n",
       "  'gna',\n",
       "  'miss',\n",
       "  'evrything'],\n",
       " ['i', 'lost', 'my', 'artistic', 'abilities'],\n",
       " ['so',\n",
       "  'not',\n",
       "  'close',\n",
       "  'enough',\n",
       "  'that',\n",
       "  'i',\n",
       "  'could',\n",
       "  'run',\n",
       "  'out',\n",
       "  'and',\n",
       "  'get',\n",
       "  'one'],\n",
       " ['that', 'was', 'stone', 'cold', 'crazy'],\n",
       " ['totally',\n",
       "  'having',\n",
       "  'austin',\n",
       "  'powers',\n",
       "  'withdrawl',\n",
       "  'symptons',\n",
       "  'and',\n",
       "  'darrius',\n",
       "  'withdrawl',\n",
       "  'symptoms',\n",
       "  'and',\n",
       "  'mommy',\n",
       "  'and',\n",
       "  'minne',\n",
       "  'withdrawl',\n",
       "  'syamptoms'],\n",
       " ['xo',\n",
       "  'they',\n",
       "  'were',\n",
       "  'so',\n",
       "  'pretty',\n",
       "  'and',\n",
       "  'took',\n",
       "  'like',\n",
       "  'an',\n",
       "  'hour',\n",
       "  'to',\n",
       "  'do',\n",
       "  'can',\n",
       "  'i',\n",
       "  'do',\n",
       "  'ursssss'],\n",
       " ['seniors', 'last', 'day'],\n",
       " ['crisis',\n",
       "  'forgot',\n",
       "  'my',\n",
       "  'fringe',\n",
       "  'comb',\n",
       "  'im',\n",
       "  'with',\n",
       "  'menno',\n",
       "  'one',\n",
       "  'will',\n",
       "  'help',\n",
       "  'me'],\n",
       " ['already',\n",
       "  'got',\n",
       "  'my',\n",
       "  'ticket',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'making',\n",
       "  'sure',\n",
       "  'though'],\n",
       " ['thanks', 'to', 'all', 'my', 'new', 'followers'],\n",
       " ['were',\n",
       "  'getting',\n",
       "  'closer',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'further',\n",
       "  'from',\n",
       "  'real',\n",
       "  'lobby',\n",
       "  'dates',\n",
       "  'chicago',\n",
       "  'squee'],\n",
       " ['has',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'vocie',\n",
       "  'and',\n",
       "  'adele',\n",
       "  'is',\n",
       "  'laughing',\n",
       "  'at',\n",
       "  'me',\n",
       "  'lol',\n",
       "  'and',\n",
       "  'still',\n",
       "  'wondering',\n",
       "  'why',\n",
       "  'im',\n",
       "  'in',\n",
       "  'college',\n",
       "  'on',\n",
       "  'me',\n",
       "  'week',\n",
       "  'off'],\n",
       " ['killboy',\n",
       "  'oh',\n",
       "  'sorry',\n",
       "  'not',\n",
       "  'getting',\n",
       "  'all',\n",
       "  'my',\n",
       "  'replies',\n",
       "  'nothing',\n",
       "  'against',\n",
       "  'you',\n",
       "  'and',\n",
       "  'yes',\n",
       "  'i',\n",
       "  'do',\n",
       "  'know',\n",
       "  'nirvana'],\n",
       " ['busy',\n",
       "  'working',\n",
       "  'on',\n",
       "  'a',\n",
       "  'new',\n",
       "  'kit',\n",
       "  'and',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'interviews',\n",
       "  'doneyea',\n",
       "  'the',\n",
       "  'weekend',\n",
       "  'pray',\n",
       "  'for',\n",
       "  'my',\n",
       "  'uncle',\n",
       "  'still',\n",
       "  'young',\n",
       "  'and',\n",
       "  'had',\n",
       "  'a',\n",
       "  'massive',\n",
       "  'stroke'],\n",
       " ['didnt',\n",
       "  'get',\n",
       "  'bitten',\n",
       "  'by',\n",
       "  'a',\n",
       "  'rabies',\n",
       "  'infested',\n",
       "  'person',\n",
       "  'last',\n",
       "  'night',\n",
       "  'yay',\n",
       "  'for',\n",
       "  'me',\n",
       "  'gonna',\n",
       "  'scare',\n",
       "  'rachel',\n",
       "  'with',\n",
       "  'quarantine',\n",
       "  'tonight',\n",
       "  'this',\n",
       "  'shall',\n",
       "  'be',\n",
       "  'fun'],\n",
       " ['nooo',\n",
       "  'no',\n",
       "  'roo',\n",
       "  'crying',\n",
       "  'but',\n",
       "  'omg',\n",
       "  'i',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'slap',\n",
       "  'her',\n",
       "  'she',\n",
       "  'was',\n",
       "  'singing',\n",
       "  'fine',\n",
       "  'then',\n",
       "  'from',\n",
       "  'out',\n",
       "  'of',\n",
       "  'nowhere',\n",
       "  'boohooooooooooo'],\n",
       " ['watching', 'the', 'simpsons'],\n",
       " ['good',\n",
       "  'morning',\n",
       "  'court',\n",
       "  'crossfit',\n",
       "  'bible',\n",
       "  'study',\n",
       "  'someone',\n",
       "  'very',\n",
       "  'specials',\n",
       "  'house'],\n",
       " ['have', 'a', 'great', 'time', 'in', 'london'],\n",
       " ['has', 'work', 'very', 'very', 'soon', 'way', 'too', 'soon'],\n",
       " ['phaket', 'what', 'did', 'anneliese', 'want', 'to', 'do'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'emergency',\n",
       "  'room',\n",
       "  'with',\n",
       "  'my',\n",
       "  'cousin',\n",
       "  'shes',\n",
       "  'got',\n",
       "  'mad',\n",
       "  'flu',\n",
       "  'and',\n",
       "  'cant',\n",
       "  'walk',\n",
       "  'or',\n",
       "  'breathe',\n",
       "  'why',\n",
       "  'are',\n",
       "  'hospitals',\n",
       "  'always',\n",
       "  'so',\n",
       "  'cold'],\n",
       " ['thanks', 'for', 'the', 'greeting'],\n",
       " ['im',\n",
       "  'hungry',\n",
       "  'wife',\n",
       "  'is',\n",
       "  'at',\n",
       "  'a',\n",
       "  'bodyshop',\n",
       "  'party',\n",
       "  'and',\n",
       "  'is',\n",
       "  'bringing',\n",
       "  'a',\n",
       "  'takeaway',\n",
       "  'home',\n",
       "  'with',\n",
       "  'her',\n",
       "  'how',\n",
       "  'much',\n",
       "  'longer',\n",
       "  'will',\n",
       "  'the',\n",
       "  'party',\n",
       "  'go',\n",
       "  'on'],\n",
       " ['such', 'a', 'pretty', 'baby'],\n",
       " ['invite', 'them', 'to', 'your', 'house', 'instead'],\n",
       " ['im', 'a', 'bit', 'bens', 'thaied', 'out'],\n",
       " ['stackeoverflow'],\n",
       " ['jungle',\n",
       "  'book',\n",
       "  'is',\n",
       "  'sooooo',\n",
       "  'cute',\n",
       "  'i',\n",
       "  'have',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'or',\n",
       "  'drink'],\n",
       " ['dead',\n",
       "  'stopped',\n",
       "  'in',\n",
       "  'the',\n",
       "  'express',\n",
       "  'lane',\n",
       "  'this',\n",
       "  'would',\n",
       "  'happen',\n",
       "  'when',\n",
       "  'i',\n",
       "  'choose',\n",
       "  'to',\n",
       "  'take',\n",
       "  'it',\n",
       "  'no',\n",
       "  'way',\n",
       "  'out',\n",
       "  'now',\n",
       "  'ugh',\n",
       "  'hopefully',\n",
       "  'this',\n",
       "  'gets',\n",
       "  'moving'],\n",
       " ['okeefe',\n",
       "  'yay',\n",
       "  'youre',\n",
       "  'on',\n",
       "  'twitter',\n",
       "  'youre',\n",
       "  'my',\n",
       "  'secret',\n",
       "  'celeb',\n",
       "  'crush',\n",
       "  'too',\n",
       "  'much',\n",
       "  'info'],\n",
       " ['ah', 'ok', 'thank', 'youuuuuu'],\n",
       " ['twitter', 'you', 'just', 'fail', 'at', 'life', 'sometimes', 'oh', 'well'],\n",
       " ['no',\n",
       "  'phone',\n",
       "  'call',\n",
       "  'yet',\n",
       "  'minutes',\n",
       "  'until',\n",
       "  'i',\n",
       "  'pluck',\n",
       "  'up',\n",
       "  'the',\n",
       "  'courage',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'my',\n",
       "  'phone',\n",
       "  'would',\n",
       "  'ring'],\n",
       " ['points',\n",
       "  'at',\n",
       "  'the',\n",
       "  'gear',\n",
       "  'question',\n",
       "  'i',\n",
       "  'just',\n",
       "  'posted',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'get',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'my',\n",
       "  'dreadweave',\n",
       "  'set'],\n",
       " ['you',\n",
       "  'remind',\n",
       "  'me',\n",
       "  'so',\n",
       "  'much',\n",
       "  'of',\n",
       "  'a',\n",
       "  'omaha',\n",
       "  'girl',\n",
       "  'that',\n",
       "  'i',\n",
       "  'use',\n",
       "  'to',\n",
       "  'date',\n",
       "  'i',\n",
       "  'guess',\n",
       "  'it',\n",
       "  'all',\n",
       "  'in',\n",
       "  'the',\n",
       "  'jeans',\n",
       "  'calvin',\n",
       "  'kleins',\n",
       "  'is',\n",
       "  'what',\n",
       "  'she',\n",
       "  'wore'],\n",
       " ['sherrieshepherd',\n",
       "  'gave',\n",
       "  'the',\n",
       "  'link',\n",
       "  'for',\n",
       "  'he',\n",
       "  'gives',\n",
       "  'twitter',\n",
       "  'tips',\n",
       "  'hope',\n",
       "  'this',\n",
       "  'helps'],\n",
       " ['i', 'loved', 'him', 'and', 'he', 'was', 'in', 'a', 'mini'],\n",
       " ['yeah',\n",
       "  'im',\n",
       "  'okay',\n",
       "  'been',\n",
       "  'icing',\n",
       "  'and',\n",
       "  'ace',\n",
       "  'bandage',\n",
       "  'and',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'my',\n",
       "  'on',\n",
       "  'twitter',\n",
       "  'lol',\n",
       "  'thanks'],\n",
       " ['youre', 'so', 'gorgeous'],\n",
       " ['i',\n",
       "  'guess',\n",
       "  'the',\n",
       "  'relaxing',\n",
       "  'dinner',\n",
       "  'and',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'is',\n",
       "  'out',\n",
       "  'for',\n",
       "  'tonighti',\n",
       "  'was',\n",
       "  'looking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'that',\n",
       "  'after',\n",
       "  'my',\n",
       "  'day',\n",
       "  'at',\n",
       "  'work'],\n",
       " ['my',\n",
       "  'laptop',\n",
       "  'grew',\n",
       "  'speakers',\n",
       "  'now',\n",
       "  'i',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'charlie',\n",
       "  'with',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'on'],\n",
       " ['rofl', 'uh', 'huh'],\n",
       " ['this', 'was', 'funny', 'i', 'have'],\n",
       " ['well',\n",
       "  'doesnt',\n",
       "  'that',\n",
       "  'look',\n",
       "  'fab',\n",
       "  'even',\n",
       "  'if',\n",
       "  'i',\n",
       "  'do',\n",
       "  'say',\n",
       "  'so',\n",
       "  'myself'],\n",
       " ['deadlines'],\n",
       " ['has', 'a', 'terrible', 'headache', 'i', 'need', 'relief'],\n",
       " ['two', 'months', 'ago', 'i', 'became', 'irrelevant'],\n",
       " ['finally',\n",
       "  'sunny',\n",
       "  'days',\n",
       "  'and',\n",
       "  'im',\n",
       "  'too',\n",
       "  'sick',\n",
       "  'to',\n",
       "  'go',\n",
       "  'outside',\n",
       "  'and',\n",
       "  'play'],\n",
       " ['good', 'luck', 'how', 'exciting'],\n",
       " ['working',\n",
       "  'up',\n",
       "  'to',\n",
       "  'my',\n",
       "  'vacation',\n",
       "  'to',\n",
       "  'thailand',\n",
       "  'getting',\n",
       "  'more',\n",
       "  'excited',\n",
       "  'every',\n",
       "  'day'],\n",
       " ['we', 'wont', 'be', 'home', 'till', 'like', 'next', 'month'],\n",
       " ['finally',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'show',\n",
       "  'genuine',\n",
       "  'love',\n",
       "  'not',\n",
       "  'dependent',\n",
       "  'selfish',\n",
       "  'love',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do',\n",
       "  'it',\n",
       "  'my',\n",
       "  'heart',\n",
       "  'goes',\n",
       "  'out',\n",
       "  'to',\n",
       "  'you',\n",
       "  'and',\n",
       "  'im',\n",
       "  'sorry',\n",
       "  'ur',\n",
       "  'pain'],\n",
       " ['im', 'game', 'too', 'bad', 'your', 'leaving', 'hi'],\n",
       " ['so', 'screwed', 'for', 'sat', 'us'],\n",
       " ['just',\n",
       "  'got',\n",
       "  'an',\n",
       "  'im',\n",
       "  'from',\n",
       "  'another',\n",
       "  'coworker',\n",
       "  'who',\n",
       "  'just',\n",
       "  'got',\n",
       "  'laid',\n",
       "  'off',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'people',\n",
       "  'becoming',\n",
       "  'unemployed'],\n",
       " ['the', 'exact', 'one', 'i', 'was', 'thinking', 'of', 'the', 'bestttt'],\n",
       " ['easties', 'you', 'can', 'go', 'there', 'anytime'],\n",
       " ['why',\n",
       "  'does',\n",
       "  'googledocs',\n",
       "  'do',\n",
       "  'folders',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'labels',\n",
       "  'like',\n",
       "  'gmail',\n",
       "  'i',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'like',\n",
       "  'labels'],\n",
       " ['lemme',\n",
       "  'guess',\n",
       "  'you',\n",
       "  'ran',\n",
       "  'miles',\n",
       "  'at',\n",
       "  'the',\n",
       "  'gym',\n",
       "  'and',\n",
       "  'are',\n",
       "  'waking',\n",
       "  'your',\n",
       "  'kids',\n",
       "  'up',\n",
       "  'and',\n",
       "  'then',\n",
       "  'going',\n",
       "  'to',\n",
       "  'the',\n",
       "  'beach',\n",
       "  'and',\n",
       "  'or',\n",
       "  'recording',\n",
       "  'studio'],\n",
       " ['i', 'never', 'knew', 'a', 'dentention', 'was', 'so', 'hard', 'get'],\n",
       " ['pacquiao',\n",
       "  'fight',\n",
       "  'was',\n",
       "  'fun',\n",
       "  'at',\n",
       "  'home',\n",
       "  'wif',\n",
       "  'fam',\n",
       "  'and',\n",
       "  'melissa',\n",
       "  'sat',\n",
       "  'today',\n",
       "  'was',\n",
       "  'a',\n",
       "  'mission',\n",
       "  'to',\n",
       "  'ikea',\n",
       "  'srsly',\n",
       "  'different',\n",
       "  'freeways',\n",
       "  'to',\n",
       "  'ge',\n",
       "  'to',\n",
       "  'burbank'],\n",
       " ['my', 'nail', 'broke', 'i', 'haaaaaaaaate'],\n",
       " ['dang', 'that', 'is', 'disappointing'],\n",
       " ['yep'],\n",
       " ['how',\n",
       "  'much',\n",
       "  'longer',\n",
       "  'is',\n",
       "  'the',\n",
       "  'nkotb',\n",
       "  'block',\n",
       "  'party',\n",
       "  'love',\n",
       "  'it',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'so',\n",
       "  'just',\n",
       "  'wondering',\n",
       "  'what',\n",
       "  'time',\n",
       "  'its',\n",
       "  'overlolthanks'],\n",
       " ['thanks',\n",
       "  'my',\n",
       "  'moms',\n",
       "  'seed',\n",
       "  'is',\n",
       "  'larger',\n",
       "  'and',\n",
       "  'already',\n",
       "  'cracked',\n",
       "  'and',\n",
       "  'planted',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'avalina',\n",
       "  'isnt',\n",
       "  'a',\n",
       "  'dud'],\n",
       " ['anyone',\n",
       "  'want',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'me',\n",
       "  'this',\n",
       "  'anthropomorphic',\n",
       "  'planter',\n",
       "  'only',\n",
       "  'available',\n",
       "  'till',\n",
       "  'the'],\n",
       " ['its',\n",
       "  'a',\n",
       "  'beautiful',\n",
       "  'day',\n",
       "  'outside',\n",
       "  'today',\n",
       "  'shame',\n",
       "  'im',\n",
       "  'stuck',\n",
       "  'in',\n",
       "  'the',\n",
       "  'office',\n",
       "  'with',\n",
       "  'the',\n",
       "  'blinds',\n",
       "  'shut',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'glare'],\n",
       " ['woke',\n",
       "  'up',\n",
       "  'and',\n",
       "  'there',\n",
       "  'was',\n",
       "  'sun',\n",
       "  'and',\n",
       "  'then',\n",
       "  'it',\n",
       "  'started',\n",
       "  'to',\n",
       "  'rain'],\n",
       " ['and',\n",
       "  'the',\n",
       "  'creative',\n",
       "  'vados',\n",
       "  'are',\n",
       "  'out',\n",
       "  'of',\n",
       "  'stock',\n",
       "  'at',\n",
       "  'walmartcom',\n",
       "  'missed',\n",
       "  'it',\n",
       "  'but',\n",
       "  'thanks',\n",
       "  'for',\n",
       "  'tweeting',\n",
       "  'about',\n",
       "  'it'],\n",
       " ['hates', 'this', 'weather'],\n",
       " ['cultural',\n",
       "  'tour',\n",
       "  'by',\n",
       "  'loiusas',\n",
       "  'family',\n",
       "  'kangaroo',\n",
       "  'sightseeing',\n",
       "  'in',\n",
       "  'cemetary',\n",
       "  'lovely'],\n",
       " ['flapataco', 'was', 'nice', 'until', 'the', 'plebs', 'came', 'in'],\n",
       " ['oh',\n",
       "  'and',\n",
       "  'yippee',\n",
       "  'for',\n",
       "  'lynz',\n",
       "  'way',\n",
       "  'who',\n",
       "  'gets',\n",
       "  'to',\n",
       "  'celebrate',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'for',\n",
       "  'the',\n",
       "  'first',\n",
       "  'time',\n",
       "  'as',\n",
       "  'a',\n",
       "  'mother'],\n",
       " ['am',\n",
       "  'chillaxin',\n",
       "  'after',\n",
       "  'a',\n",
       "  'busy',\n",
       "  'bankholiday',\n",
       "  'hope',\n",
       "  'everbody',\n",
       "  'had',\n",
       "  'a',\n",
       "  'gd',\n",
       "  'wkend',\n",
       "  'holiday',\n",
       "  'in',\n",
       "  'days'],\n",
       " ['havin',\n",
       "  'a',\n",
       "  'much',\n",
       "  'better',\n",
       "  'day',\n",
       "  'today',\n",
       "  'finished',\n",
       "  'the',\n",
       "  'last',\n",
       "  'twilight',\n",
       "  'book',\n",
       "  'yesterday',\n",
       "  'classes',\n",
       "  'start',\n",
       "  'next',\n",
       "  'week',\n",
       "  'get',\n",
       "  'at',\n",
       "  'me',\n",
       "  'yall'],\n",
       " ['new',\n",
       "  'motorcycle',\n",
       "  'and',\n",
       "  'you',\n",
       "  'popped',\n",
       "  'a',\n",
       "  'cable',\n",
       "  'already',\n",
       "  'wowyou',\n",
       "  'ride',\n",
       "  'hard'],\n",
       " ['check',\n",
       "  'out',\n",
       "  'the',\n",
       "  'flyer',\n",
       "  'i',\n",
       "  'designed',\n",
       "  'for',\n",
       "  'the',\n",
       "  'notary',\n",
       "  'and',\n",
       "  'retrograde',\n",
       "  'let',\n",
       "  'me',\n",
       "  'know',\n",
       "  'what',\n",
       "  'you',\n",
       "  'think'],\n",
       " ['thanks', 'welcome', 'back'],\n",
       " ['i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'experience',\n",
       "  'snow',\n",
       "  'we',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'snow',\n",
       "  'here',\n",
       "  'and',\n",
       "  'it',\n",
       "  'sucks'],\n",
       " ['i', 'have', 'such', 'a', 'sore', 'head'],\n",
       " ['at',\n",
       "  'the',\n",
       "  'office',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'mystery',\n",
       "  'of',\n",
       "  'whose',\n",
       "  'blood',\n",
       "  'is',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  'toilet',\n",
       "  'eewwwww'],\n",
       " ['aw',\n",
       "  'love',\n",
       "  'him',\n",
       "  'his',\n",
       "  'car',\n",
       "  'was',\n",
       "  'soooo',\n",
       "  'cute',\n",
       "  'tonight',\n",
       "  'i',\n",
       "  'love',\n",
       "  'me',\n",
       "  'some',\n",
       "  'carlmy',\n",
       "  'old',\n",
       "  'is',\n",
       "  'sad',\n",
       "  'nowlol'],\n",
       " ['bryan', 'hasnt', 'replied', 'about', 'wingnuts'],\n",
       " ['watching', 'southpark', 'for', 'another', 'minutes'],\n",
       " ['thanks',\n",
       "  'amy',\n",
       "  'that',\n",
       "  'video',\n",
       "  'is',\n",
       "  'so',\n",
       "  'awesome',\n",
       "  'did',\n",
       "  'you',\n",
       "  'see',\n",
       "  'tmh',\n",
       "  'hes',\n",
       "  'amazing',\n",
       "  'in',\n",
       "  'that',\n",
       "  'too',\n",
       "  'bouncy',\n",
       "  'bouncy',\n",
       "  'bouncy'],\n",
       " ['lmaoha', 'no', 'i', 'just', 'simply', 'wanted', 'to', 'go', 'to', 'ny'],\n",
       " ['is', 'bored', 'cant', 'go', 'on', 'habbo', 'stupid', 'ban'],\n",
       " ['tried', 'on', 'all', 'the', 'shoes', 'in', 'new', 'look'],\n",
       " ['its', 'too', 'early', 'i', 'wanna', 'go', 'back', 'to', 'sleeep'],\n",
       " ['i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'i',\n",
       "  'am',\n",
       "  'my',\n",
       "  'sisters',\n",
       "  'refusn',\n",
       "  'to',\n",
       "  'get',\n",
       "  'me',\n",
       "  'a',\n",
       "  'ticket',\n",
       "  'now',\n",
       "  'what',\n",
       "  'you',\n",
       "  'doing',\n",
       "  'next',\n",
       "  'week'],\n",
       " ['oh', 'wowhope', 'hes', 'ok', 'u', 'take', 'him', 'the', 'vet'],\n",
       " ['he',\n",
       "  'died',\n",
       "  'wait',\n",
       "  'what',\n",
       "  'about',\n",
       "  'magic',\n",
       "  'jack',\n",
       "  'i',\n",
       "  'just',\n",
       "  'read',\n",
       "  'it'],\n",
       " ['ive', 'just', 'woken', 'up'],\n",
       " ['hahaha',\n",
       "  'oh',\n",
       "  'man',\n",
       "  'please',\n",
       "  'come',\n",
       "  'to',\n",
       "  'pomona',\n",
       "  'i',\n",
       "  'would',\n",
       "  'love',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'everyday',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'like',\n",
       "  'once',\n",
       "  'a',\n",
       "  'year',\n",
       "  'if',\n",
       "  'that'],\n",
       " ['jon',\n",
       "  'made',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'greatest',\n",
       "  'dinners',\n",
       "  'ever',\n",
       "  'roast',\n",
       "  'pork',\n",
       "  'tenderloin',\n",
       "  'on',\n",
       "  'a',\n",
       "  'bed',\n",
       "  'of',\n",
       "  'wild',\n",
       "  'rice',\n",
       "  'on',\n",
       "  'a',\n",
       "  'bed',\n",
       "  'of',\n",
       "  'mixed',\n",
       "  'greens',\n",
       "  'yummy',\n",
       "  'sauce',\n",
       "  'no',\n",
       "  'wine'],\n",
       " ['nooooo', 'its', 'raininghad', 'leave', 'the', 'beach'],\n",
       " ['shower',\n",
       "  'class',\n",
       "  'more',\n",
       "  'class',\n",
       "  'taking',\n",
       "  'care',\n",
       "  'of',\n",
       "  'my',\n",
       "  'ladyfriend',\n",
       "  'writing',\n",
       "  'like',\n",
       "  'theres',\n",
       "  'no',\n",
       "  'tomorrow'],\n",
       " ['rockstar',\n",
       "  'photographer',\n",
       "  'shoot',\n",
       "  'went',\n",
       "  'great',\n",
       "  'tonight',\n",
       "  'a',\n",
       "  'little',\n",
       "  'different',\n",
       "  'than',\n",
       "  'the',\n",
       "  'usual',\n",
       "  'stuff',\n",
       "  'very',\n",
       "  'nice'],\n",
       " ['great',\n",
       "  'pics',\n",
       "  'you',\n",
       "  'should',\n",
       "  'try',\n",
       "  'to',\n",
       "  'start',\n",
       "  'selling',\n",
       "  'your',\n",
       "  'race',\n",
       "  'photos',\n",
       "  'to',\n",
       "  'runners'],\n",
       " ['goodmorning',\n",
       "  'twitter',\n",
       "  'oh',\n",
       "  'my',\n",
       "  'gosh',\n",
       "  'i',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'soooo',\n",
       "  'nice',\n",
       "  'lol',\n",
       "  'oh',\n",
       "  'hai',\n",
       "  'thar',\n",
       "  'twitterverse',\n",
       "  'happy',\n",
       "  'mothersday',\n",
       "  'everybody',\n",
       "  'especially',\n",
       "  'mine'],\n",
       " ['dulay',\n",
       "  'i',\n",
       "  'swear',\n",
       "  'it',\n",
       "  'took',\n",
       "  'me',\n",
       "  'hours',\n",
       "  'to',\n",
       "  'get',\n",
       "  'from',\n",
       "  'bel',\n",
       "  'air',\n",
       "  'to',\n",
       "  'alabang',\n",
       "  'but',\n",
       "  'yes',\n",
       "  'i',\n",
       "  'loved',\n",
       "  'reminiscing',\n",
       "  'about',\n",
       "  'our',\n",
       "  'hk',\n",
       "  'trip',\n",
       "  'with',\n",
       "  'you'],\n",
       " ['hubby',\n",
       "  'went',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'my',\n",
       "  'fringe',\n",
       "  'comics',\n",
       "  'today',\n",
       "  'store',\n",
       "  'by',\n",
       "  'his',\n",
       "  'work',\n",
       "  'that',\n",
       "  'store',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'business',\n",
       "  'too',\n",
       "  'no',\n",
       "  'comix',\n",
       "  'in',\n",
       "  'houston',\n",
       "  'have',\n",
       "  'web'],\n",
       " ['the', 'world', 'is', 'just', 'amazing'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'what',\n",
       "  'im',\n",
       "  'doing',\n",
       "  'and',\n",
       "  'i',\n",
       "  'am',\n",
       "  'completely',\n",
       "  'lost'],\n",
       " ['gadgetopia',\n",
       "  'need',\n",
       "  'to',\n",
       "  'dm',\n",
       "  'you',\n",
       "  'but',\n",
       "  'youre',\n",
       "  'not',\n",
       "  'following',\n",
       "  'me',\n",
       "  'will',\n",
       "  'send',\n",
       "  'email'],\n",
       " ['awww', 'hes', 'too', 'cutewish', 'i', 'couldve', 'gone'],\n",
       " ['got',\n",
       "  'my',\n",
       "  'cable',\n",
       "  'set',\n",
       "  'up',\n",
       "  'win',\n",
       "  'got',\n",
       "  'my',\n",
       "  'lock',\n",
       "  'put',\n",
       "  'on',\n",
       "  'my',\n",
       "  'door',\n",
       "  'win',\n",
       "  'feeling',\n",
       "  'a',\n",
       "  'tad',\n",
       "  'neglected',\n",
       "  'fail'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'that',\n",
       "  'may',\n",
       "  'look',\n",
       "  'a',\n",
       "  'little',\n",
       "  'silly',\n",
       "  'also',\n",
       "  'my',\n",
       "  'camera',\n",
       "  'is',\n",
       "  'broken',\n",
       "  'so',\n",
       "  'no',\n",
       "  'photo'],\n",
       " ['just',\n",
       "  'had',\n",
       "  'a',\n",
       "  'great',\n",
       "  'talk',\n",
       "  'with',\n",
       "  'grace',\n",
       "  'about',\n",
       "  'how',\n",
       "  'awesome',\n",
       "  'god',\n",
       "  'is',\n",
       "  'and',\n",
       "  'how',\n",
       "  'he',\n",
       "  'worksthat',\n",
       "  'somehow',\n",
       "  'started',\n",
       "  'with',\n",
       "  'how',\n",
       "  'remote',\n",
       "  'controls',\n",
       "  'work'],\n",
       " ['this', 'day', 'has', 'beasted', 'me'],\n",
       " ['ill', 'be', 'listening'],\n",
       " ['oh',\n",
       "  'nou',\n",
       "  'dont',\n",
       "  'have',\n",
       "  'to',\n",
       "  'hit',\n",
       "  'him',\n",
       "  'up',\n",
       "  'he',\n",
       "  'had',\n",
       "  'a',\n",
       "  'family',\n",
       "  'emergency',\n",
       "  'so',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'lil',\n",
       "  'delay',\n",
       "  'just',\n",
       "  'cant',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'see',\n",
       "  'them'],\n",
       " ['sitting',\n",
       "  'at',\n",
       "  'home',\n",
       "  'doing',\n",
       "  'nothing',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'like',\n",
       "  'this',\n",
       "  'all',\n",
       "  'weekend'],\n",
       " ['oh', 'nevermind', 'i', 'think', 'this', 'thing', 'is', 'unsalvageable'],\n",
       " ['flew',\n",
       "  'brisbane',\n",
       "  'lax',\n",
       "  'today',\n",
       "  'great',\n",
       "  'flight',\n",
       "  'love',\n",
       "  'the',\n",
       "  'lights',\n",
       "  'shame',\n",
       "  'about',\n",
       "  'one',\n",
       "  'drink',\n",
       "  'limit',\n",
       "  'though'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'should',\n",
       "  'go',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'considering',\n",
       "  'i',\n",
       "  'hav',\n",
       "  'to',\n",
       "  'b',\n",
       "  'up',\n",
       "  'on'],\n",
       " ['if',\n",
       "  'i',\n",
       "  'told',\n",
       "  'you',\n",
       "  'how',\n",
       "  'often',\n",
       "  'i',\n",
       "  'wash',\n",
       "  'my',\n",
       "  'hair',\n",
       "  'you',\n",
       "  'would',\n",
       "  'never',\n",
       "  'speak',\n",
       "  'to',\n",
       "  'me',\n",
       "  'again'],\n",
       " ['i',\n",
       "  'just',\n",
       "  'spent',\n",
       "  'hours',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'a',\n",
       "  'blog',\n",
       "  'topic',\n",
       "  'and',\n",
       "  'ended',\n",
       "  'up',\n",
       "  'inventing',\n",
       "  'my',\n",
       "  'own',\n",
       "  'grrrr'],\n",
       " ['seems', 'to', 'have', 'disappeared', 'out', 'of', 'my', 'life'],\n",
       " ['happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'to',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'and',\n",
       "  'every',\n",
       "  'mom',\n",
       "  'everywhere',\n",
       "  'off',\n",
       "  'for',\n",
       "  'a',\n",
       "  'stroll',\n",
       "  'at',\n",
       "  'the',\n",
       "  'beaches',\n",
       "  'laterhopefully'],\n",
       " ['ohhh',\n",
       "  'i',\n",
       "  'wanna',\n",
       "  'go',\n",
       "  'gahhh',\n",
       "  'but',\n",
       "  'i',\n",
       "  'dunnooooooo',\n",
       "  's',\n",
       "  'me',\n",
       "  'confuzzzledd',\n",
       "  'should',\n",
       "  'i',\n",
       "  'or',\n",
       "  'not'],\n",
       " ['kittykat', 'hello', 'new', 'follower', 'haha', 'how', 'are', 'ya'],\n",
       " ['haha', 'best', 'thing', 'about', 'office', 'birthdays', 'hey'],\n",
       " ['i',\n",
       "  'never',\n",
       "  'knew',\n",
       "  'i',\n",
       "  'could',\n",
       "  'miss',\n",
       "  'my',\n",
       "  'phone',\n",
       "  'so',\n",
       "  'much',\n",
       "  'for',\n",
       "  'hours',\n",
       "  'till',\n",
       "  'they',\n",
       "  'told',\n",
       "  'me',\n",
       "  'i',\n",
       "  'wont',\n",
       "  'have',\n",
       "  'it',\n",
       "  'back',\n",
       "  'till',\n",
       "  'then'],\n",
       " ['lay',\n",
       "  'aww',\n",
       "  'well',\n",
       "  'i',\n",
       "  'just',\n",
       "  'randomly',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'and',\n",
       "  'now',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'sleep',\n",
       "  'too',\n",
       "  'many',\n",
       "  'things',\n",
       "  'on',\n",
       "  'my',\n",
       "  'mind'],\n",
       " ['thats',\n",
       "  'it',\n",
       "  'its',\n",
       "  'done',\n",
       "  'already',\n",
       "  'this',\n",
       "  'is',\n",
       "  'one',\n",
       "  'proof',\n",
       "  'that',\n",
       "  'theres',\n",
       "  'nothing',\n",
       "  'fair',\n",
       "  'in',\n",
       "  'this',\n",
       "  'world'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'going',\n",
       "  'to',\n",
       "  'see',\n",
       "  'how',\n",
       "  'long',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do',\n",
       "  'this',\n",
       "  'for'],\n",
       " ['you',\n",
       "  'better',\n",
       "  'come',\n",
       "  'here',\n",
       "  'by',\n",
       "  'the',\n",
       "  'time',\n",
       "  'i',\n",
       "  'count',\n",
       "  'to',\n",
       "  'or',\n",
       "  'else',\n",
       "  'bam'],\n",
       " ['prd', 'take', 'a', 'long', 'time', 'to', 'review'],\n",
       " ['u',\n",
       "  'know',\n",
       "  'kids',\n",
       "  'do',\n",
       "  'what',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'what',\n",
       "  'we',\n",
       "  'say',\n",
       "  'well',\n",
       "  'dont',\n",
       "  'we',\n",
       "  'all',\n",
       "  'really'],\n",
       " ['ugh',\n",
       "  'i',\n",
       "  'wanna',\n",
       "  'play',\n",
       "  'dnd',\n",
       "  'but',\n",
       "  'i',\n",
       "  'know',\n",
       "  'im',\n",
       "  'going',\n",
       "  'to',\n",
       "  'fail',\n",
       "  'this',\n",
       "  'final',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'study'],\n",
       " ['hi',\n",
       "  'thx',\n",
       "  'for',\n",
       "  'following',\n",
       "  'i',\n",
       "  'teach',\n",
       "  'some',\n",
       "  'chinese',\n",
       "  'lessons',\n",
       "  'on',\n",
       "  'youtube',\n",
       "  'pls',\n",
       "  'feel',\n",
       "  'free',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'look'],\n",
       " ['how', 'sad', 'are', 'you', 'saying', 'that', 'im', 'fat', 'tears'],\n",
       " ['why',\n",
       "  'thank',\n",
       "  'you',\n",
       "  'i',\n",
       "  'might',\n",
       "  'just',\n",
       "  'take',\n",
       "  'you',\n",
       "  'up',\n",
       "  'on',\n",
       "  'your',\n",
       "  'offer'],\n",
       " ['im',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'find',\n",
       "  'the',\n",
       "  'driver',\n",
       "  'for',\n",
       "  'my',\n",
       "  'microsoft',\n",
       "  'lifecam',\n",
       "  'webcam',\n",
       "  'and',\n",
       "  'cant',\n",
       "  'find',\n",
       "  'it',\n",
       "  'anywhere',\n",
       "  'anyone',\n",
       "  'have',\n",
       "  'any',\n",
       "  'links'],\n",
       " ['finally',\n",
       "  'get',\n",
       "  'to',\n",
       "  'lay',\n",
       "  'down',\n",
       "  'for',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'i',\n",
       "  'have',\n",
       "  'a',\n",
       "  'major',\n",
       "  'headache'],\n",
       " ['yes',\n",
       "  'you',\n",
       "  'should',\n",
       "  'go',\n",
       "  'see',\n",
       "  'star',\n",
       "  'trek',\n",
       "  'its',\n",
       "  'sooooo',\n",
       "  'much',\n",
       "  'fun'],\n",
       " ['mitchel',\n",
       "  'you',\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'how',\n",
       "  'much',\n",
       "  'i',\n",
       "  'want',\n",
       "  'to',\n",
       "  'call',\n",
       "  'you',\n",
       "  'but',\n",
       "  'it',\n",
       "  'costs',\n",
       "  'loads',\n",
       "  'to',\n",
       "  'call',\n",
       "  'from',\n",
       "  'england'],\n",
       " ['stupid',\n",
       "  'me',\n",
       "  'accidentally',\n",
       "  'gave',\n",
       "  'my',\n",
       "  'honey',\n",
       "  'the',\n",
       "  'atomic',\n",
       "  'flavored',\n",
       "  'buffalo',\n",
       "  'wings',\n",
       "  'and',\n",
       "  'now',\n",
       "  'his',\n",
       "  'stomach',\n",
       "  'feels',\n",
       "  'just',\n",
       "  'awful',\n",
       "  'im',\n",
       "  'sorry',\n",
       "  'baby'],\n",
       " ['very',\n",
       "  'relaxing',\n",
       "  'thank',\n",
       "  'you',\n",
       "  'hope',\n",
       "  'you',\n",
       "  'get',\n",
       "  'to',\n",
       "  'put',\n",
       "  'your',\n",
       "  'feet',\n",
       "  'up',\n",
       "  'tomorrow',\n",
       "  'and',\n",
       "  'enjoy',\n",
       "  'the',\n",
       "  'day'],\n",
       " ['yessir', 'that', 'is', 'right'],\n",
       " ['night'],\n",
       " ['writing',\n",
       "  'my',\n",
       "  'music',\n",
       "  'lit',\n",
       "  'final',\n",
       "  'paper',\n",
       "  'on',\n",
       "  'mozarts',\n",
       "  'eine',\n",
       "  'kleine',\n",
       "  'nashtmusik',\n",
       "  'mom',\n",
       "  'is',\n",
       "  'giving',\n",
       "  'me',\n",
       "  'a',\n",
       "  'handand',\n",
       "  'im',\n",
       "  'actually',\n",
       "  'having',\n",
       "  'a',\n",
       "  'great',\n",
       "  'time'],\n",
       " ['i',\n",
       "  'got',\n",
       "  'over',\n",
       "  'the',\n",
       "  'crush',\n",
       "  'issue',\n",
       "  'but',\n",
       "  'now',\n",
       "  'tomorrow',\n",
       "  'my',\n",
       "  'friend',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'india',\n",
       "  'for',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'summer',\n",
       "  'im',\n",
       "  'back',\n",
       "  'to',\n",
       "  'being',\n",
       "  'sad'],\n",
       " ['too', 'warm'],\n",
       " ['ada',\n",
       "  'acara',\n",
       "  'menarik',\n",
       "  'lain',\n",
       "  'keys',\n",
       "  'to',\n",
       "  'the',\n",
       "  'vip',\n",
       "  'di',\n",
       "  'channel',\n",
       "  'v',\n",
       "  'ttg',\n",
       "  'straight',\n",
       "  'yg',\n",
       "  'dikasih',\n",
       "  'tasks',\n",
       "  'to',\n",
       "  'approach',\n",
       "  'strangers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'crowd',\n",
       "  'hmm'],\n",
       " ['well', 'hit', 'me', 'and', 'we', 'can', 'seeit', 'depends', 'then'],\n",
       " ['aww', 'thanx', 'andy'],\n",
       " ['some',\n",
       "  'goodies',\n",
       "  'bagged',\n",
       "  'at',\n",
       "  'the',\n",
       "  'car',\n",
       "  'boot',\n",
       "  'including',\n",
       "  'some',\n",
       "  'very',\n",
       "  'cute',\n",
       "  'cross',\n",
       "  'stitch',\n",
       "  'birds',\n",
       "  'for',\n",
       "  'my',\n",
       "  'craft',\n",
       "  'room',\n",
       "  'the',\n",
       "  'man',\n",
       "  'selling',\n",
       "  'was',\n",
       "  'a',\n",
       "  'sweetie'],\n",
       " ['has',\n",
       "  'just',\n",
       "  'finished',\n",
       "  'ironing',\n",
       "  'his',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'church',\n",
       "  'gonna',\n",
       "  'walk',\n",
       "  'the',\n",
       "  'dog',\n",
       "  'now',\n",
       "  'then',\n",
       "  'grab',\n",
       "  'a',\n",
       "  'showershave',\n",
       "  'and',\n",
       "  'be',\n",
       "  'off',\n",
       "  'jottonia',\n",
       "  'looks',\n",
       "  'good',\n",
       "  'too'],\n",
       " ['shower', 'time'],\n",
       " ['coooooooool', 'dooooooooown', 'patience', 'is', 'virtue'],\n",
       " ['gotta',\n",
       "  'drop',\n",
       "  'off',\n",
       "  'some',\n",
       "  'car',\n",
       "  'parts',\n",
       "  'for',\n",
       "  'a',\n",
       "  'buddy',\n",
       "  'to',\n",
       "  'press',\n",
       "  'out',\n",
       "  'then',\n",
       "  'to',\n",
       "  'the',\n",
       "  'dentist'],\n",
       " ['i', 'cant', 'call', 'im', 'at', 'work'],\n",
       " ['going',\n",
       "  'to',\n",
       "  'the',\n",
       "  'courthouse',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'tags',\n",
       "  'taxes',\n",
       "  'on',\n",
       "  'all',\n",
       "  'our',\n",
       "  'carsthis',\n",
       "  'is',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'expensive'],\n",
       " ['so',\n",
       "  'tired',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'bed',\n",
       "  'really',\n",
       "  'in',\n",
       "  'the',\n",
       "  'mood',\n",
       "  'for',\n",
       "  'salt',\n",
       "  'pepper',\n",
       "  'chicken',\n",
       "  'wings',\n",
       "  'noodles',\n",
       "  'but',\n",
       "  'have',\n",
       "  'no',\n",
       "  'money',\n",
       "  'on',\n",
       "  'me',\n",
       "  'for',\n",
       "  'a',\n",
       "  'chinese'],\n",
       " ['the',\n",
       "  'usual',\n",
       "  'two',\n",
       "  'family',\n",
       "  'parties',\n",
       "  'today',\n",
       "  'happy',\n",
       "  'birthday',\n",
       "  'lily'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'on',\n",
       "  'herefinally',\n",
       "  'and',\n",
       "  'yay',\n",
       "  'seriously',\n",
       "  'that',\n",
       "  'made',\n",
       "  'my',\n",
       "  'day',\n",
       "  'oh',\n",
       "  'fellow',\n",
       "  'hell',\n",
       "  'ruler'],\n",
       " ['goodnight', 'magic', 'and', 'pretty', 'world'],\n",
       " ['doesnt',\n",
       "  'have',\n",
       "  'a',\n",
       "  'hangover',\n",
       "  'and',\n",
       "  'is',\n",
       "  'getting',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'a',\n",
       "  'good',\n",
       "  'ol',\n",
       "  'english',\n",
       "  'fry',\n",
       "  'up'],\n",
       " ['waiting',\n",
       "  'to',\n",
       "  'put',\n",
       "  'my',\n",
       "  'story',\n",
       "  'about',\n",
       "  'stereo',\n",
       "  'skyline',\n",
       "  'up',\n",
       "  'dont',\n",
       "  'know',\n",
       "  'where',\n",
       "  'to',\n",
       "  'put',\n",
       "  'it',\n",
       "  'boooo'],\n",
       " ['working', 'now'],\n",
       " ['just', 'at', 'starbucks', 'with', 'farrah'],\n",
       " ['ginniejean',\n",
       "  'theres',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'mojo',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'place',\n",
       "  'yes'],\n",
       " ['third', 'date', 'went', 'wellmoving', 'on', 'to', 'fourth'],\n",
       " ['mad',\n",
       "  'tired',\n",
       "  'but',\n",
       "  'its',\n",
       "  'the',\n",
       "  'hols',\n",
       "  'i',\n",
       "  'miss',\n",
       "  'chomp',\n",
       "  'chomp',\n",
       "  'terribly'],\n",
       " ['is', 'finally', 'starting', 'her', 'assignments'],\n",
       " ['good', 'morning', 'ready', 'to', 'start', 'this', 'week'],\n",
       " ['ive',\n",
       "  'read',\n",
       "  'good',\n",
       "  'things',\n",
       "  'bout',\n",
       "  'it',\n",
       "  'just',\n",
       "  'not',\n",
       "  'feelin',\n",
       "  'it',\n",
       "  'tonight',\n",
       "  'proly',\n",
       "  'finish',\n",
       "  'it',\n",
       "  'tomorrow',\n",
       "  'after',\n",
       "  'star',\n",
       "  'trek'],\n",
       " ['so', 'glad', 'im', 'finally', 'done', 'with', 'finals'],\n",
       " ['watching',\n",
       "  'that',\n",
       "  'thing',\n",
       "  'you',\n",
       "  'do',\n",
       "  'on',\n",
       "  'comcast',\n",
       "  'missing',\n",
       "  'my',\n",
       "  'boo',\n",
       "  'like',\n",
       "  'crrrrrazy'],\n",
       " ['it',\n",
       "  'just',\n",
       "  'had',\n",
       "  'to',\n",
       "  'rain',\n",
       "  'on',\n",
       "  'me',\n",
       "  'almost',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'day',\n",
       "  'now',\n",
       "  'my',\n",
       "  'clothes',\n",
       "  'are',\n",
       "  'wet'],\n",
       " ['yeah',\n",
       "  'we',\n",
       "  'only',\n",
       "  'went',\n",
       "  'for',\n",
       "  'days',\n",
       "  'im',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'get',\n",
       "  'back',\n",
       "  'in',\n",
       "  'november',\n",
       "  'with',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'for',\n",
       "  'super',\n",
       "  'soak',\n",
       "  'stars',\n",
       "  'weekend'],\n",
       " ['i',\n",
       "  'miss',\n",
       "  'u',\n",
       "  'guys',\n",
       "  'too',\n",
       "  'i',\n",
       "  'prob',\n",
       "  'wont',\n",
       "  'b',\n",
       "  'bk',\n",
       "  'til',\n",
       "  'august',\n",
       "  'sumtime',\n",
       "  'but',\n",
       "  'if',\n",
       "  'i',\n",
       "  'come',\n",
       "  'bk',\n",
       "  'anytime',\n",
       "  'then',\n",
       "  'ill',\n",
       "  'sure',\n",
       "  'let',\n",
       "  'u',\n",
       "  'kno'],\n",
       " ['okay',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'hes',\n",
       "  'alright',\n",
       "  'kk',\n",
       "  'cuidalo',\n",
       "  'let',\n",
       "  'him',\n",
       "  'know',\n",
       "  'hes',\n",
       "  'a',\n",
       "  'got',\n",
       "  'friend',\n",
       "  'in',\n",
       "  'us',\n",
       "  'aha'],\n",
       " ['it',\n",
       "  'will',\n",
       "  'if',\n",
       "  'i',\n",
       "  'do',\n",
       "  'it',\n",
       "  'in',\n",
       "  'a',\n",
       "  'round',\n",
       "  'about',\n",
       "  'way',\n",
       "  'i',\n",
       "  'ahve',\n",
       "  'to',\n",
       "  'copy',\n",
       "  'the',\n",
       "  'public',\n",
       "  'contacts',\n",
       "  'into',\n",
       "  'my',\n",
       "  'personal',\n",
       "  'contacts',\n",
       "  'first',\n",
       "  'no',\n",
       "  'big',\n",
       "  'deal'],\n",
       " ['trying', 'to', 'figure', 'it', 'out'],\n",
       " ['ill',\n",
       "  'update',\n",
       "  'you',\n",
       "  'i',\n",
       "  'had',\n",
       "  'to',\n",
       "  'leave',\n",
       "  'him',\n",
       "  'at',\n",
       "  'the',\n",
       "  'vet',\n",
       "  'for',\n",
       "  'tests',\n",
       "  'and',\n",
       "  'xrays'],\n",
       " ['went',\n",
       "  'to',\n",
       "  'see',\n",
       "  'hannah',\n",
       "  'montana',\n",
       "  'movie',\n",
       "  'on',\n",
       "  'saturday',\n",
       "  'loved',\n",
       "  'it',\n",
       "  'still',\n",
       "  'cant',\n",
       "  'work',\n",
       "  'twitter',\n",
       "  'out',\n",
       "  'though'],\n",
       " ['lol', 'ive', 'done', 'that', 'one', 'im', 'a', 'victim', 'that', 'lol'],\n",
       " ['i',\n",
       "  'would',\n",
       "  'slip',\n",
       "  'and',\n",
       "  'fall',\n",
       "  'on',\n",
       "  'the',\n",
       "  'dirty',\n",
       "  'school',\n",
       "  'bathroom',\n",
       "  'floor',\n",
       "  'fml'],\n",
       " ['just',\n",
       "  'got',\n",
       "  'confirmed',\n",
       "  'that',\n",
       "  'its',\n",
       "  'pizzatime',\n",
       "  'with',\n",
       "  'some',\n",
       "  'ex',\n",
       "  'coworkers',\n",
       "  'on',\n",
       "  'fridaylooking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'it'],\n",
       " ['well',\n",
       "  'paisley',\n",
       "  'has',\n",
       "  'one',\n",
       "  'of',\n",
       "  'those',\n",
       "  'cone',\n",
       "  'things',\n",
       "  'around',\n",
       "  'her',\n",
       "  'headso',\n",
       "  'funny',\n",
       "  'but',\n",
       "  'i',\n",
       "  'feel',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'her'],\n",
       " ['ugggh',\n",
       "  'idk',\n",
       "  'how',\n",
       "  'to',\n",
       "  'do',\n",
       "  'that',\n",
       "  'but',\n",
       "  'i',\n",
       "  'only',\n",
       "  'wanna',\n",
       "  'stop',\n",
       "  'getting',\n",
       "  'texts',\n",
       "  'from',\n",
       "  'twitterr',\n",
       "  'ilse'],\n",
       " ['cant',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'november',\n",
       "  'for',\n",
       "  'jobros',\n",
       "  'concert',\n",
       "  'in',\n",
       "  'examination'],\n",
       " ['been',\n",
       "  'there',\n",
       "  'done',\n",
       "  'that',\n",
       "  'it',\n",
       "  'always',\n",
       "  'ended',\n",
       "  'up',\n",
       "  'with',\n",
       "  'me',\n",
       "  'selling',\n",
       "  'the',\n",
       "  'machine',\n",
       "  'and',\n",
       "  'going',\n",
       "  'back',\n",
       "  'to',\n",
       "  'my',\n",
       "  'mac'],\n",
       " ['just',\n",
       "  'came',\n",
       "  'back',\n",
       "  'from',\n",
       "  'watching',\n",
       "  'terminator',\n",
       "  'salvation',\n",
       "  'cathay',\n",
       "  'its',\n",
       "  'soso',\n",
       "  'only',\n",
       "  'not',\n",
       "  'so',\n",
       "  'much',\n",
       "  'action',\n",
       "  'but',\n",
       "  'i',\n",
       "  'feel',\n",
       "  'sorry',\n",
       "  'for',\n",
       "  'marcus',\n",
       "  'though'],\n",
       " ['is',\n",
       "  'sitting',\n",
       "  'thru',\n",
       "  'the',\n",
       "  'boring',\n",
       "  'bits',\n",
       "  'in',\n",
       "  'titanic',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'the',\n",
       "  'good',\n",
       "  'bit',\n",
       "  'to',\n",
       "  'start',\n",
       "  'in',\n",
       "  'couple',\n",
       "  'of',\n",
       "  'hours'],\n",
       " ['fire', 'and', 'urban', 'at', 'rock', 'challenge'],\n",
       " ['i',\n",
       "  'cant',\n",
       "  'believe',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'i',\n",
       "  'had',\n",
       "  'a',\n",
       "  'morning',\n",
       "  'shift',\n",
       "  'today',\n",
       "  'and',\n",
       "  'told',\n",
       "  'alex',\n",
       "  'that',\n",
       "  'i',\n",
       "  'could',\n",
       "  'take',\n",
       "  'him',\n",
       "  'to',\n",
       "  'the',\n",
       "  'airport',\n",
       "  'his',\n",
       "  'flight',\n",
       "  'is',\n",
       "  'during',\n",
       "  'my',\n",
       "  'shift'],\n",
       " ['my',\n",
       "  'poor',\n",
       "  'heather',\n",
       "  'she',\n",
       "  'didnt',\n",
       "  'make',\n",
       "  'the',\n",
       "  'cheerleading',\n",
       "  'squad',\n",
       "  'im',\n",
       "  'sorry',\n",
       "  'babygirl',\n",
       "  'maybe',\n",
       "  'next',\n",
       "  'year'],\n",
       " ['well', 'now', 'i', 'do'],\n",
       " ['crazzyyyy',\n",
       "  'but',\n",
       "  'just',\n",
       "  'this',\n",
       "  'summer',\n",
       "  'cuz',\n",
       "  'ci',\n",
       "  'are',\n",
       "  'very',\n",
       "  'close',\n",
       "  'to',\n",
       "  'rd',\n",
       "  's'],\n",
       " ['i',\n",
       "  'jus',\n",
       "  'love',\n",
       "  'doin',\n",
       "  'night',\n",
       "  'shiftswill',\n",
       "  'be',\n",
       "  'done',\n",
       "  'in',\n",
       "  'an',\n",
       "  'hour'],\n",
       " ['morning', 'tweepleway', 'to', 'early', 'again'],\n",
       " ['i', 'have', 'to', 'reupload', 'the', 'thing', 'again'],\n",
       " ['you',\n",
       "  'know',\n",
       "  'your',\n",
       "  'updates',\n",
       "  'are',\n",
       "  'really',\n",
       "  'amusing',\n",
       "  'how',\n",
       "  'was',\n",
       "  'the',\n",
       "  'prop',\n",
       "  'auctionhow',\n",
       "  'much',\n",
       "  'did',\n",
       "  'that',\n",
       "  'baseship',\n",
       "  'bed',\n",
       "  'go',\n",
       "  'for'],\n",
       " ['loves',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'theres',\n",
       "  'only',\n",
       "  'days',\n",
       "  'of',\n",
       "  'school',\n",
       "  'left'],\n",
       " ['oh', 'no', 'i', 'hope', 'its', 'not', 'bad'],\n",
       " ['awesomeam',\n",
       "  'headin',\n",
       "  'there',\n",
       "  'that',\n",
       "  'nite',\n",
       "  'after',\n",
       "  'my',\n",
       "  'grad',\n",
       "  'dinner',\n",
       "  'c',\n",
       "  'u',\n",
       "  'then',\n",
       "  'boi',\n",
       "  'hehe'],\n",
       " ['beery',\n",
       "  'yeah',\n",
       "  'little',\n",
       "  'rough',\n",
       "  'this',\n",
       "  'morning',\n",
       "  'but',\n",
       "  'more',\n",
       "  'tonight',\n",
       "  'and',\n",
       "  'tomorrow',\n",
       "  'night',\n",
       "  'if',\n",
       "  'all',\n",
       "  'goes',\n",
       "  'as',\n",
       "  'planned',\n",
       "  'caloric',\n",
       "  'intake',\n",
       "  'off',\n",
       "  'the',\n",
       "  'charts'],\n",
       " ['aww',\n",
       "  'congrats',\n",
       "  'to',\n",
       "  'the',\n",
       "  'family',\n",
       "  'send',\n",
       "  'me',\n",
       "  'piccies',\n",
       "  'in',\n",
       "  'the',\n",
       "  'email'],\n",
       " ['uber',\n",
       "  'bored',\n",
       "  'atm',\n",
       "  'after',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'blue',\n",
       "  'will',\n",
       "  'have',\n",
       "  'shower',\n",
       "  'then',\n",
       "  'watch',\n",
       "  'house',\n",
       "  'or',\n",
       "  'vid',\n",
       "  'then',\n",
       "  'csi',\n",
       "  'csi',\n",
       "  'ny',\n",
       "  'bones',\n",
       "  'double',\n",
       "  'yay'],\n",
       " ['i', 'cant'],\n",
       " ['strongly',\n",
       "  'agrees',\n",
       "  'with',\n",
       "  'jason',\n",
       "  'about',\n",
       "  'wolverine',\n",
       "  'but',\n",
       "  'not',\n",
       "  'about',\n",
       "  'hugh',\n",
       "  'jackman',\n",
       "  'sorry',\n",
       "  'no',\n",
       "  'kids',\n",
       "  'for',\n",
       "  'this',\n",
       "  'mouse'],\n",
       " ['you', 'okay', 'bby'],\n",
       " ['okay',\n",
       "  'okay',\n",
       "  'sleep',\n",
       "  'for',\n",
       "  'realz',\n",
       "  'now',\n",
       "  'goodnight',\n",
       "  'waves',\n",
       "  'to',\n",
       "  'followers'],\n",
       " ['omg', 'my', 'mom', 'just', 'called', 'im', 'too', 'late', 'hes', 'gone'],\n",
       " ['just',\n",
       "  'lost',\n",
       "  'my',\n",
       "  'internet',\n",
       "  'signal',\n",
       "  'how',\n",
       "  'will',\n",
       "  'life',\n",
       "  'go',\n",
       "  'on'],\n",
       " ['sorry',\n",
       "  'we',\n",
       "  'didnt',\n",
       "  'get',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'chat',\n",
       "  'at',\n",
       "  'caught',\n",
       "  'glimpse',\n",
       "  'of',\n",
       "  'you',\n",
       "  'across',\n",
       "  'room',\n",
       "  'but',\n",
       "  'was',\n",
       "  'dragged',\n",
       "  'home',\n",
       "  'prematurely'],\n",
       " ['buckley',\n",
       "  'good',\n",
       "  'for',\n",
       "  'you',\n",
       "  'mate',\n",
       "  'sadly',\n",
       "  'i',\n",
       "  'couldnt',\n",
       "  'get',\n",
       "  'pissed',\n",
       "  'tonight',\n",
       "  'driving',\n",
       "  'bad',\n",
       "  'times'],\n",
       " ['i', 'just', 'bit', 'my', 'tongue', 'blood', 'everywhere'],\n",
       " ['pulled',\n",
       "  'up',\n",
       "  'walmart',\n",
       "  'aunt',\n",
       "  'got',\n",
       "  'out',\n",
       "  'went',\n",
       "  'in',\n",
       "  'i',\n",
       "  'fell',\n",
       "  'asleep',\n",
       "  'hours',\n",
       "  'later',\n",
       "  'were',\n",
       "  'r',\n",
       "  'you',\n",
       "  'lol'],\n",
       " ['searching',\n",
       "  'my',\n",
       "  'home',\n",
       "  'for',\n",
       "  'a',\n",
       "  'few',\n",
       "  'things',\n",
       "  'to',\n",
       "  'cook',\n",
       "  'them',\n",
       "  'for',\n",
       "  'dinner',\n",
       "  'this',\n",
       "  'evening',\n",
       "  'its',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'so',\n",
       "  'guess',\n",
       "  'who',\n",
       "  'im',\n",
       "  'eating',\n",
       "  'with'],\n",
       " ['very', 'very', 'cute', 'and', 'fun', 'to', 'watch'],\n",
       " ['woke',\n",
       "  'up',\n",
       "  'at',\n",
       "  'then',\n",
       "  'fell',\n",
       "  'back',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'at',\n",
       "  'and',\n",
       "  'back',\n",
       "  'to',\n",
       "  'sleep',\n",
       "  'again',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'at',\n",
       "  'and',\n",
       "  'im',\n",
       "  'staying',\n",
       "  'awake',\n",
       "  'morning'],\n",
       " ['great',\n",
       "  'weekend',\n",
       "  'even',\n",
       "  'though',\n",
       "  'my',\n",
       "  'site',\n",
       "  'is',\n",
       "  'not',\n",
       "  'moved',\n",
       "  'plenty',\n",
       "  'other',\n",
       "  'things',\n",
       "  'to',\n",
       "  'do',\n",
       "  'and',\n",
       "  'learn',\n",
       "  'keeping',\n",
       "  'the',\n",
       "  'faith',\n",
       "  'and',\n",
       "  'looking',\n",
       "  'to',\n",
       "  'the',\n",
       "  'future'],\n",
       " ['dont',\n",
       "  'know',\n",
       "  'it',\n",
       "  'really',\n",
       "  'hurt',\n",
       "  'my',\n",
       "  'arm',\n",
       "  'guess',\n",
       "  'you',\n",
       "  'have',\n",
       "  'to',\n",
       "  'booze',\n",
       "  'me',\n",
       "  'or',\n",
       "  'just',\n",
       "  'ask',\n",
       "  'or',\n",
       "  'if',\n",
       "  'you',\n",
       "  'dont',\n",
       "  'believe',\n",
       "  'me'],\n",
       " ['not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'the',\n",
       "  'dance',\n",
       "  'recital',\n",
       "  'and',\n",
       "  'now',\n",
       "  'i',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'a',\n",
       "  'piece',\n",
       "  'of',\n",
       "  'cuz',\n",
       "  'it',\n",
       "  'cost',\n",
       "  'so',\n",
       "  'much',\n",
       "  'money'],\n",
       " ['tiiiiiiired',\n",
       "  'going',\n",
       "  'to',\n",
       "  'bed',\n",
       "  'drinking',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'making',\n",
       "  'out',\n",
       "  'with',\n",
       "  'boys',\n",
       "  'who',\n",
       "  'you',\n",
       "  'later',\n",
       "  'forget',\n",
       "  'their',\n",
       "  'names',\n",
       "  'dont',\n",
       "  'drink',\n",
       "  'kids',\n",
       "  'goodnight'],\n",
       " ['just',\n",
       "  'been',\n",
       "  'in',\n",
       "  'that',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'mood',\n",
       "  'not',\n",
       "  'reason',\n",
       "  'at',\n",
       "  'all',\n",
       "  'lol',\n",
       "  'but',\n",
       "  'ill',\n",
       "  'try',\n",
       "  'not',\n",
       "  'to',\n",
       "  'be',\n",
       "  'too',\n",
       "  'mushy',\n",
       "  'around',\n",
       "  'you',\n",
       "  'i',\n",
       "  'can',\n",
       "  'behave'],\n",
       " ['thats',\n",
       "  'what',\n",
       "  'doting',\n",
       "  'husbands',\n",
       "  'are',\n",
       "  'for',\n",
       "  'lol',\n",
       "  'i',\n",
       "  'hope',\n",
       "  'that',\n",
       "  'once',\n",
       "  'my',\n",
       "  'braces',\n",
       "  'go',\n",
       "  'on',\n",
       "  'i',\n",
       "  'can',\n",
       "  'eat',\n",
       "  'normally',\n",
       "  'again'],\n",
       " ['keeps',\n",
       "  'getting',\n",
       "  'such',\n",
       "  'delayed',\n",
       "  'responses',\n",
       "  'why',\n",
       "  'is',\n",
       "  'my',\n",
       "  'internet',\n",
       "  'so',\n",
       "  'messed',\n",
       "  'up'],\n",
       " ['and',\n",
       "  'dont',\n",
       "  'tell',\n",
       "  'burnsy',\n",
       "  'but',\n",
       "  'no',\n",
       "  'comparison',\n",
       "  'between',\n",
       "  'the',\n",
       "  'rocky',\n",
       "  'mountains',\n",
       "  'and',\n",
       "  'mountains',\n",
       "  'in',\n",
       "  'enlgland'],\n",
       " ['i', 'know', 'that', 'is', 'so', 'sad', 'i'],\n",
       " ['good',\n",
       "  'morning',\n",
       "  'twits',\n",
       "  'lets',\n",
       "  'makes',\n",
       "  'today',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'one',\n",
       "  'before',\n",
       "  'start',\n",
       "  'runnin'],\n",
       " ['i',\n",
       "  'could',\n",
       "  'get',\n",
       "  'away',\n",
       "  'with',\n",
       "  'it',\n",
       "  'dare',\n",
       "  'me',\n",
       "  'ill',\n",
       "  'go',\n",
       "  'buy',\n",
       "  'it',\n",
       "  'tomorrow'],\n",
       " ['thanks', 'man', 'that', 'sorted', 'it', 'i', 'only', 'ever', 'remember'],\n",
       " ['craigg',\n",
       "  'hope',\n",
       "  'your',\n",
       "  'enjoying',\n",
       "  'the',\n",
       "  'moneyits',\n",
       "  'looking',\n",
       "  'real',\n",
       "  'good',\n",
       "  'to',\n",
       "  'me',\n",
       "  'right',\n",
       "  'now'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'my',\n",
       "  'favourite',\n",
       "  'shirt',\n",
       "  'because',\n",
       "  'its',\n",
       "  'true',\n",
       "  'grumpy',\n",
       "  'a',\n",
       "  'cute',\n",
       "  'b',\n",
       "  'huggable',\n",
       "  'c',\n",
       "  'life',\n",
       "  'of',\n",
       "  'the',\n",
       "  'party',\n",
       "  'd'],\n",
       " ['ok',\n",
       "  'back',\n",
       "  'to',\n",
       "  'packing',\n",
       "  'have',\n",
       "  'been',\n",
       "  'sitting',\n",
       "  'in',\n",
       "  'car',\n",
       "  'charging',\n",
       "  'phone',\n",
       "  'as',\n",
       "  'charger',\n",
       "  'was',\n",
       "  'left',\n",
       "  'home',\n",
       "  'as',\n",
       "  'well'],\n",
       " ['and', 'thanks', 'fr', 'yr', 'congratulatory', 'gweetin'],\n",
       " ['every',\n",
       "  'time',\n",
       "  'i',\n",
       "  'have',\n",
       "  'friday',\n",
       "  'off',\n",
       "  'sadly',\n",
       "  'thats',\n",
       "  'not',\n",
       "  'too',\n",
       "  'often'],\n",
       " ['star', 'trek', 'was', 'good', 'times'],\n",
       " ['the', 'sun', 'is', 'not', 'cool'],\n",
       " ['that', 'was', 'meeeaaannn', 'people', 'make', 'mistakes', 'ok', 'lol'],\n",
       " ['invisible', 'car', 'helps', 'to', 'boost', 'recycling', 'honest'],\n",
       " ['baby',\n",
       "  'baby',\n",
       "  'its',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'all',\n",
       "  'right',\n",
       "  'when',\n",
       "  'im',\n",
       "  'by',\n",
       "  'your',\n",
       "  'side',\n",
       "  'and',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'world',\n",
       "  'turns',\n",
       "  'against',\n",
       "  'you',\n",
       "  'i',\n",
       "  'it',\n",
       "  'when',\n",
       "  'my',\n",
       "  'ipod',\n",
       "  'randoms',\n",
       "  'bsb',\n",
       "  'songs'],\n",
       " ['ha',\n",
       "  'totally',\n",
       "  'posting',\n",
       "  'an',\n",
       "  'update',\n",
       "  'at',\n",
       "  'lightning',\n",
       "  'outside',\n",
       "  'pretty'],\n",
       " ['do',\n",
       "  'a',\n",
       "  'tour',\n",
       "  'in',\n",
       "  'the',\n",
       "  'philippines',\n",
       "  'sometime',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'fans',\n",
       "  'here',\n",
       "  'would',\n",
       "  'really',\n",
       "  'love',\n",
       "  'that'],\n",
       " ['has',\n",
       "  'broken',\n",
       "  'off',\n",
       "  'the',\n",
       "  'fb',\n",
       "  'wedding',\n",
       "  'so',\n",
       "  'sadly',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'has',\n",
       "  'an',\n",
       "  'excuse',\n",
       "  'to',\n",
       "  'get',\n",
       "  'hauntingxealot',\n",
       "  'to',\n",
       "  'goulburn'],\n",
       " ['you', 'are', 'kickable'],\n",
       " ['richie',\n",
       "  'i',\n",
       "  'also',\n",
       "  'saw',\n",
       "  'u',\n",
       "  'on',\n",
       "  'american',\n",
       "  'idol',\n",
       "  'great',\n",
       "  'performance',\n",
       "  'i',\n",
       "  'see',\n",
       "  'u',\n",
       "  'will',\n",
       "  'be',\n",
       "  'at',\n",
       "  'windsor',\n",
       "  'in',\n",
       "  'june',\n",
       "  'commodores',\n",
       "  'wont',\n",
       "  'be',\n",
       "  'there'],\n",
       " ['nice', 'clutch'],\n",
       " ['happy', 'mothers', 'day', 'to', 'all', 'the', 'mommies'],\n",
       " ['just', 'finished', 'watching', 'marley', 'and', 'me'],\n",
       " ['enjoying', 'mothers', 'day'],\n",
       " ['everyone',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'love',\n",
       "  'it',\n",
       "  'but',\n",
       "  'it',\n",
       "  'felt',\n",
       "  'kinda',\n",
       "  'lazy',\n",
       "  'and',\n",
       "  'repetative',\n",
       "  'to',\n",
       "  'me',\n",
       "  'i',\n",
       "  'was',\n",
       "  'really',\n",
       "  'disappointed'],\n",
       " ['roll', 'on', 'thursday'],\n",
       " ['dadgum',\n",
       "  'i',\n",
       "  'think',\n",
       "  'this',\n",
       "  'nations',\n",
       "  'shipping',\n",
       "  'needs',\n",
       "  'have',\n",
       "  'shut',\n",
       "  'down',\n",
       "  'completely',\n",
       "  'still',\n",
       "  'no',\n",
       "  'freight',\n",
       "  'for',\n",
       "  'carriers',\n",
       "  'out',\n",
       "  'there'],\n",
       " ['cavs',\n",
       "  'got',\n",
       "  'lucky',\n",
       "  'lol',\n",
       "  'but',\n",
       "  'lebron',\n",
       "  'took',\n",
       "  'over',\n",
       "  'and',\n",
       "  'killed',\n",
       "  'em',\n",
       "  'another',\n",
       "  'triple',\n",
       "  'double'],\n",
       " ['wishing',\n",
       "  'all',\n",
       "  'the',\n",
       "  'mommies',\n",
       "  'out',\n",
       "  'there',\n",
       "  'a',\n",
       "  'very',\n",
       "  'happy',\n",
       "  'day'],\n",
       " ['what',\n",
       "  'did',\n",
       "  'i',\n",
       "  'learn',\n",
       "  'today',\n",
       "  'never',\n",
       "  'post',\n",
       "  'anything',\n",
       "  'youve',\n",
       "  'sold',\n",
       "  'on',\n",
       "  'ebay',\n",
       "  'using',\n",
       "  'royal',\n",
       "  'mail',\n",
       "  'they',\n",
       "  'lose',\n",
       "  'it',\n",
       "  'i',\n",
       "  'refund',\n",
       "  'compos',\n",
       "  'nowhere',\n",
       "  'near',\n",
       "  'my',\n",
       "  'bad'],\n",
       " ['oh', 'god', 'yeah', 'i', 'forgot', 'about', 'that'],\n",
       " ['as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'you',\n",
       "  'have',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'make',\n",
       "  'out',\n",
       "  'with',\n",
       "  'lol'],\n",
       " ['ahaha', 'its', 'stuck', 'in', 'my', 'head', 'thanxx'],\n",
       " ['you',\n",
       "  'arent',\n",
       "  'following',\n",
       "  'me',\n",
       "  'so',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'send',\n",
       "  'you',\n",
       "  'a',\n",
       "  'dm'],\n",
       " ['im', 'poorly', 'and', 'cant', 'sleep'],\n",
       " ['happy',\n",
       "  'star',\n",
       "  'wars',\n",
       "  'day',\n",
       "  'may',\n",
       "  'the',\n",
       "  'be',\n",
       "  'with',\n",
       "  'you',\n",
       "  'read',\n",
       "  'for',\n",
       "  'more'],\n",
       " ['i',\n",
       "  'picked',\n",
       "  'up',\n",
       "  'a',\n",
       "  'taco',\n",
       "  'over',\n",
       "  'lunch',\n",
       "  'you',\n",
       "  'got',\n",
       "  'a',\n",
       "  'guitar'],\n",
       " ['buried',\n",
       "  'under',\n",
       "  'more',\n",
       "  'web',\n",
       "  'changes',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'lunch',\n",
       "  'now',\n",
       "  'i',\n",
       "  'wont',\n",
       "  'have',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'later',\n",
       "  'too',\n",
       "  'much',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['up', 'is', 'all', 'sold', 'out'],\n",
       " ['i',\n",
       "  'hope',\n",
       "  'everyone',\n",
       "  'had',\n",
       "  'a',\n",
       "  'great',\n",
       "  'weekend',\n",
       "  'i',\n",
       "  'will',\n",
       "  'be',\n",
       "  'here',\n",
       "  'on',\n",
       "  'and',\n",
       "  'off',\n",
       "  'today',\n",
       "  'as',\n",
       "  'i',\n",
       "  'have',\n",
       "  'important',\n",
       "  'meetings',\n",
       "  'today'],\n",
       " ['gd',\n",
       "  'whoaa',\n",
       "  'kinda',\n",
       "  'hard',\n",
       "  'o',\n",
       "  'that',\n",
       "  'one',\n",
       "  'that',\n",
       "  'you',\n",
       "  'think',\n",
       "  'will',\n",
       "  'be',\n",
       "  'interesting',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'tell'],\n",
       " ['i', 'love', 'you', 'guys', 'youre', 'the', 'best'],\n",
       " ['listening',\n",
       "  'music',\n",
       "  'home',\n",
       "  'all',\n",
       "  'alone',\n",
       "  'lol',\n",
       "  'who',\n",
       "  'wants',\n",
       "  'come',\n",
       "  'over',\n",
       "  'hang',\n",
       "  'with',\n",
       "  'me',\n",
       "  'lol'],\n",
       " ['shut',\n",
       "  'your',\n",
       "  'face',\n",
       "  'why',\n",
       "  'are',\n",
       "  'you',\n",
       "  'so',\n",
       "  'mean',\n",
       "  'to',\n",
       "  'me',\n",
       "  'pedro',\n",
       "  'is',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'mean',\n",
       "  'one'],\n",
       " ['or',\n",
       "  'so',\n",
       "  'a',\n",
       "  'month',\n",
       "  'i',\n",
       "  'put',\n",
       "  'my',\n",
       "  'weeks',\n",
       "  'notice',\n",
       "  'in',\n",
       "  'a',\n",
       "  'little',\n",
       "  'over',\n",
       "  'a',\n",
       "  'week',\n",
       "  'ago',\n",
       "  'my',\n",
       "  'last',\n",
       "  'day',\n",
       "  'is',\n",
       "  'this',\n",
       "  'friday'],\n",
       " ['oh',\n",
       "  'yea',\n",
       "  'mspacers',\n",
       "  'my',\n",
       "  'boy',\n",
       "  'just',\n",
       "  'hooked',\n",
       "  'up',\n",
       "  'my',\n",
       "  'page',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'kewl',\n",
       "  'at',\n",
       "  'least',\n",
       "  'i',\n",
       "  'think',\n",
       "  'so',\n",
       "  'and',\n",
       "  'it',\n",
       "  'only',\n",
       "  'took',\n",
       "  'him',\n",
       "  'minutes'],\n",
       " ['babe', 'woo', 'im', 'getting', 'mine', 'on', 'mondaycant', 'wait', 'x'],\n",
       " ['awww',\n",
       "  'shes',\n",
       "  'laavly',\n",
       "  'i',\n",
       "  'had',\n",
       "  'to',\n",
       "  'come',\n",
       "  'in',\n",
       "  'but',\n",
       "  'ive',\n",
       "  'got',\n",
       "  'a',\n",
       "  'stunning',\n",
       "  'wee',\n",
       "  'tan',\n",
       "  'l',\n",
       "  'yourself'],\n",
       " ['yes',\n",
       "  'please',\n",
       "  'and',\n",
       "  'if',\n",
       "  'youre',\n",
       "  'gone',\n",
       "  'i',\n",
       "  'might',\n",
       "  'actually',\n",
       "  'get',\n",
       "  'some',\n",
       "  'work',\n",
       "  'done',\n",
       "  'lol'],\n",
       " ['im',\n",
       "  'really',\n",
       "  'getting',\n",
       "  'sick',\n",
       "  'ugh',\n",
       "  'nursing',\n",
       "  'homes',\n",
       "  'laying',\n",
       "  'in',\n",
       "  'bed',\n",
       "  'might',\n",
       "  'go',\n",
       "  'run',\n",
       "  'later',\n",
       "  'watch',\n",
       "  'some',\n",
       "  'more',\n",
       "  'movies',\n",
       "  'with',\n",
       "  'austin',\n",
       "  'sara',\n",
       "  'sami',\n",
       "  'left'],\n",
       " ['i',\n",
       "  'saw',\n",
       "  'you',\n",
       "  'stalkerishly',\n",
       "  'from',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'but',\n",
       "  'brookie',\n",
       "  'was',\n",
       "  'eating',\n",
       "  'her',\n",
       "  'moracca',\n",
       "  'so',\n",
       "  'we',\n",
       "  'had',\n",
       "  'to',\n",
       "  'go'],\n",
       " ['youtube'],\n",
       " ['calling', 'mum', 'too', 'ask', 'if', 'she', 'can', 'by', 'icecream'],\n",
       " ['having',\n",
       "  'a',\n",
       "  'very',\n",
       "  'lazy',\n",
       "  'day',\n",
       "  'playing',\n",
       "  'xbox',\n",
       "  'and',\n",
       "  'drinking',\n",
       "  'tea'],\n",
       " ['well', 'thats', 'disappointing', 'to', 'hear'],\n",
       " ['well',\n",
       "  'if',\n",
       "  'i',\n",
       "  'use',\n",
       "  'all',\n",
       "  'my',\n",
       "  'tweets',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'push',\n",
       "  'to',\n",
       "  'make',\n",
       "  'me',\n",
       "  'go',\n",
       "  'to',\n",
       "  'the',\n",
       "  'shop',\n",
       "  'and',\n",
       "  'by',\n",
       "  'the',\n",
       "  'time',\n",
       "  'im',\n",
       "  'back',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'over',\n",
       "  'hopefully'],\n",
       " ['my',\n",
       "  'mom',\n",
       "  'just',\n",
       "  'texted',\n",
       "  'me',\n",
       "  'and',\n",
       "  'told',\n",
       "  'me',\n",
       "  'that',\n",
       "  'rodney',\n",
       "  'was',\n",
       "  'chasing',\n",
       "  'fireflies',\n",
       "  'in',\n",
       "  'their',\n",
       "  'backyard',\n",
       "  'awwwww',\n",
       "  'im',\n",
       "  'miss',\n",
       "  'him'],\n",
       " ['is',\n",
       "  'getting',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'bed',\n",
       "  'happy',\n",
       "  'mothers',\n",
       "  'day',\n",
       "  'to',\n",
       "  'all',\n",
       "  'the',\n",
       "  'mothers',\n",
       "  'out',\n",
       "  'there'],\n",
       " ['blinks', 'fast', 'its', 'better', 'now', 'lol', 'thanks'],\n",
       " ['my',\n",
       "  'legs',\n",
       "  'are',\n",
       "  'killing',\n",
       "  'me',\n",
       "  'now',\n",
       "  'but',\n",
       "  'i',\n",
       "  'know',\n",
       "  'its',\n",
       "  'a',\n",
       "  'good',\n",
       "  'pain',\n",
       "  'all',\n",
       "  'in',\n",
       "  'all'],\n",
       " ['cont',\n",
       "  'a',\n",
       "  'bastardized',\n",
       "  'version',\n",
       "  'of',\n",
       "  'french',\n",
       "  'its',\n",
       "  'fun',\n",
       "  'believe',\n",
       "  'me'],\n",
       " ['alas',\n",
       "  'i',\n",
       "  'am',\n",
       "  'moving',\n",
       "  'like',\n",
       "  'where',\n",
       "  'im',\n",
       "  'moving',\n",
       "  'too',\n",
       "  'but',\n",
       "  'the',\n",
       "  'actual',\n",
       "  'moving',\n",
       "  'ugh',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'could',\n",
       "  'go',\n",
       "  'too'],\n",
       " ['ready', 'to', 'go', 'home'],\n",
       " ['need',\n",
       "  'to',\n",
       "  'push',\n",
       "  'diet',\n",
       "  'to',\n",
       "  'last',\n",
       "  'level',\n",
       "  'not',\n",
       "  'too',\n",
       "  'good',\n",
       "  'last',\n",
       "  'week',\n",
       "  'lost',\n",
       "  'lb',\n",
       "  'better',\n",
       "  'than',\n",
       "  'a',\n",
       "  'gain'],\n",
       " ['today',\n",
       "  'jon',\n",
       "  'doe',\n",
       "  'plays',\n",
       "  'at',\n",
       "  'the',\n",
       "  'moho',\n",
       "  'ia',\n",
       "  'm',\n",
       "  'excited',\n",
       "  'its',\n",
       "  'gonna',\n",
       "  'be',\n",
       "  'funny',\n",
       "  'but',\n",
       "  'before',\n",
       "  'i',\n",
       "  'have',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'all',\n",
       "  'the',\n",
       "  'equipment',\n",
       "  'and',\n",
       "  'do',\n",
       "  'the',\n",
       "  'backline'],\n",
       " ['my',\n",
       "  'back',\n",
       "  'is',\n",
       "  'killing',\n",
       "  'me',\n",
       "  'it',\n",
       "  'wont',\n",
       "  'keep',\n",
       "  'me',\n",
       "  'from',\n",
       "  'dropping',\n",
       "  'it',\n",
       "  'lowhope',\n",
       "  'i',\n",
       "  'got',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'it',\n",
       "  'back',\n",
       "  'up',\n",
       "  'tho',\n",
       "  'lol'],\n",
       " ['facebook', 'is', 'being', 'a'],\n",
       " ['mad', 'the', 'rain', 'got', 'menow', 'i', 'cant', 'go', 'see', 'jaiden'],\n",
       " ['i', 'am', 'at', 'my', 'grandparents', 'place'],\n",
       " ['hi',\n",
       "  'from',\n",
       "  'chile',\n",
       "  'its',\n",
       "  'deg',\n",
       "  'c',\n",
       "  'winters',\n",
       "  'comingcant',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'cali',\n",
       "  'sun'],\n",
       " ['i', 'dont', 'feel', 'very', 'good'],\n",
       " ['i', 'was', 'born', 'there'],\n",
       " ['congradts',\n",
       "  'on',\n",
       "  'ur',\n",
       "  'show',\n",
       "  'even',\n",
       "  'tho',\n",
       "  'i',\n",
       "  'wasnt',\n",
       "  'there',\n",
       "  'lol'],\n",
       " ['damjust',\n",
       "  'finished',\n",
       "  'watching',\n",
       "  'prison',\n",
       "  'break',\n",
       "  'the',\n",
       "  'final',\n",
       "  'breakomg',\n",
       "  'i',\n",
       "  'dont',\n",
       "  'think',\n",
       "  'ive',\n",
       "  'cried',\n",
       "  'so',\n",
       "  'hard',\n",
       "  'for',\n",
       "  'a',\n",
       "  'showfinally',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'finale'],\n",
       " ['visiting',\n",
       "  'the',\n",
       "  'grandparents',\n",
       "  'in',\n",
       "  'manhattan',\n",
       "  'and',\n",
       "  'dropping',\n",
       "  'off',\n",
       "  'my',\n",
       "  'sister',\n",
       "  'for',\n",
       "  'the',\n",
       "  'week',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'had',\n",
       "  'an',\n",
       "  'excuse',\n",
       "  'to',\n",
       "  'be',\n",
       "  'so',\n",
       "  'tired',\n",
       "  'today'],\n",
       " ['so',\n",
       "  'glad',\n",
       "  'it',\n",
       "  'is',\n",
       "  'friday',\n",
       "  'two',\n",
       "  'classes',\n",
       "  'then',\n",
       "  'lazy',\n",
       "  'afternoon',\n",
       "  'too',\n",
       "  'bad',\n",
       "  'it',\n",
       "  'isnt',\n",
       "  'nice',\n",
       "  'and',\n",
       "  'warm',\n",
       "  'out',\n",
       "  'today'],\n",
       " ['good',\n",
       "  'luck',\n",
       "  'finally',\n",
       "  'your',\n",
       "  'long',\n",
       "  'time',\n",
       "  'will',\n",
       "  'of',\n",
       "  'panvel',\n",
       "  'tweetup',\n",
       "  'finally',\n",
       "  'coming',\n",
       "  'true'],\n",
       " ['heading',\n",
       "  'off',\n",
       "  'to',\n",
       "  'hollywood',\n",
       "  'studios',\n",
       "  'today',\n",
       "  'manta',\n",
       "  'and',\n",
       "  'kraken',\n",
       "  'were',\n",
       "  'both',\n",
       "  'awesome',\n",
       "  'yesterday',\n",
       "  'feeling',\n",
       "  'like',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'few',\n",
       "  'more',\n",
       "  'rides'],\n",
       " ['this',\n",
       "  'weekend',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'packed',\n",
       "  'full',\n",
       "  'of',\n",
       "  'work',\n",
       "  'for',\n",
       "  'school',\n",
       "  'no',\n",
       "  'life',\n",
       "  'this',\n",
       "  'summer',\n",
       "  'im',\n",
       "  'afraid'],\n",
       " ['please', 'read', 'my', 'blog', 'im', 'not', 'having', 'the', 'best', 'day'],\n",
       " ['goodnight'],\n",
       " ['welcome'],\n",
       " ['ha',\n",
       "  'thanks',\n",
       "  'bryan',\n",
       "  'and',\n",
       "  'dont',\n",
       "  'remind',\n",
       "  'me',\n",
       "  'about',\n",
       "  'the',\n",
       "  'state',\n",
       "  'budget',\n",
       "  'issues',\n",
       "  'actually',\n",
       "  'steve',\n",
       "  'only',\n",
       "  'has',\n",
       "  'staffers',\n",
       "  'in',\n",
       "  'offices'],\n",
       " ['thanks', 'none', 'close', 'to', 'me'],\n",
       " ['watered',\n",
       "  'the',\n",
       "  'tomato',\n",
       "  'plants',\n",
       "  'pepper',\n",
       "  'plants',\n",
       "  'and',\n",
       "  'lettuce',\n",
       "  'feeling',\n",
       "  'all',\n",
       "  'homely',\n",
       "  'off',\n",
       "  'out',\n",
       "  'with',\n",
       "  'freddie',\n",
       "  'for',\n",
       "  'a',\n",
       "  'funpacked',\n",
       "  'day'],\n",
       " ['haha', 'i', 'will', 'remember', 'that'],\n",
       " ['will',\n",
       "  'do',\n",
       "  'hee',\n",
       "  'after',\n",
       "  'exams',\n",
       "  'ill',\n",
       "  'give',\n",
       "  'u',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'shows',\n",
       "  'haha',\n",
       "  'hopeless',\n",
       "  'me'],\n",
       " ['i', 'sorry'],\n",
       " ['awww',\n",
       "  'it',\n",
       "  'does',\n",
       "  'remind',\n",
       "  'me',\n",
       "  'of',\n",
       "  'getting',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'the',\n",
       "  'ball'],\n",
       " ['you', 'did', 'know', 'you', 'just', 'couldnt', 'remember'],\n",
       " ['bishop',\n",
       "  'sez',\n",
       "  'need',\n",
       "  'to',\n",
       "  'get',\n",
       "  'u',\n",
       "  'to',\n",
       "  'look',\n",
       "  'at',\n",
       "  'my',\n",
       "  'flights',\n",
       "  'again',\n",
       "  'will',\n",
       "  'email',\n",
       "  'ur',\n",
       "  'work',\n",
       "  'tonite'],\n",
       " ['if',\n",
       "  'so',\n",
       "  'the',\n",
       "  'tmobile',\n",
       "  'is',\n",
       "  'the',\n",
       "  'hummer',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'had',\n",
       "  'the',\n",
       "  'battery',\n",
       "  'life',\n",
       "  'of',\n",
       "  'an',\n",
       "  'iphone'],\n",
       " ['nite',\n",
       "  'nite',\n",
       "  'twitts',\n",
       "  'i',\n",
       "  'wish',\n",
       "  'u',\n",
       "  'all',\n",
       "  'a',\n",
       "  'happy',\n",
       "  'sunday',\n",
       "  'i',\n",
       "  'already',\n",
       "  'have',\n",
       "  'my',\n",
       "  'major',\n",
       "  'gift',\n",
       "  'my',\n",
       "  'my',\n",
       "  'bron',\n",
       "  'n',\n",
       "  'other',\n",
       "  'gift',\n",
       "  'on',\n",
       "  'd',\n",
       "  'way',\n",
       "  'tyg'],\n",
       " ['omg',\n",
       "  'its',\n",
       "  'am',\n",
       "  'and',\n",
       "  'kim',\n",
       "  'possible',\n",
       "  'is',\n",
       "  'on',\n",
       "  'disney',\n",
       "  'channel',\n",
       "  'right',\n",
       "  'now',\n",
       "  'i',\n",
       "  'am',\n",
       "  'glued',\n",
       "  'to',\n",
       "  'the',\n",
       "  'screen'],\n",
       " ['at',\n",
       "  'first',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'bar',\n",
       "  'life',\n",
       "  'meant',\n",
       "  'you',\n",
       "  'were',\n",
       "  'partying',\n",
       "  'nonstop',\n",
       "  'to',\n",
       "  'catch',\n",
       "  'up',\n",
       "  'for',\n",
       "  'the',\n",
       "  'last',\n",
       "  'yearslol',\n",
       "  'shoulda',\n",
       "  'known',\n",
       "  'better'],\n",
       " ['work', 'in', 'that', 'heat', 'is', 'horrible'],\n",
       " ['someone',\n",
       "  'came',\n",
       "  'in',\n",
       "  'when',\n",
       "  'i',\n",
       "  'was',\n",
       "  'sleeping',\n",
       "  'off',\n",
       "  'my',\n",
       "  'national',\n",
       "  'passtime',\n",
       "  'and',\n",
       "  'turned',\n",
       "  'me',\n",
       "  'human'],\n",
       " ['i',\n",
       "  'see',\n",
       "  'you',\n",
       "  'didnt',\n",
       "  'shave',\n",
       "  'your',\n",
       "  'head',\n",
       "  'but',\n",
       "  'i',\n",
       "  'love',\n",
       "  'the',\n",
       "  'cut',\n",
       "  'im',\n",
       "  'glad',\n",
       "  'you',\n",
       "  'didnt',\n",
       "  'shave',\n",
       "  'it',\n",
       "  'your',\n",
       "  'hairs',\n",
       "  'too',\n",
       "  'pretty'],\n",
       " ['starr',\n",
       "  'yep',\n",
       "  'the',\n",
       "  'hawkesbury',\n",
       "  'classic',\n",
       "  'starts',\n",
       "  'at',\n",
       "  'windsor',\n",
       "  'home',\n",
       "  'of',\n",
       "  'said',\n",
       "  'dj'],\n",
       " ['i', 'am', 'twittering', 'like', 'a', 'boss', 'thanks', 'savvv'],\n",
       " ['my',\n",
       "  'sleep',\n",
       "  'pattern',\n",
       "  'is',\n",
       "  'screwed',\n",
       "  'i',\n",
       "  'need',\n",
       "  'to',\n",
       "  'try',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'up',\n",
       "  'midnight',\n",
       "  'so',\n",
       "  'i',\n",
       "  'can',\n",
       "  'get',\n",
       "  'some',\n",
       "  'decent',\n",
       "  'sleep',\n",
       "  'coz',\n",
       "  'i',\n",
       "  'havent',\n",
       "  'slept'],\n",
       " ['since',\n",
       "  'the',\n",
       "  'demise',\n",
       "  'of',\n",
       "  'woolworths',\n",
       "  'it',\n",
       "  'isnt',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'find',\n",
       "  'reasonably',\n",
       "  'priced',\n",
       "  'pick',\n",
       "  'n',\n",
       "  'mix',\n",
       "  'anywhere'],\n",
       " ['may', 'the', 'fourth', 'be', 'with', 'you', 'happy', 'star', 'wars', 'day'],\n",
       " ['ive',\n",
       "  'been',\n",
       "  'unlocked',\n",
       "  'for',\n",
       "  'decades',\n",
       "  'nowjust',\n",
       "  'not',\n",
       "  'lucky',\n",
       "  'never',\n",
       "  'have',\n",
       "  'been',\n",
       "  'gottta',\n",
       "  'make',\n",
       "  'my',\n",
       "  'own',\n",
       "  'luck',\n",
       "  'and',\n",
       "  'that',\n",
       "  'involves'],\n",
       " ['taking', 'care', 'of', 'yucky', 'stuff'],\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If i just want each row as a list:\n",
    "[sublist for sublist in data['temp_list1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we have to remove all the stopwords from \n",
    "data['temp_list1'] = data['temp_list1'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_index</th>\n",
       "      <th>num_words_ST</th>\n",
       "      <th>num_words_T</th>\n",
       "      <th>diff_in_words</th>\n",
       "      <th>temp_list</th>\n",
       "      <th>temp_list1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[bullying]</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[leave, alone]</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>[sons]</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_index  num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   num_words_T  diff_in_words               temp_list  \\\n",
       "0            7              0  [id, responded, going]   \n",
       "1           10              8             [sooo, sad]   \n",
       "2            5              3              [bullying]   \n",
       "3            5              2          [leave, alone]   \n",
       "4           14             11                  [sons]   \n",
       "\n",
       "                                        temp_list1  \n",
       "0                           [id, responded, going]  \n",
       "1                    [sooo, sad, miss, san, diego]  \n",
       "2                                 [boss, bullying]  \n",
       "3                        [interview, leave, alone]  \n",
       "4  [sons, couldnt, put, releases, already, bought]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in data['temp_list1'] for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'id': 161,\n",
       "         'responded': 1,\n",
       "         'going': 1096,\n",
       "         'sooo': 108,\n",
       "         'sad': 474,\n",
       "         'miss': 614,\n",
       "         'san': 19,\n",
       "         'diego': 11,\n",
       "         'boss': 22,\n",
       "         'bullying': 1,\n",
       "         'interview': 27,\n",
       "         'leave': 139,\n",
       "         'alone': 84,\n",
       "         'sons': 8,\n",
       "         'couldnt': 119,\n",
       "         'put': 152,\n",
       "         'releases': 2,\n",
       "         'already': 243,\n",
       "         'bought': 72,\n",
       "         'shameless': 1,\n",
       "         'plugging': 3,\n",
       "         'best': 306,\n",
       "         'rangers': 3,\n",
       "         'forum': 7,\n",
       "         'earth': 22,\n",
       "         'feedings': 1,\n",
       "         'baby': 159,\n",
       "         'fun': 527,\n",
       "         'smiles': 11,\n",
       "         'coos': 1,\n",
       "         'soooo': 70,\n",
       "         'high': 72,\n",
       "         'journey': 11,\n",
       "         'wow': 190,\n",
       "         'u': 923,\n",
       "         'became': 10,\n",
       "         'cooler': 6,\n",
       "         'hehe': 75,\n",
       "         'possible': 22,\n",
       "         'much': 659,\n",
       "         'love': 1122,\n",
       "         'hopeful': 7,\n",
       "         'reckon': 6,\n",
       "         'chances': 5,\n",
       "         'minimal': 2,\n",
       "         'p': 65,\n",
       "         'im': 3020,\n",
       "         'never': 291,\n",
       "         'gonna': 433,\n",
       "         'get': 1426,\n",
       "         'cake': 53,\n",
       "         'stuff': 155,\n",
       "         'really': 908,\n",
       "         'like': 1346,\n",
       "         'song': 164,\n",
       "         'story': 44,\n",
       "         'taylor': 28,\n",
       "         'swift': 10,\n",
       "         'sharpie': 1,\n",
       "         'running': 80,\n",
       "         'dangerously': 1,\n",
       "         'low': 35,\n",
       "         'ink': 3,\n",
       "         'want': 714,\n",
       "         'go': 1267,\n",
       "         'music': 148,\n",
       "         'tonight': 459,\n",
       "         'lost': 158,\n",
       "         'voice': 28,\n",
       "         'test': 66,\n",
       "         'lg': 4,\n",
       "         'uh': 16,\n",
       "         'oh': 663,\n",
       "         'sunburned': 8,\n",
       "         'sok': 1,\n",
       "         'trying': 223,\n",
       "         'plot': 4,\n",
       "         'alternatives': 2,\n",
       "         'speak': 18,\n",
       "         'sigh': 62,\n",
       "         'ive': 396,\n",
       "         'sick': 250,\n",
       "         'past': 60,\n",
       "         'days': 324,\n",
       "         'thus': 6,\n",
       "         'hair': 148,\n",
       "         'looks': 202,\n",
       "         'wierd': 2,\n",
       "         'didnt': 469,\n",
       "         'hat': 17,\n",
       "         'would': 503,\n",
       "         'look': 260,\n",
       "         'back': 891,\n",
       "         'home': 717,\n",
       "         'every': 111,\n",
       "         'one': 971,\n",
       "         'hes': 168,\n",
       "         'marly': 1,\n",
       "         'sorry': 475,\n",
       "         'hope': 589,\n",
       "         'find': 225,\n",
       "         'soon': 294,\n",
       "         'playing': 124,\n",
       "         'ghost': 9,\n",
       "         'online': 91,\n",
       "         'interesting': 59,\n",
       "         'new': 740,\n",
       "         'updates': 41,\n",
       "         'kirin': 1,\n",
       "         'pet': 12,\n",
       "         'metamorph': 1,\n",
       "         'third': 22,\n",
       "         'job': 176,\n",
       "         'cant': 1020,\n",
       "         'wait': 326,\n",
       "         'dragon': 6,\n",
       "         'cleaning': 60,\n",
       "         'house': 230,\n",
       "         'family': 148,\n",
       "         'comming': 2,\n",
       "         'later': 170,\n",
       "         'today': 1096,\n",
       "         'gotta': 153,\n",
       "         'restart': 2,\n",
       "         'computer': 79,\n",
       "         'thought': 207,\n",
       "         'supposed': 67,\n",
       "         'end': 131,\n",
       "         'constant': 10,\n",
       "         'rebootiness': 1,\n",
       "         'see': 797,\n",
       "         'wat': 22,\n",
       "         'mean': 139,\n",
       "         'bout': 61,\n",
       "         'friidays': 1,\n",
       "         'called': 84,\n",
       "         'lose': 25,\n",
       "         'friday': 214,\n",
       "         'smh': 21,\n",
       "         'free': 116,\n",
       "         'fillin': 1,\n",
       "         'app': 36,\n",
       "         'ipod': 55,\n",
       "         'addicted': 16,\n",
       "         'way': 404,\n",
       "         'malaysiano': 1,\n",
       "         'internet': 90,\n",
       "         'access': 23,\n",
       "         'twit': 17,\n",
       "         'juss': 8,\n",
       "         'came': 100,\n",
       "         'backk': 2,\n",
       "         'berkeleyy': 1,\n",
       "         'omg': 189,\n",
       "         'madd': 3,\n",
       "         'havent': 165,\n",
       "         'minute': 28,\n",
       "         'whassqoodd': 1,\n",
       "         'went': 214,\n",
       "         'sleep': 405,\n",
       "         'power': 30,\n",
       "         'cut': 54,\n",
       "         'noida': 2,\n",
       "         'working': 285,\n",
       "         'seen': 114,\n",
       "         'twitter': 501,\n",
       "         'design': 21,\n",
       "         'quiteheavenly': 1,\n",
       "         'unni': 2,\n",
       "         'make': 444,\n",
       "         'audition': 7,\n",
       "         'fighting': 20,\n",
       "         'dahye': 1,\n",
       "         'consolation': 3,\n",
       "         'got': 1072,\n",
       "         'bmi': 1,\n",
       "         'tested': 2,\n",
       "         'hahaha': 106,\n",
       "         'says': 109,\n",
       "         'obesed': 1,\n",
       "         'well': 744,\n",
       "         'unhappy': 8,\n",
       "         'minutes': 88,\n",
       "         'thats': 551,\n",
       "         'funny': 133,\n",
       "         'cute': 127,\n",
       "         'kids': 117,\n",
       "         'ahhh': 42,\n",
       "         'slept': 46,\n",
       "         'game': 131,\n",
       "         'try': 179,\n",
       "         'watch': 226,\n",
       "         'tomorrow': 499,\n",
       "         'though': 416,\n",
       "         'play': 165,\n",
       "         'army': 8,\n",
       "         'tears': 13,\n",
       "         'fears': 3,\n",
       "         'vs': 14,\n",
       "         'eric': 11,\n",
       "         'prydz': 1,\n",
       "         'dj': 15,\n",
       "         'hero': 19,\n",
       "         'born': 17,\n",
       "         'raised': 4,\n",
       "         'nyc': 30,\n",
       "         'living': 46,\n",
       "         'texas': 15,\n",
       "         'years': 106,\n",
       "         'still': 678,\n",
       "         'ny': 26,\n",
       "         'case': 33,\n",
       "         'wonder': 37,\n",
       "         'busy': 95,\n",
       "         'coming': 158,\n",
       "         'adding': 13,\n",
       "         'tons': 14,\n",
       "         'blogs': 5,\n",
       "         'stay': 96,\n",
       "         'tuned': 4,\n",
       "         'soooooo': 14,\n",
       "         'sleeeeepy': 1,\n",
       "         'last': 581,\n",
       "         'day': 2044,\n",
       "         'school': 322,\n",
       "         'todaysniffle': 1,\n",
       "         'little': 296,\n",
       "         'happy': 976,\n",
       "         'wine': 40,\n",
       "         'jeje': 2,\n",
       "         'ok': 280,\n",
       "         'itsm': 1,\n",
       "         'time': 942,\n",
       "         'cares': 5,\n",
       "         'jaja': 3,\n",
       "         'car': 162,\n",
       "         'big': 200,\n",
       "         'dent': 2,\n",
       "         'boot': 14,\n",
       "         'hoping': 72,\n",
       "         'theyre': 91,\n",
       "         'write': 60,\n",
       "         'crossing': 9,\n",
       "         'fingers': 39,\n",
       "         'waiting': 154,\n",
       "         'avid': 2,\n",
       "         'fan': 74,\n",
       "         'magazine': 9,\n",
       "         'magazines': 2,\n",
       "         'mayday': 3,\n",
       "         'ratt': 1,\n",
       "         'rocked': 13,\n",
       "         'nashville': 5,\n",
       "         'toniteone': 1,\n",
       "         'thing': 302,\n",
       "         'sucked': 18,\n",
       "         'encore': 2,\n",
       "         'show': 288,\n",
       "         'pearcy': 1,\n",
       "         'hott': 6,\n",
       "         'bad': 474,\n",
       "         'boy': 73,\n",
       "         'available': 27,\n",
       "         'dear': 62,\n",
       "         'help': 157,\n",
       "         'convert': 4,\n",
       "         'vids': 1,\n",
       "         'girl': 208,\n",
       "         'salon': 3,\n",
       "         'asked': 22,\n",
       "         'shall': 36,\n",
       "         'trim': 1,\n",
       "         'eyebrows': 3,\n",
       "         'old': 222,\n",
       "         'feel': 519,\n",
       "         'egh': 1,\n",
       "         'blah': 21,\n",
       "         'boooooooooooo': 1,\n",
       "         'dunno': 26,\n",
       "         'wanna': 249,\n",
       "         'work': 1112,\n",
       "         'hangovers': 2,\n",
       "         'suckkkkkk': 1,\n",
       "         'drunk': 44,\n",
       "         'mess': 24,\n",
       "         'visiting': 12,\n",
       "         'friendster': 9,\n",
       "         'facebook': 79,\n",
       "         'donbt': 1,\n",
       "         'peel': 1,\n",
       "         'prawns': 2,\n",
       "         'also': 196,\n",
       "         'dont': 1200,\n",
       "         'shopping': 90,\n",
       "         'money': 137,\n",
       "         'crawling': 7,\n",
       "         'round': 31,\n",
       "         'looking': 205,\n",
       "         'week': 419,\n",
       "         'thrilled': 7,\n",
       "         'mine': 123,\n",
       "         'check': 166,\n",
       "         'connect': 6,\n",
       "         'tweeple': 10,\n",
       "         'hate': 324,\n",
       "         'bored': 170,\n",
       "         'freelesson': 1,\n",
       "         'freistunde': 1,\n",
       "         'hm': 12,\n",
       "         'us': 253,\n",
       "         'guess': 200,\n",
       "         'dissappointed': 1,\n",
       "         'romance': 4,\n",
       "         'zero': 10,\n",
       "         'rather': 51,\n",
       "         'early': 175,\n",
       "         'runbut': 1,\n",
       "         'morning': 556,\n",
       "         'runner': 1,\n",
       "         'bah': 14,\n",
       "         'coworker': 5,\n",
       "         'ran': 40,\n",
       "         'late': 158,\n",
       "         'bag': 27,\n",
       "         'smacked': 3,\n",
       "         'knee': 22,\n",
       "         'hurts': 138,\n",
       "         'aw': 76,\n",
       "         'torn': 5,\n",
       "         'ace': 14,\n",
       "         'hearts': 5,\n",
       "         'hunchback': 1,\n",
       "         'speaking': 12,\n",
       "         'friends': 257,\n",
       "         'sleepyi': 1,\n",
       "         'haha': 555,\n",
       "         'yes': 288,\n",
       "         'give': 148,\n",
       "         'easily': 6,\n",
       "         'better': 417,\n",
       "         'spoil': 4,\n",
       "         'mum': 87,\n",
       "         'let': 196,\n",
       "         'kick': 19,\n",
       "         'relax': 16,\n",
       "         'nice': 430,\n",
       "         'meal': 15,\n",
       "         'bottle': 21,\n",
       "         'favorite': 71,\n",
       "         'red': 60,\n",
       "         'mannnn': 3,\n",
       "         'iphone': 84,\n",
       "         'jealous': 55,\n",
       "         'photoshoot': 5,\n",
       "         'awesome': 323,\n",
       "         'worked': 38,\n",
       "         'good': 1549,\n",
       "         'friend': 186,\n",
       "         'yay': 212,\n",
       "         'boo': 94,\n",
       "         'soggy': 2,\n",
       "         'right': 458,\n",
       "         'chilliin': 1,\n",
       "         'know': 930,\n",
       "         'agent': 3,\n",
       "         'smell': 12,\n",
       "         'smoke': 11,\n",
       "         'kitchenfire': 3,\n",
       "         'celticslakers': 1,\n",
       "         'rematch': 1,\n",
       "         'sounds': 129,\n",
       "         'think': 705,\n",
       "         'lol': 948,\n",
       "         'anyone': 134,\n",
       "         'extra': 31,\n",
       "         'keane': 1,\n",
       "         'ticket': 28,\n",
       "         'promise': 19,\n",
       "         'buy': 117,\n",
       "         'drink': 80,\n",
       "         'take': 269,\n",
       "         'rad': 3,\n",
       "         'pics': 59,\n",
       "         'fb': 59,\n",
       "         'blog': 75,\n",
       "         'flickr': 6,\n",
       "         'etc': 36,\n",
       "         'ride': 48,\n",
       "         'catch': 65,\n",
       "         'summer': 143,\n",
       "         'til': 79,\n",
       "         'pop': 15,\n",
       "         'open': 68,\n",
       "         'gorjuz': 1,\n",
       "         'yea': 72,\n",
       "         'kno': 21,\n",
       "         'yesterday': 158,\n",
       "         'tha': 22,\n",
       "         'hospital': 36,\n",
       "         'talked': 15,\n",
       "         'said': 183,\n",
       "         'popped': 7,\n",
       "         'say': 322,\n",
       "         'hi': 159,\n",
       "         'things': 185,\n",
       "         'ill': 534,\n",
       "         'probably': 123,\n",
       "         'head': 154,\n",
       "         'guttah': 1,\n",
       "         'missin': 6,\n",
       "         'baddd': 2,\n",
       "         'sources': 3,\n",
       "         'tired': 260,\n",
       "         'hey': 296,\n",
       "         'change': 84,\n",
       "         'account': 64,\n",
       "         'even': 299,\n",
       "         'tell': 164,\n",
       "         'thank': 283,\n",
       "         'yyyyyyyyyoooooooooouuuuu': 1,\n",
       "         'lucky': 75,\n",
       "         'kidi': 1,\n",
       "         'loserville': 1,\n",
       "         'pity': 11,\n",
       "         'oz': 8,\n",
       "         'fell': 54,\n",
       "         'asleep': 62,\n",
       "         'flu': 60,\n",
       "         'reply': 56,\n",
       "         'simfinger': 1,\n",
       "         'problem': 68,\n",
       "         'irape': 1,\n",
       "         'parody': 4,\n",
       "         'video': 94,\n",
       "         'response': 8,\n",
       "         'guys': 246,\n",
       "         'star': 186,\n",
       "         'wars': 92,\n",
       "         'everyone': 255,\n",
       "         'enjoy': 140,\n",
       "         'holiday': 88,\n",
       "         'uk': 55,\n",
       "         'miles': 36,\n",
       "         'essex': 1,\n",
       "         'plenty': 19,\n",
       "         'warning': 6,\n",
       "         'arrive': 10,\n",
       "         'least': 138,\n",
       "         'beers': 3,\n",
       "         'snoring': 5,\n",
       "         'annoying': 29,\n",
       "         'n': 161,\n",
       "         'keeps': 36,\n",
       "         'sleeping': 73,\n",
       "         'honestly': 13,\n",
       "         'wud': 8,\n",
       "         'eva': 3,\n",
       "         'left': 206,\n",
       "         'bby': 6,\n",
       "         'wish': 501,\n",
       "         'isnt': 161,\n",
       "         'quite': 88,\n",
       "         'ready': 219,\n",
       "         'post': 85,\n",
       "         'publicly': 2,\n",
       "         'beta': 12,\n",
       "         'testing': 8,\n",
       "         'cool': 265,\n",
       "         'script': 9,\n",
       "         'coded': 1,\n",
       "         'sweeeeet': 1,\n",
       "         'fran': 2,\n",
       "         'mounce': 1,\n",
       "         'lasts': 7,\n",
       "         'bedtime': 16,\n",
       "         'joined': 17,\n",
       "         'pills': 10,\n",
       "         'eating': 114,\n",
       "         'ice': 72,\n",
       "         'cream': 55,\n",
       "         'getting': 388,\n",
       "         'graduation': 39,\n",
       "         'mothers': 717,\n",
       "         'mums': 39,\n",
       "         'caseys': 1,\n",
       "         'gone': 169,\n",
       "         'piddled': 1,\n",
       "         'carpet': 4,\n",
       "         'shes': 130,\n",
       "         'prolly': 5,\n",
       "         'freaked': 3,\n",
       "         'cause': 147,\n",
       "         'hemp': 1,\n",
       "         'cloth': 2,\n",
       "         'marvelous': 3,\n",
       "         'unfortunately': 54,\n",
       "         'read': 157,\n",
       "         'adam': 11,\n",
       "         'lambert': 5,\n",
       "         'bed': 365,\n",
       "         'nighty': 8,\n",
       "         'night': 737,\n",
       "         'saw': 181,\n",
       "         'none': 37,\n",
       "         'baddies': 1,\n",
       "         'beach': 71,\n",
       "         'pretty': 213,\n",
       "         'certainly': 11,\n",
       "         'cheers': 27,\n",
       "         'huh': 38,\n",
       "         'myhorrible': 1,\n",
       "         'traumatic': 1,\n",
       "         'jumping': 7,\n",
       "         'cholla': 1,\n",
       "         'accidentchollas': 1,\n",
       "         'next': 363,\n",
       "         'dirty': 13,\n",
       "         'trickpieces': 1,\n",
       "         'starting': 81,\n",
       "         'emerge': 2,\n",
       "         'hand': 41,\n",
       "         'ouch': 39,\n",
       "         'realy': 8,\n",
       "         'wanted': 128,\n",
       "         'everybodys': 2,\n",
       "         'ocean': 15,\n",
       "         'yourbiggestfan': 1,\n",
       "         'real': 105,\n",
       "         'lets': 77,\n",
       "         'pens': 6,\n",
       "         'wear': 40,\n",
       "         'black': 47,\n",
       "         'blip': 7,\n",
       "         'apart': 22,\n",
       "         'obvious': 6,\n",
       "         'thanks': 657,\n",
       "         'reblipping': 1,\n",
       "         'safe': 38,\n",
       "         'trip': 87,\n",
       "         'joshy': 1,\n",
       "         'pooyoull': 1,\n",
       "         'knock': 4,\n",
       "         'dead': 77,\n",
       "         'speech': 13,\n",
       "         'woof': 1,\n",
       "         'allowed': 21,\n",
       "         'add': 51,\n",
       "         'email': 70,\n",
       "         'adress': 1,\n",
       "         'comment': 37,\n",
       "         'tickets': 67,\n",
       "         'afrin': 1,\n",
       "         'nasal': 3,\n",
       "         'spray': 6,\n",
       "         'giant': 11,\n",
       "         'teacup': 1,\n",
       "         'acsm': 1,\n",
       "         'unfathomable': 1,\n",
       "         'kept': 13,\n",
       "         'comfort': 3,\n",
       "         'bedrooms': 1,\n",
       "         'aww': 148,\n",
       "         'daddy': 26,\n",
       "         'works': 48,\n",
       "         'almost': 148,\n",
       "         'tries': 1,\n",
       "         'sf': 13,\n",
       "         'many': 143,\n",
       "         'tests': 7,\n",
       "         'todayyy': 3,\n",
       "         'confident': 2,\n",
       "         'anyy': 1,\n",
       "         'done': 266,\n",
       "         'hang': 63,\n",
       "         'hahaa': 4,\n",
       "         'awesomee': 3,\n",
       "         'holy': 23,\n",
       "         'smokes': 2,\n",
       "         'trek': 84,\n",
       "         'freaking': 25,\n",
       "         'awesomeeeee': 1,\n",
       "         'fallout': 3,\n",
       "         'making': 147,\n",
       "         'jump': 19,\n",
       "         'health': 12,\n",
       "         'ammo': 1,\n",
       "         'food': 115,\n",
       "         'worry': 48,\n",
       "         'itunes': 28,\n",
       "         'songs': 60,\n",
       "         'whats': 134,\n",
       "         'gloomy': 12,\n",
       "         'weather': 153,\n",
       "         'sun': 155,\n",
       "         'must': 149,\n",
       "         'come': 401,\n",
       "         'heading': 69,\n",
       "         'victoria': 6,\n",
       "         'gardens': 3,\n",
       "         'impulse': 1,\n",
       "         'buys': 2,\n",
       "         'forward': 136,\n",
       "         'maths': 10,\n",
       "         'geography': 8,\n",
       "         'english': 50,\n",
       "         'french': 34,\n",
       "         'exams': 53,\n",
       "         'totalling': 1,\n",
       "         'hours': 242,\n",
       "         'poor': 153,\n",
       "         'outside': 111,\n",
       "         'garden': 50,\n",
       "         'forget': 57,\n",
       "         'suncream': 1,\n",
       "         'prob': 28,\n",
       "         'hun': 39,\n",
       "         'dads': 28,\n",
       "         'watching': 338,\n",
       "         'mtv': 12,\n",
       "         'minutee': 1,\n",
       "         'absolutely': 45,\n",
       "         'matter': 33,\n",
       "         'chickadee': 1,\n",
       "         'mia': 10,\n",
       "         'totally': 124,\n",
       "         'adore': 8,\n",
       "         'cd': 30,\n",
       "         'bmfing': 1,\n",
       "         'webcam': 4,\n",
       "         'chatting': 13,\n",
       "         'nephews': 3,\n",
       "         'nothing': 178,\n",
       "         'spesh': 1,\n",
       "         'bank': 80,\n",
       "         'monday': 183,\n",
       "         'nonetheless': 4,\n",
       "         'need': 570,\n",
       "         'ask': 76,\n",
       "         'something': 232,\n",
       "         'lmao': 70,\n",
       "         'splinters': 1,\n",
       "         'painfulbut': 1,\n",
       "         'heroic': 1,\n",
       "         'saving': 15,\n",
       "         'mr': 46,\n",
       "         'pickle': 2,\n",
       "         'tweeting': 46,\n",
       "         'sunday': 130,\n",
       "         'may': 258,\n",
       "         'celebrating': 15,\n",
       "         'yer': 11,\n",
       "         'mom': 266,\n",
       "         'decided': 36,\n",
       "         'trans': 2,\n",
       "         'frm': 8,\n",
       "         'relaxed': 3,\n",
       "         'natural': 2,\n",
       "         'whole': 116,\n",
       "         'looked': 48,\n",
       "         'roots': 5,\n",
       "         'age': 22,\n",
       "         'instant': 7,\n",
       "         'gratification': 1,\n",
       "         'namaskar': 2,\n",
       "         'namaste': 1,\n",
       "         'r': 99,\n",
       "         'marathi': 2,\n",
       "         'people': 364,\n",
       "         'word': 44,\n",
       "         'naaaah': 1,\n",
       "         'congrats': 53,\n",
       "         'cuss': 2,\n",
       "         'reward': 3,\n",
       "         'humous': 1,\n",
       "         'doritos': 1,\n",
       "         'missed': 192,\n",
       "         'movie': 238,\n",
       "         'normal': 25,\n",
       "         'group': 32,\n",
       "         'pilots': 1,\n",
       "         'large': 15,\n",
       "         'airline': 2,\n",
       "         'terrible': 24,\n",
       "         'evans': 3,\n",
       "         'call': 163,\n",
       "         'childline': 1,\n",
       "         'unfortunatley': 2,\n",
       "         'aerlingus': 1,\n",
       "         'longer': 42,\n",
       "         'fly': 35,\n",
       "         'copenhagen': 3,\n",
       "         'ryanair': 1,\n",
       "         'billund': 1,\n",
       "         'drive': 74,\n",
       "         'actually': 179,\n",
       "         'google': 51,\n",
       "         'term': 12,\n",
       "         'sucks': 204,\n",
       "         'tho': 137,\n",
       "         'watched': 81,\n",
       "         'win': 80,\n",
       "         'fightlol': 1,\n",
       "         'carwarmed': 1,\n",
       "         'sprite': 2,\n",
       "         'tastes': 9,\n",
       "         'sore': 65,\n",
       "         'throat': 43,\n",
       "         'cross': 11,\n",
       "         'country': 16,\n",
       "         'beat': 30,\n",
       "         'dumbo': 2,\n",
       "         'candle': 2,\n",
       "         'wax': 2,\n",
       "         'enjoyable': 4,\n",
       "         'unassuming': 1,\n",
       "         'unpretentious': 1,\n",
       "         'suppose': 26,\n",
       "         'endearingbecause': 1,\n",
       "         'relate': 5,\n",
       "         'valerias': 1,\n",
       "         'lunch': 136,\n",
       "         'arraving': 1,\n",
       "         'cousins': 21,\n",
       "         'babtizm': 1,\n",
       "         'whatever': 34,\n",
       "         'spell': 12,\n",
       "         'goooooddd': 2,\n",
       "         'tweets': 89,\n",
       "         'three': 53,\n",
       "         'workout': 14,\n",
       "         'mention': 28,\n",
       "         'glasses': 15,\n",
       "         'fine': 75,\n",
       "         'walk': 52,\n",
       "         'cruisers': 1,\n",
       "         'ones': 81,\n",
       "         'lmfao': 12,\n",
       "         'mmmmmmmm': 1,\n",
       "         'neither': 17,\n",
       "         'two': 185,\n",
       "         'hour': 116,\n",
       "         'lunchbreak': 2,\n",
       "         'yeah': 425,\n",
       "         'bugger': 8,\n",
       "         'forgot': 95,\n",
       "         'washing': 17,\n",
       "         'machine': 29,\n",
       "         'laurie': 8,\n",
       "         'sending': 32,\n",
       "         'blessings': 6,\n",
       "         'healing': 3,\n",
       "         'thoughts': 23,\n",
       "         'peace': 25,\n",
       "         'hurtsreally': 1,\n",
       "         'ah': 80,\n",
       "         'feeling': 256,\n",
       "         'cookers': 1,\n",
       "         'dad': 90,\n",
       "         'modem': 5,\n",
       "         'offline': 6,\n",
       "         'god': 143,\n",
       "         'bless': 43,\n",
       "         'network': 13,\n",
       "         'tim': 9,\n",
       "         'schedule': 16,\n",
       "         'brutal': 1,\n",
       "         'nope': 54,\n",
       "         'coquitlam': 1,\n",
       "         'parent': 7,\n",
       "         'teacher': 16,\n",
       "         'boring': 66,\n",
       "         'skl': 4,\n",
       "         'saturday': 95,\n",
       "         'lichfield': 1,\n",
       "         'tweetup': 7,\n",
       "         'else': 98,\n",
       "         'booming': 1,\n",
       "         'thunder': 14,\n",
       "         'storm': 16,\n",
       "         'maybe': 201,\n",
       "         'bevvies': 1,\n",
       "         'twngreat': 1,\n",
       "         'first': 261,\n",
       "         'myers': 1,\n",
       "         'wout': 5,\n",
       "         'lydia': 2,\n",
       "         'excited': 155,\n",
       "         'ever': 228,\n",
       "         'url': 11,\n",
       "         'previous': 8,\n",
       "         'timer': 1,\n",
       "         'removed': 5,\n",
       "         'space': 24,\n",
       "         'messed': 22,\n",
       "         'es': 5,\n",
       "         'iv': 5,\n",
       "         'hurt': 81,\n",
       "         'tooth': 12,\n",
       "         'eilish': 1,\n",
       "         'cassie': 4,\n",
       "         'drawing': 10,\n",
       "         'competiton': 1,\n",
       "         'draw': 8,\n",
       "         'cookies': 19,\n",
       "         'pineapples': 1,\n",
       "         'l': 28,\n",
       "         'auditions': 4,\n",
       "         'mander': 1,\n",
       "         'text': 56,\n",
       "         'orreply': 1,\n",
       "         'please': 250,\n",
       "         'nooooo': 10,\n",
       "         'secret': 16,\n",
       "         'namerebecca': 1,\n",
       "         'neice': 2,\n",
       "         'grown': 14,\n",
       "         'fixed': 27,\n",
       "         'hopes': 14,\n",
       "         'cars': 18,\n",
       "         'illness': 2,\n",
       "         'terminal': 3,\n",
       "         'following': 102,\n",
       "         'tweet': 173,\n",
       "         'siri': 2,\n",
       "         'woulda': 5,\n",
       "         'honeybut': 1,\n",
       "         'xmen': 17,\n",
       "         'origins': 5,\n",
       "         'wolverine': 29,\n",
       "         'loved': 100,\n",
       "         'voted': 16,\n",
       "         'personal': 10,\n",
       "         'myspace': 30,\n",
       "         'keep': 184,\n",
       "         'talking': 87,\n",
       "         'fakes': 2,\n",
       "         'helped': 9,\n",
       "         'thru': 26,\n",
       "         'hrdest': 1,\n",
       "         'life': 248,\n",
       "         'x': 213,\n",
       "         'finally': 215,\n",
       "         'marriage': 10,\n",
       "         'counseling': 1,\n",
       "         'ended': 28,\n",
       "         'stupid': 129,\n",
       "         'rats': 4,\n",
       "         'impromptu': 2,\n",
       "         'pool': 37,\n",
       "         'party': 149,\n",
       "         'except': 45,\n",
       "         'swim': 17,\n",
       "         'whilst': 5,\n",
       "         'gumoww': 1,\n",
       "         'year': 198,\n",
       "         'hella': 16,\n",
       "         'official': 16,\n",
       "         'hear': 177,\n",
       "         'goooooooooooood': 1,\n",
       "         'morrrrrrrrning': 1,\n",
       "         'twitterville': 7,\n",
       "         'phew': 8,\n",
       "         'note': 30,\n",
       "         'runs': 10,\n",
       "         'issue': 1,\n",
       "         'vote': 65,\n",
       "         'starving': 16,\n",
       "         'diet': 19,\n",
       "         'killing': 25,\n",
       "         'eat': 130,\n",
       "         'talk': 151,\n",
       "         'soo': 78,\n",
       "         'boredim': 1,\n",
       "         'deffo': 2,\n",
       "         'missing': 137,\n",
       "         'channels': 3,\n",
       "         'nite': 60,\n",
       "         'bday': 68,\n",
       "         'concert': 78,\n",
       "         'nicotine': 1,\n",
       "         'replacement': 5,\n",
       "         'patch': 3,\n",
       "         'far': 136,\n",
       "         'bit': 198,\n",
       "         'twitchy': 1,\n",
       "         'sanderson': 1,\n",
       "         'twatter': 1,\n",
       "         'lately': 27,\n",
       "         'either': 87,\n",
       "         'replies': 13,\n",
       "         'turn': 72,\n",
       "         'couple': 70,\n",
       "         'ago': 102,\n",
       "         'parked': 3,\n",
       "         'gets': 94,\n",
       "         'hit': 96,\n",
       "         'heard': 79,\n",
       "         'fall': 48,\n",
       "         'nightmares': 4,\n",
       "         'huggles': 3,\n",
       "         'creeper': 2,\n",
       "         'disappointed': 29,\n",
       "         'cyberstalking': 1,\n",
       "         'skills': 11,\n",
       "         'privacy': 3,\n",
       "         'headache': 96,\n",
       "         'moms': 149,\n",
       "         'grabbing': 3,\n",
       "         'coffee': 137,\n",
       "         'breakfast': 76,\n",
       "         'thinking': 131,\n",
       "         'tonightand': 1,\n",
       "         'changes': 8,\n",
       "         'major': 20,\n",
       "         'chop': 2,\n",
       "         'handle': 11,\n",
       "         'fame': 3,\n",
       "         'updated': 19,\n",
       "         'sober': 11,\n",
       "         'tanghaling': 1,\n",
       "         'tapat': 1,\n",
       "         'dude': 92,\n",
       "         'wild': 17,\n",
       "         'knowwww': 1,\n",
       "         'plan': 40,\n",
       "         'icarly': 4,\n",
       "         'son': 39,\n",
       "         'huge': 48,\n",
       "         'crush': 13,\n",
       "         'miranda': 2,\n",
       "         'james': 14,\n",
       "         'carville': 1,\n",
       "         'store': 48,\n",
       "         'bald': 2,\n",
       "         'yellow': 8,\n",
       "         'means': 61,\n",
       "         'youre': 343,\n",
       "         'vancouver': 12,\n",
       "         'hahah': 35,\n",
       "         'smooth': 6,\n",
       "         'chrome': 6,\n",
       "         'ew': 14,\n",
       "         'traffic': 42,\n",
       "         'downloading': 10,\n",
       "         'sneak': 5,\n",
       "         'lil': 74,\n",
       "         'homework': 35,\n",
       "         'main': 11,\n",
       "         'priority': 5,\n",
       "         'rara': 1,\n",
       "         'alonei': 1,\n",
       "         'realize': 19,\n",
       "         'youve': 52,\n",
       "         'happiest': 7,\n",
       "         'walking': 32,\n",
       "         'class': 102,\n",
       "         'bikeespecially': 1,\n",
       "         'nesmith': 1,\n",
       "         'failed': 29,\n",
       "         'inspection': 5,\n",
       "         'pass': 36,\n",
       "         'wooven': 1,\n",
       "         'woantitip': 1,\n",
       "         'bracket': 3,\n",
       "         'sold': 38,\n",
       "         'woven': 1,\n",
       "         'worse': 40,\n",
       "         'taxes': 3,\n",
       "         'jonas': 59,\n",
       "         'brothers': 49,\n",
       "         'live': 197,\n",
       "         'rocking': 11,\n",
       "         'hard': 176,\n",
       "         'world': 171,\n",
       "         'wave': 10,\n",
       "         'demo': 8,\n",
       "         'lot': 158,\n",
       "         'sleepy': 35,\n",
       "         'tabz': 1,\n",
       "         'listened': 15,\n",
       "         'episode': 54,\n",
       "         'jossd': 1,\n",
       "         'exception': 3,\n",
       "         'short': 60,\n",
       "         'larenz': 1,\n",
       "         'fineass': 1,\n",
       "         'tate': 1,\n",
       "         'yum': 45,\n",
       "         'screw': 12,\n",
       "         'reviews': 11,\n",
       "         'enough': 119,\n",
       "         'dominic': 1,\n",
       "         'monaghan': 1,\n",
       "         'liking': 16,\n",
       "         'followed': 31,\n",
       "         'recently': 9,\n",
       "         'offended': 4,\n",
       "         'limit': 13,\n",
       "         'hopefully': 95,\n",
       "         'hmmm': 23,\n",
       "         ...})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top #this is what top is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Counter"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can convert Counter object to a dataframe:\n",
    "temp = pd.DataFrame(top.most_common(25))\n",
    "temp = temp.iloc[:,:]\n",
    "temp.columns = ['Common Words', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>go</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dont</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>love</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>going</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>today</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>got</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cant</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>happy</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>one</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lol</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>know</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>really</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>back</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>see</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>well</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>new</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>night</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "0       im  3020\n",
       "1      day  2044\n",
       "2     good  1549\n",
       "3      get  1426\n",
       "4     like  1346\n",
       "5       go  1267\n",
       "6     dont  1200\n",
       "7     love  1122\n",
       "8     work  1112\n",
       "9    going  1096\n",
       "10   today  1096\n",
       "11     got  1072\n",
       "12    cant  1020\n",
       "13   happy   976\n",
       "14     one   971\n",
       "15     lol   948\n",
       "16    time   942\n",
       "17    know   930\n",
       "18       u   923\n",
       "19  really   908\n",
       "20    back   891\n",
       "21     see   797\n",
       "22    well   744\n",
       "23     new   740\n",
       "24   night   737"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that im is the most common...ignoring that day is the most common word in data['text'] column !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(temp, x=\"Count\", y=\"Common Words\", title='Commmon Words in Text', orientation='h', \n",
    "             width=700, height=700,color='Common Words')\n",
    "fig.show() #press Y to change it to code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common words sentiment-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data[data['sentiment'] == 'positive']\n",
    "negative = data[data['sentiment'] == 'negative']\n",
    "neutral = data[data['sentiment'] == 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Common words in positive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fun</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nice</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mothers</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hope</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>awesome</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thank</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>like</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>best</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wish</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>amazing</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>really</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>better</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cool</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>much</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Common Words  Count\n",
       "0          good    826\n",
       "1         happy    730\n",
       "2          love    697\n",
       "3           day    456\n",
       "4        thanks    439\n",
       "5         great    364\n",
       "6           fun    287\n",
       "7          nice    267\n",
       "8       mothers    259\n",
       "9          hope    245\n",
       "10      awesome    232\n",
       "11        thank    180\n",
       "12         like    167\n",
       "13         best    154\n",
       "14         wish    152\n",
       "15      amazing    135\n",
       "16       really    128\n",
       "17       better    125\n",
       "18         cool    119\n",
       "19         much    110"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [item for list in positive['temp_list'] for item in list]\n",
    "top = Counter(temp)\n",
    "top_positive = pd.DataFrame(top.most_common(20))\n",
    "top_positive.columns = ['Common Words', 'Count']\n",
    "top_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common words in negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>miss</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sorry</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dont</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cant</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sick</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sucks</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feel</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tired</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>really</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bored</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>day</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hurts</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>work</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>get</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>missed</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Common Words  Count\n",
       "0          miss    358\n",
       "1           sad    343\n",
       "2         sorry    300\n",
       "3           bad    246\n",
       "4          hate    230\n",
       "5          dont    221\n",
       "6          cant    201\n",
       "7          sick    166\n",
       "8          like    162\n",
       "9         sucks    159\n",
       "10         feel    158\n",
       "11        tired    144\n",
       "12       really    137\n",
       "13         good    127\n",
       "14        bored    115\n",
       "15          day    110\n",
       "16        hurts    108\n",
       "17         work     99\n",
       "18          get     97\n",
       "19       missed     90"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [item for list in negative['temp_list'] for item in list]\n",
    "top = Counter(temp)\n",
    "top_negative = pd.DataFrame(top.most_common(20))\n",
    "top_negative.columns = ['Common Words', 'Count']\n",
    "top_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Common words in neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>going</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>work</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>like</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>got</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>today</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lol</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>time</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>know</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>one</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>see</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cant</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>want</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>new</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Common Words  Count\n",
       "0           get    612\n",
       "1            go    569\n",
       "2           day    492\n",
       "3          dont    482\n",
       "4         going    472\n",
       "5          work    467\n",
       "6          like    445\n",
       "7           got    441\n",
       "8         today    427\n",
       "9           lol    427\n",
       "10         time    413\n",
       "11         know    407\n",
       "12         back    402\n",
       "13          one    394\n",
       "14            u    376\n",
       "15          see    349\n",
       "16         cant    339\n",
       "17         home    335\n",
       "18         want    319\n",
       "19          new    316"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [item for list in neutral['temp_list'] for item in list]\n",
    "top = Counter(temp)\n",
    "top_neutral = pd.DataFrame(top.most_common(20))\n",
    "top_neutral.columns = ['Common Words', 'Count']\n",
    "top_neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have looked at the top used words in each sentiment-wise word tweets !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['Num_words_text']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26752"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_dir, nlp, new_model_name):\n",
    "    ''' This Function Saves model to \n",
    "    given output directory'''\n",
    "    \n",
    "    output_dir = f'../working/{output_dir}'\n",
    "    if output_dir is not None:        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        nlp.meta[\"name\"] = new_model_name\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out_path(sentiment):\n",
    "    '''\n",
    "    Returns Model output path\n",
    "    '''\n",
    "    model_out_path = None\n",
    "    if sentiment == 'positive':\n",
    "        model_out_path = 'models/model_pos'\n",
    "    elif sentiment == 'negative':\n",
    "        model_out_path = 'models/model_neg'\n",
    "    return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(sentiment):\n",
    "    '''\n",
    "    Returns Trainong data in the format needed to train spacy NER\n",
    "    '''\n",
    "    train_data = []\n",
    "    for index, row in df_train.iterrows():\n",
    "        if row.sentiment == sentiment:\n",
    "            selected_text = row.selected_text\n",
    "            text = row.text\n",
    "            start = text.find(selected_text)\n",
    "            end = start + len(selected_text)\n",
    "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    \"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        else:\n",
    "            nlp.resume_training()\n",
    "\n",
    "\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts,  # batch of texts\n",
    "                            annotations,  # batch of annotations\n",
    "                            drop=0.5,   # dropout - make it harder to memorise data\n",
    "                            losses=losses, \n",
    "                            )\n",
    "            print(\"Losses\", losses)\n",
    "    save_model(output_dir, nlp, 'st_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                          | 1/3 [01:08<02:17, 68.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 33820.54045392887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                             | 2/3 [02:24<01:10, 70.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 30884.24250881766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [03:38<00:00, 72.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29750.668025989333}\n",
      "Saved model to ../working/models/model_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from spacy.util import minibatch\n",
    "from spacy.util import compounding\n",
    "import os\n",
    "sentiment = 'positive'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "# For DEmo Purposes I have taken 3 iterations you can train the model as you want\n",
    "train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Guys (    ) I know! My ability to read time tellin...\" with entities \"[[57, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  And it`s only downhill from now until Labor Day!\" with entities \"[[14, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  dont make me sad... i do agree tho it does need ...\" with entities \"[[13, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My new landlord just called.. I cant move in until...\" with entities \"[[30, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no...i`m just tired..\" with entities \"[[4, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"can`t tell you how thrilled I am to have just had ...\" with entities \"[[0, 117, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Just got home from work.. My feet are killing me\" with entities \"[[24, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Ha!  I dunno about standing anything up.  Very v...\" with entities \"[[40, 82, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" right..  making compromises is what kills us!\" with entities \"[[35, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Not so good  I think that`s my fault though - did...\" with entities \"[[30, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Need a tickettttt  Gah. Ya you`ve got me on there...\" with entities \"[[113, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i`ve become one of those pathetic girls that feel ...\" with entities \"[[91, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  no room for me smh\" with entities \"[[15, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ahaha i know. but now i can`t do anything over th...\" with entities \"[[21, 59, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"It`s freakin` hot and humid today.\" with entities \"[[1, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" noo  I`m in miami and I just wanna lay out in the...\" with entities \"[[62, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Ok super bored... guess no one else it\" with entities \"[[9, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" So sad...found otu about your boot camp too late....\" with entities \"[[4, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m not having a good day... can u cheer me up wi...\" with entities \"[[5, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" last reply  a scholar in US Homeland Security sai...\" with entities \"[[96, 103, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate not bringing my ipod to school\" with entities \"[[2, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"missing my hobo/****/tramp way of life, and cookin...\" with entities \"[[0, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"The VP is gone...so why am I getting a headache?  ...\" with entities \"[[0, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"mothers day..didnt do anything exciting...saw a mo...\" with entities \"[[13, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I think I have hayfever. Not sure due to wearing n...\" with entities \"[[68, 79, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"At work... supposed to be a day off but too much w...\" with entities \"[[40, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" LMAO!I was JUST thinking how I **** hate @ least ...\" with entities \"[[79, 125, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  it was just true  and you do cause me to having ...\" with entities \"[[47, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Being slammed with spam followers today. Is it jus...\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" me neither at first...but u gotta go thru somethi...\" with entities \"[[77, 101, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh no!  thats no good! I pierced  my bottom lip o...\" with entities \"[[1, 126, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" haha IE...it`s expensive!!!! Hm...let me message ...\" with entities \"[[10, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"sat in the pub. Pretty quiet so far. Prob leave in...\" with entities \"[[16, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`ve got really bad arthritus in my left hand. I ...\" with entities \"[[15, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"mad the rain got me...now i cant go see jaiden   *...\" with entities \"[[0, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh but that girl  but AIDAN!\" with entities \"[[21, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nope, up tomorrow  I`m tired need bed\" with entities \"[[22, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  oist the 1st tym, di pa ko 18, the 2nd tym, may ...\" with entities \"[[65, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" That`s how it was for me in March...it came sooo ...\" with entities \"[[50, 55, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" who knows  It makes me sad  lol\" with entities \"[[22, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Waiting for my momma so i can go to Chase and see ...\" with entities \"[[91, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ..ok brother...did you change your num and not gi...\" with entities \"[[76, 93, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"just woke up, its laura`s last full day here  Last...\" with entities \"[[66, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"this hole twitter thing is new too me, its not let...\" with entities \"[[84, 117, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"nooo i cant be sick...not now! im about to go see ...\" with entities \"[[0, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Oh..I`m so borin`.. why not play the computer?? My...\" with entities \"[[11, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"The arrival of cargo Red G5 to Toronto has been po...\" with entities \"[[87, 106, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i`m kinda sad of being alone all the time i miss m...\" with entities \"[[74, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"can`t gauge the time of day in my office anymore.....\" with entities \"[[57, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Morning tweeple! I`m a bit sneezy today\" with entities \"[[27, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i did that but my INS wouldn`t pay for the therap...\" with entities \"[[58, 75, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Listening to have heart. Aka i took over carlys la...\" with entities \"[[90, 113, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Good work.I`ve only just managed to turn my studi...\" with entities \"[[56, 82, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" so i spoke too soon.... & my weekend may be delay...\" with entities \"[[111, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" given the way kunal khemu etc. starrers turn out....\" with entities \"[[60, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" me too.  I was in Florida last weekend for the ra...\" with entities \"[[80, 90, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Drinking and smoking is very bad.---but im grown t...\" with entities \"[[21, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_ no idea what that means bb\" with entities \"[[0, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" iya, nyokap gue pernah berkata demikian  :-|  and...\" with entities \"[[48, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" pictures of your bliss?  In JPEG format?  Sorry, ...\" with entities \"[[1, 115, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  so sorry, I just found the members preview has b...\" with entities \"[[3, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Well the one thing where you lay on the floor I c...\" with entities \"[[75, 97, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m just starting to feel really panicky and anxi...\" with entities \"[[17, 118, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" time to leave a passive agressive note to the own...\" with entities \"[[1, 104, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Hear  full album preview during todays webcast!  #...\" with entities \"[[62, 93, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i want to experience snow  we don`t have snow her...\" with entities \"[[57, 64, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it`s not sooo noticable it depends on how you loo...\" with entities \"[[96, 111, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  you`re mean to me. You`re gonna have to have piz...\" with entities \"[[7, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hahahah of course  they have such a nasty display...\" with entities \"[[28, 58, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"mom just woke me u[p and i am so mad i was dreamin...\" with entities \"[[106, 114, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I definitely missed listening to The Spill Canvas,...\" with entities \"[[13, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" too late  I`m already on the bus goin home  what ...\" with entities \"[[1, 85, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" come back to Perth     I missed the show here!\" with entities \"[[24, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Eating pringles at nearly 1 AM really reminds me  ...\" with entities \"[[102, 123, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh man, that sux... price u pay for being on the ...\" with entities \"[[14, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" He doesn`t need the shirt for that Jane...we just...\" with entities \"[[42, 64, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" following 865 and followers 539...not nice\" with entities \"[[34, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Thats actually not that fun as you would think......\" with entities \"[[1, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"my phone is broken    & im too lazy to go to the v...\" with entities \"[[0, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"#myweawkness chocolate...i can`t say no\" with entities \"[[0, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aha yeah  all else fails just push  yeah we are d...\" with entities \"[[18, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \":kwanghock    it is the Hao Da Za Ji Pa?? I miss t...\" with entities \"[[42, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"but now my feet really hurt...\" with entities \"[[23, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"New work wellness challenge not going well.  I com...\" with entities \"[[101, 127, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Know I`m not the only one.  Just harder on me.\" with entities \"[[32, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" its ok..i was kinda feeling ignored anyway  And i...\" with entities \"[[8, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"im soo bored...im deffo missing my music channels\" with entities \"[[7, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i fear the spaceship is not long for this earth. i...\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_mcsupergirl ok, finished set u free, and i am soo...\" with entities \"[[42, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i am Marina and i sware to God i`ll never again en...\" with entities \"[[18, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" - So sorry Ambien got sick.  Perhaps work her ash...\" with entities \"[[21, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  get back to tokyo man..we miss you.\" with entities \"[[26, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I know.  I have such guilt associated with pickin...\" with entities \"[[20, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"All of a sudden I`m craving broccoli and cheese so...\" with entities \"[[60, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" are you giving up on me  oh well. It`s not the co...\" with entities \"[[106, 127, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" physics  the most boring class ever!\" with entities \"[[17, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Psych has to be better than neuro!  Or at least i...\" with entities \"[[73, 85, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Tired and gunna go to bed soon!!! First time I`ve ...\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Youtube isn`t working...and I wanted to watch Brit...\" with entities \"[[8, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" can`t! need to work on overtime project at luncht...\" with entities \"[[58, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  that made me sad..\" with entities \"[[10, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   We were all set to get a room last Saturday! I ...\" with entities \"[[74, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"So I played this game , yeahhhhh I lost  I`m inlov...\" with entities \"[[59, 89, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"In a period of exams days are for study and nights...\" with entities \"[[74, 89, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"      You`ll be missed!!  Bring me back  a keychai...\" with entities \"[[6, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"So disapointed,good Evans,  they sound really bad,...\" with entities \"[[3, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" that`s family for you  imna crash, woke up 630 3 ...\" with entities \"[[27, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"blahh i`m tired and i gotta go to the airport to p...\" with entities \"[[0, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Is sooooo tired... wants to crawl back into bed\" with entities \"[[3, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" you seem desperate,that says probly enough\" with entities \"[[10, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no, silly, to shoot other shoppers with  though a...\" with entities \"[[83, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Oh ffs :@ a don`t get paid till monday :@:@:@ :$. ...\" with entities \"[[50, 104, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" im home alone in the house and imma scared  x\" with entities \"[[35, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Now i feel really really bad...sorry\" with entities \"[[25, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Rest in peace marshall\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Cancelling my JavaOne  http://ff.im/3nzTH\" with entities \"[[0, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Migranes suck....Especially when the kids are sudd...\" with entities \"[[9, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"aarrgghh - fu*k.....a hose has leaked water all ov...\" with entities \"[[0, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"why does  never reply to mee  he must really hate ...\" with entities \"[[36, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m working on a painting due for school and hati...\" with entities \"[[44, 59, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate waiting in lines\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" now my heart isnt cold  but im still missing you.\" with entities \"[[27, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ashley tisdale , i mean . cuz shes in berlin on 6t...\" with entities \"[[86, 121, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Dans public transport again and have decided it`s ...\" with entities \"[[89, 102, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Very bad things.......I need to stop thinking!\" with entities \"[[0, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m the same way, but with Backstreet Boys. I rem...\" with entities \"[[114, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" wow... you`re doing this all through text?  I wou...\" with entities \"[[55, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"4 hours of sleep, a migraine, again? What is wrong...\" with entities \"[[38, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Hey where my left ****? She never respond bacc..\" with entities \"[[28, 44, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it`s nto as good\" with entities \"[[4, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I would think the pres would be afraid you`d Pun`...\" with entities \"[[31, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"now feels like a dork for using the wrong Ping gro...\" with entities \"[[10, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ERRG I cant believe that i am not working at all n...\" with entities \"[[0, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Food @ Cheesecake Factory w/ Travis. He lost his p...\" with entities \"[[37, 60, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"feel like ****.....and will continue to for as lon...\" with entities \"[[10, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  YOU`RE FAKING IT! Hahaha...I kid.\" with entities \"[[7, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is back home now      gonna miss every one\" with entities \"[[23, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i think they are working why eyes are drooping  it...\" with entities \"[[50, 96, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ugh... only 1 3/4th hour and i will be 19...\" with entities \"[[0, 5, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I heard from  &  you`re away. I miss you too  Loo...\" with entities \"[[28, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Jess is invited just not me  I feel really unlove...\" with entities \"[[35, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_mejer I couldn`t remember what all the different ...\" with entities \"[[9, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" soooo over ppl telling me they went to the tonite...\" with entities \"[[92, 104, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" **** marriage isn`t legal everywhere here.\" with entities \"[[13, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I know what you mean  rain sucks...\" with entities \"[[26, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" im hella pushin for it...how was tha graduation.....\" with entities \"[[49, 55, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"****... It`s 2am and I`m wide awake\" with entities \"[[0, 6, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Now that sucks...  P?i ?i s? n?eleg c? Jay Len...\" with entities \"[[1, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" boo... i was hoping for a fake alien story with a...\" with entities \"[[1, 5, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"nooooo its raining......had 2 leave the beach\" with entities \"[[0, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Is not a happy bunny\" with entities \"[[3, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"how do i get my cat 2stop killin rabbits? another ...\" with entities \"[[0, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"if you`re as lovesick as I am, give me a call, we ...\" with entities \"[[72, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"dammit i cant watch stadium music\" with entities \"[[0, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Not looking forward to the upcoming week...My bett...\" with entities \"[[91, 110, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Heh, aye. I should have investigated properly fir...\" with entities \"[[81, 121, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Im not bannished... but I am at work till 6\" with entities \"[[1, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Last day at DMA over!     a million sad faces.\" with entities \"[[32, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" revising as uni exams are looming\" with entities \"[[25, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Kinda may have chickened out...\" with entities \"[[0, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m watchign the garden from the window...far too...\" with entities \"[[42, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Likewise. But I don`t know anyone who uses gtalk ...\" with entities \"[[65, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Without whipped topping, there is no shortcake.  ...\" with entities \"[[51, 64, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Think wearing bermudas at the cinema wasn`t a goo...\" with entities \"[[36, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" and he REALLY doesn`t like Shiny Happy People. I`...\" with entities \"[[13, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Oh no matey, did you get ill?  It would be a bit...\" with entities \"[[48, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"always tired, always cold and always have a headac...\" with entities \"[[105, 138, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Had a crazy night, lost keys, walked home, missed ...\" with entities \"[[86, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I missed the bl***y bus!!!!!!!!\" with entities \"[[2, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I cant to sleep and tomorrow i must wake up too ea...\" with entities \"[[0, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" you`re missing the devil wears prada!!!!! sad...\" with entities \"[[43, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m pondering lunch at Shane`s. I think. I can alr...\" with entities \"[[67, 77, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_n_booklife I heard about that too... that seems a...\" with entities \"[[52, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hypnotyst .... hmmmm... i should beware..\" with entities \"[[34, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aaaah I swear I took it by mistake  it was someho...\" with entities \"[[76, 120, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"boo for all the season finales..\" with entities \"[[0, 6, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"just got back from my exam... im surely gonna fail...\" with entities \"[[46, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Omg ! BGT making me cry  . That wee girl  it`s soo...\" with entities \"[[49, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Toooooom! Do a tour in the Philippines, pleeease?...\" with entities \"[[53, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Just got my marks...  BCIT is the death of me I sw...\" with entities \"[[32, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Okay, the man with the hook for a hand is kinda fr...\" with entities \"[[39, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nope  i`m bored and hungry.\" with entities \"[[9, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   plus, it is going to clash with ugly betty when...\" with entities \"[[12, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" which case? I got a new one last week and I`m not...\" with entities \"[[41, 77, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" LMAO! I don`t fake being Paris anymore. Look at m...\" with entities \"[[1, 102, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My mouth hurts from this stupid retainer!!\" with entities \"[[0, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yeah, Sabrina..though I keep thinking it`s someth...\" with entities \"[[80, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_music aah i stopped getting your updates on my ho...\" with entities \"[[61, 67, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"<-----bored to death\" with entities \"[[6, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"has spent the last two weeks attempting to grow a ...\" with entities \"[[100, 109, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ok sweet! and whenever u want, I am stuck in bed ...\" with entities \"[[29, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"wonders when all of these end... hay...  http://pl...\" with entities \"[[0, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no.1 dont really mean anything to me anymore :L i...\" with entities \"[[4, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m not! They frighten me to death............I ju...\" with entities \"[[9, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" No i am not a mom or dad, hmm well I will forward...\" with entities \"[[75, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" those splinters look very painful...but you were ...\" with entities \"[[27, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I would of won that contest if I weren`t to have c...\" with entities \"[[2, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" OMG.  I`m so sorry! Anything I can do to help?\" with entities \"[[12, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i hate history coursework sooo much\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I dint dump anyone. It`s always me who gets dump...\" with entities \"[[55, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m bummed...you`re gonna be only 30 minutes from...\" with entities \"[[1, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ready for the weekend and sad that I have to be at...\" with entities \"[[26, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"omg i didnt tweet all that much today.... *sadness...\" with entities \"[[40, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_leigh u know wut devy dev it sure does suck havin...\" with entities \"[[78, 90, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Officially out of my apt  Learned some stuff about...\" with entities \"[[107, 114, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Can`t give blood within a year of getting a tattoo...\" with entities \"[[68, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"The geographY was an exam today!But turned out wel...\" with entities \"[[109, 118, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh so nooooowwww youre too busy for me...dam I se...\" with entities \"[[18, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ...i`m sorry about you are still sick  u know mos...\" with entities \"[[3, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i guess ill never have it  but the sad thing is t...\" with entities \"[[30, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_girl - Bummer...mail came but package didn`t\" with entities \"[[8, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I`m sorry to hear that. Here is my optimist: Thi...\" with entities \"[[4, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"hopping in the shower,   you can help me tidy my r...\" with entities \"[[44, 69, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh the noon? I don`t know if I can make that one....\" with entities \"[[14, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh ok,Thanks.Dont know where the courthouse id ei...\" with entities \"[[113, 120, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Summer Glau to appear in Dollhouse next year http:...\" with entities \"[[72, 117, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"tired as hell!!!! bed time from cara  nighty night...\" with entities \"[[0, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I am sad... Tanner wasn`t invited to the Panthers ...\" with entities \"[[5, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh no your sick! I`m feeling kinda sick too  and ...\" with entities \"[[52, 60, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Never has a chance of sleeping before midnight  my...\" with entities \"[[62, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"LAPPYTOP BATERRRY DYING,tryingtofind a movieto wat...\" with entities \"[[0, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I am so sad...\" with entities \"[[8, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Im really desappointed...\" with entities \"[[6, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Oh man....my fiance just got off work and I start ...\" with entities \"[[68, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   too bad Vo got me sick I think  & I don`t even ...\" with entities \"[[3, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  EEW  Cheese. I hate cheese.\" with entities \"[[15, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Or he`s gonna chop you up into tiny bits - one of...\" with entities \"[[2, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i would slip and fall... on the dirty school bathr...\" with entities \"[[0, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"heading up to the farm   dont want to i wanna stay...\" with entities \"[[84, 116, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i havent been out west since 07...i think i picke...\" with entities \"[[34, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Don`t know what the heck to do with the space of t...\" with entities \"[[77, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"can i have some followers :` ( ... i`m so sad...  ...\" with entities \"[[26, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Jeff can`t get his visa in time to come visit me! ...\" with entities \"[[54, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I`m @ work and missed everythin yesterday but do...\" with entities \"[[15, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" SO jealous...see if you can get some Dallas conce...\" with entities \"[[4, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Im in so deep its disgusting. I would even take a...\" with entities \"[[17, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I wish I knew someone down there who could hook ...\" with entities \"[[54, 121, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I know. I think I`m going to have to miss it, tho...\" with entities \"[[103, 110, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" my days been aight! been cleaning mostly! went to...\" with entities \"[[79, 87, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i want magic mountain tix but i dont get ur stati...\" with entities \"[[68, 73, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it would hurt only when you touch it or when it g...\" with entities \"[[90, 126, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Oh how today sucks....\" with entities \"[[13, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"wow its follow friday and i havent tweeted... Fail...\" with entities \"[[89, 106, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  darn! now we have to go through the WHOLE weeken...\" with entities \"[[50, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ohh, i`m watching my best friend`s wedding. it`s ...\" with entities \"[[53, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aww  that`s horrible! xD\" with entities \"[[11, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" lol,  on blip.fm is not the  on twitter! i hate t...\" with entities \"[[39, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  #wci hashtag simply isn`t dying out anytime soon...\" with entities \"[[26, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  It is so unfair, Hustlaball, US citizens working...\" with entities \"[[9, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"mannnn..... _ got an iphone!!! im jealous....  htt...\" with entities \"[[34, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"so bored at work, its ridiculous, and my Saturday ...\" with entities \"[[18, 69, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" OMG....that is soooo sad.\" with entities \"[[7, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i JUST **** cleaned the whole kitchen....and the *...\" with entities \"[[49, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hey!  sorry for the late reply.but i do plan on p...\" with entities \"[[7, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yen lol but i can only get the vid on my phone an...\" with entities \"[[55, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"waaa the octo drive and i can`t go for it\" with entities \"[[0, 7, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Will miss nostalgia ... everyone please kick tusha...\" with entities \"[[0, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i bit my tongue sooo bad...it`s swollen.\" with entities \"[[16, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate when it`s cloudy. I either want it to be al...\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" but it all went too quick and there wasn`t a chan...\" with entities \"[[29, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Whew! I literally shopped till I dropped....and sp...\" with entities \"[[68, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" sigh..... exams aint no wer neaaarr finished!! i ...\" with entities \"[[71, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  gutted i miss that! the one night i try 2 leave ...\" with entities \"[[80, 87, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"In bed can`t sleep .... Something is missing.....\" with entities \"[[37, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" There`s loads of highly qualified stuff  and load...\" with entities \"[[44, 75, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I think it`s because I`m always offtopic and som...\" with entities \"[[25, 70, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"OMG...the heater in my room has been on all day wh...\" with entities \"[[0, 5, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Nothing like getting to work and finding out you h...\" with entities \"[[33, 87, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Have I ever told you I absolutly hate writing emai...\" with entities \"[[33, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  i`m sorry people are so rude to you, isaac, they...\" with entities \"[[4, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" why you never answer me..  wath i say to you\" with entities \"[[1, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Im @ the dentist  ....scary people here...\" with entities \"[[21, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"shud realy go 2 bed  proper tired bt cnt b boverd....\" with entities \"[[35, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \": I`m sure lots of that studio equipment was colle...\" with entities \"[[109, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" kenny u alive!!!...I`m here getting da hair done....\" with entities \"[[90, 95, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Hmm, $25 to see the Decemberists, but I have to go...\" with entities \"[[92, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"*sigh* I`m going to bed... I just don`t feel right...\" with entities \"[[27, 60, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" srry can`t go paintballing tonight  and there are...\" with entities \"[[49, 58, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   Sorry, we`ll try to keep it down.\" with entities \"[[3, 7, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ze Franz has not friended me  i think they think ...\" with entities \"[[37, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I would but its like 1800 or 1000+ miles  gas pri...\" with entities \"[[56, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"had 2 leave the mrs  cuz i have to go 2 work  real...\" with entities \"[[51, 67, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" god I need to revise today! I`m so lazy\" with entities \"[[34, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I can`t die  I have a lunch date with rocio comin...\" with entities \"[[73, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"being far too vigorous with pruning and regretting...\" with entities \"[[40, 53, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh  I`m sorry  I can`t even imagine...although I ...\" with entities \"[[7, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I don`t think they sale Ciroc where I stay..****....\" with entities \"[[44, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"wishes he had realized his wife hadn`t held onto t...\" with entities \"[[23, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   No, seriously you guys, I /wanted/ to kick Mond...\" with entities \"[[3, 60, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Same  also trying to get my house ready to sell.....\" with entities \"[[74, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   .?????.  i bet. man i wish i coulda...\" with entities \"[[113, 130, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Wow, really? I didn`t know it was that serious.  ...\" with entities \"[[26, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_Bee same here : /   Coincidently, my friend just ...\" with entities \"[[48, 59, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"This will be the worst day ever....graduation\" with entities \"[[17, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  FTR I <3 U and miss U on the team already\" with entities \"[[15, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Hey girl!  Yeah, my allergies kick in at the most...\" with entities \"[[19, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m so lost without my laptop. And no break again ...\" with entities \"[[64, 82, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Is sad when people`s phones are dead\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" is it bad that I sort of want her to miss me?  I ...\" with entities \"[[63, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Trying to go to sleep but no luck  I think i`m sic...\" with entities \"[[22, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"can`t stop playing Fallout 3!  This game is addict...\" with entities \"[[71, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is tired and about to go to sleep. night everyone\" with entities \"[[0, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  haha, i was crying  ****\" with entities \"[[12, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Si, no bueno  I guess I just don`t entertain him ...\" with entities \"[[21, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Sick......and no it`s not the swine flu atleast I ...\" with entities \"[[0, 6, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Grrr, I can`t even practice Trumpet or vocals beca...\" with entities \"[[70, 82, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"HOMELESS afterJune 1st.......\" with entities \"[[0, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ohhhh, how sad...I didnt get it!\" with entities \"[[11, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m currently into Emarosa. Their new album is th...\" with entities \"[[50, 91, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  BUT THEY ARE EXPENSIVE.\" with entities \"[[13, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_BHB I went to that concert and I remember Derek a...\" with entities \"[[74, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"WTF? Twitter doesnt support messages from my phone...\" with entities \"[[13, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Hahaha I miss Bradddd and all of the guys and KEI...\" with entities \"[[6, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Just getting back into the swing...Still sore from...\" with entities \"[[35, 73, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Well,  I discovered I can`t swim.  I`m out.  Sorry\" with entities \"[[42, 49, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  i can`t vote for  her i`m #frustraded  :@\" with entities \"[[25, 38, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Just got refused a bottle of morgan`s in tesco des...\" with entities \"[[92, 101, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"im tweeting... this is so hard... i dont get it...\" with entities \"[[23, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" but...he`s..mine  you told me a couple of weeks a...\" with entities \"[[60, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I wanna buy a million copies. But i aint that rich...\" with entities \"[[31, 85, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" lucky! been beggin for jury duty for years...they...\" with entities \"[[44, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" that is sickening... Just shoot at will? Smh... P...\" with entities \"[[1, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" what`s goin on hun?  I`m worried about you\" with entities \"[[24, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Im sad...there`s a for sale sign in front of my ho...\" with entities \"[[3, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Oh ****.... Here goes my head again, 'I`m Spinning...\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"UP is the saddest movie i`ve ever seen\" with entities \"[[10, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"yay for nice weather, boo for cici not being here ...\" with entities \"[[0, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" they tried to take me 2 jail sissy  apparently i ...\" with entities \"[[81, 108, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I want to go with you !  But I`m tierd....\" with entities \"[[32, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"doesn`t want to go to work....\" with entities \"[[0, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"'No offense, but your hair is bad today.' Life isn...\" with entities \"[[22, 131, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"tired and all i want to do is play random songs on...\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" but my bday is JUNE 19.. this is wack... and ihav...\" with entities \"[[34, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"****... Why does it take so long to install SBS200...\" with entities \"[[0, 6, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Consider yourself lucky.  It hasn`t rained here i...\" with entities \"[[61, 73, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" **** girl I`m so down but ya gotta let me know so...\" with entities \"[[114, 120, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh, that sounds bed..poor girl\" with entities \"[[21, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aw  were sad you had to leave tokyo. come back.pl...\" with entities \"[[8, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" YAY!!!!   I have Mark issues, too...you`ll find I...\" with entities \"[[62, 70, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Twenty minutes on a **** call you would think that...\" with entities \"[[0, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m sooo lost without my car  This is truly depres...\" with entities \"[[42, 55, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i`m so sick   bad throat and the WORST toothache. ...\" with entities \"[[31, 38, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I dnt get to go play lasertag w/ my besties!     *...\" with entities \"[[49, 71, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" why go winchester when my sister doesnt go there ...\" with entities \"[[62, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Whats with you though, you sound a bit down yours...\" with entities \"[[24, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" --sorry for running over uncle Terry, but he just...\" with entities \"[[2, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" because I couldn`t get the money to mikey in time...\" with entities \"[[73, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Bro. Martin!! I need you to repent!! Pam said we ...\" with entities \"[[27, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" left.  so sad. waiting for mom to come home. want...\" with entities \"[[9, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i HATE U.S. history\" with entities \"[[0, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m sorry...I`ll make sure I do that next time.\" with entities \"[[5, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Ouch!!... Stomachace.... I ate a lot...\" with entities \"[[10, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I`m soo sad. It`s just on the edges of the pages...\" with entities \"[[8, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"VERY upset....  Mom is in the hospital\" with entities \"[[5, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i wanna leave work already! Not feelin it 2day\" with entities \"[[2, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"going down the post office to try and sort this wh...\" with entities \"[[48, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I do the same thing to anybody covering dave... ...\" with entities \"[[59, 71, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Suspect tax-man is at fault....\" with entities \"[[23, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" lol i know  and haha..did you fall asleep?? or ju...\" with entities \"[[55, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Stupid freshmen ruined theatre class.. Now we don`...\" with entities \"[[16, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is watching 'Sicko' and is utterly digusted with t...\" with entities \"[[27, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"**** you ipod for freezing when i need you most\" with entities \"[[0, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"3 tweeets {:    FGS tweekdeckkk hates me  -cryyyy\" with entities \"[[29, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"feeling lonely,DH on night shift all w/e\" with entities \"[[8, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yea yea  im about to torture myself by doing a st...\" with entities \"[[20, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I had bad net issues on Weds so couldn`t broadcas...\" with entities \"[[5, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"mom is ok so far. just missing jaron\" with entities \"[[18, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Wait...  and ... Electrik Red or Richgirl?  I`m a ...\" with entities \"[[40, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  i know the feeling, working so much sucks hardco...\" with entities \"[[35, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" If it is any consolation I got my BMI tested haha...\" with entities \"[[74, 124, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  lol.. zzzzy in office and I`m alone in my bay ag...\" with entities \"[[25, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" IDK....I`m trapped at work all day\" with entities \"[[7, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nothing aimed at you, just joining in...sorry\" with entities \"[[40, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Sheesh. No crochet? BAH and humbug. And sleep? Um...\" with entities \"[[27, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Sounds painful   Sorry you got hurt.. And may I a...\" with entities \"[[18, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m not at chaseton`s either  please don`t die, m...\" with entities \"[[71, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"school and the guy i like was talking to the girl ...\" with entities \"[[92, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m guessing the belt thing is a no-go since I di...\" with entities \"[[18, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m on my mobile so it won`t let me  but i can`t ...\" with entities \"[[40, 73, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I am very sad because I have gone on the show McFl...\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_de_B You have to email her - she only gets what p...\" with entities \"[[92, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  He`s got adjusting his mate`s online shop... Zzz...\" with entities \"[[64, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is updating an old ipod...sad...i miss my orange n...\" with entities \"[[26, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i want you to go walking with me!! but i still mi...\" with entities \"[[38, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"waking now, so lazy and very worry ...\" with entities \"[[12, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"so tired after work...but i have King`s Bounty Add...\" with entities \"[[0, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"will be very hard to go back to work this morning-...\" with entities \"[[0, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"So bored.... couldn`t go to a-kon...\" with entities \"[[3, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I can`t  has blocked me.  I can`t even request\" with entities \"[[1, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_juneau I did, until my parents got all f`d up and...\" with entities \"[[15, 49, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" *bows*  I try...sometimes it is hard\" with entities \"[[15, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" me too  she better be back soon! dude, this is my...\" with entities \"[[49, 58, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ohhh that cant be very fun    but hell you manned...\" with entities \"[[1, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Can`t sleep...so I`m watching HGTV. I`m afraid inf...\" with entities \"[[0, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   What did I do to you!  sheesh\" with entities \"[[22, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"on my way to work! working sucks big time\" with entities \"[[19, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Walking to class. I hate not having a bike....espe...\" with entities \"[[18, 44, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" **** that is awful... could not believe it at fir...\" with entities \"[[14, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Awww  that`s no fun, did you take something?\" with entities \"[[12, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  awwww i have no internet right now....  -drummer...\" with entities \"[[6, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hello  Well it`s sunny out but my head is fuzzy a...\" with entities \"[[41, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" You right...we are 'arguing' about nothing...I th...\" with entities \"[[12, 44, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"omg i just slept like 18hrs in the last 22hrs...  ...\" with entities \"[[0, 103, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"This may sound stupid... but i just bought a mask\" with entities \"[[15, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m sick and sad .... missing out on Martini Loung...\" with entities \"[[4, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i know... I don`t want to be left in our home by ...\" with entities \"[[9, 56, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" RE: Hulu Desktop in Windows 7 Media Center  http:...\" with entities \"[[83, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"     my bracelet broke today too.\" with entities \"[[12, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yeah I didn`t realize how bad it all was till now\" with entities \"[[21, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"justwatched the most depressing episode of Jon  Ka...\" with entities \"[[59, 84, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  on your ani?  sorry\" with entities \"[[13, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"... Still feelin like blah... 3 more hours\" with entities \"[[10, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is having headache and colds...\" with entities \"[[10, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m using paint.net x64 and it`s running crazily ...\" with entities \"[[74, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i waited too long to buy pink tickets!  now we`re ...\" with entities \"[[81, 86, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" 1000 = make sure it has the word poo or balls in ...\" with entities \"[[81, 99, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Now Im crying....  Poor thing..\" with entities \"[[4, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_KittyKat  so now im bored..untill i go out\" with entities \"[[18, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" KH is the only thing I`ll be a weeaboo about.  I ...\" with entities \"[[83, 94, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My BFF rocking Hotel California now. No  songs!  d...\" with entities \"[[87, 97, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yeah they are! So stop making fun of me! I gotta ...\" with entities \"[[17, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nah I don`t finish til next yearrrr!!!   are u st...\" with entities \"[[58, 69, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" what happened?  are you suffering from neck/shoul...\" with entities \"[[71, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i hate the bus...any donations toward my car fund?\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My tummy hurts...again\" with entities \"[[9, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Snap. I`m the same with any reality show. Watch t...\" with entities \"[[76, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Oh, I`m so sorry!...my kitty is there right now b...\" with entities \"[[5, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I don`t feel so good after eating all that food  u...\" with entities \"[[0, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" dammm..i thought i was on to something  lollllll\" with entities \"[[1, 7, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My back hurts...really bad\" with entities \"[[15, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is sad that shin ae got married...and it wasn`t to...\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  That was stone cold   Crazy....  ?\" with entities \"[[2, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" LOL.  Leave a kid on internet and the kid will do...\" with entities \"[[49, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Also, why are paracetamol so hard to swallow? Even...\" with entities \"[[6, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_ listen to FTSK  they stop my bordum  haha how wa...\" with entities \"[[69, 77, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Hi  Yes wasn`t she absolutely terrible! How on ea...\" with entities \"[[18, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I dunno...I thought I was funny\" with entities \"[[10, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"well...gotta grab at least an hour and a half slee...\" with entities \"[[89, 135, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Shoot, Rob I missed it. Just got home.\" with entities \"[[10, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Linda ~ What do you mean by your last post??  It...\" with entities \"[[45, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" The devil you say!  I`ve been waiting for the Bla...\" with entities \"[[75, 104, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" britains got talent is rather disappointing this ...\" with entities \"[[29, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m just starting it brinn, guess what?? i get my...\" with entities \"[[92, 103, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  hahaha well its try its so ugly\" with entities \"[[24, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  im just so lonely right now. maybe SADE GOT ME F...\" with entities \"[[11, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" not all of them  You`ll be missing mine and every...\" with entities \"[[26, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Bummer... I missed Taylor Swift on the Today show!...\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aw poor u   DON`T let her get 2 u just ignore her...\" with entities \"[[37, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I have clocked out for possibly my last time at No...\" with entities \"[[7, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   We`re idiots.  Ok mostly I was skint but hell I...\" with entities \"[[6, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Gleneagles then champagne receptions....can`t bea...\" with entities \"[[39, 117, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Monday...Funday!  Wake up people...and keep me awa...\" with entities \"[[115, 120, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m Twitter dumb. Just saw my '.com' & all the kin...\" with entities \"[[79, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" lol.  When I went to buy my new laptop in Feb., I...\" with entities \"[[104, 114, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Laying ALONE!! Since Mook`s soo comfy in his f`n p...\" with entities \"[[93, 129, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`ve been unlocked for decades now...just not luc...\" with entities \"[[37, 70, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Well yeah, the hormone things basically a given  ...\" with entities \"[[56, 115, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Too broke for cigarettes.\" with entities \"[[0, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I would much rather you didn`t punch yourself in ...\" with entities \"[[60, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nope- dnt have wireless ne more  HATERS!!!! Ugh.....\" with entities \"[[31, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it`s a modded 360, so you can`t send it back?  Th...\" with entities \"[[69, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" me too i hate revision\" with entities \"[[6, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_babsi there`s a manual process... but it`s taking...\" with entities \"[[90, 99, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"whoops...  not  in my last tweet\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Has research guilt as I spent the day feeling sorr...\" with entities \"[[0, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Sob! I can`t believe I`m ending my work week at th...\" with entities \"[[5, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"trying to finish my ****-ignment.please god help m...\" with entities \"[[20, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I dont know  I didnt even realize it was gone  le...\" with entities \"[[70, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Arghhh So annoyed-yet again gone 2 starbucks & giv...\" with entities \"[[10, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"****, nearly forgot my PIN  I shouldn`t try to lea...\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" But then you might end up like that poor bus driv...\" with entities \"[[37, 53, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ooohhhhh - sorry  So sad - never noticed the doll...\" with entities \"[[20, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"last day of school and last concert of my life.. w...\" with entities \"[[55, 101, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I picked up some stuff I missed the 2nd time  And...\" with entities \"[[22, 92, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hehee!! yea its supposed to sound mean.. hahhaa\" with entities \"[[17, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" so you are like the rest of us on this miserable ...\" with entities \"[[38, 49, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"1 week post my'horrible, traumatic jumping cholla ...\" with entities \"[[15, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \". Too bad they never made it over here during the ...\" with entities \"[[2, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Down again   seems like it never gonna stop and I`...\" with entities \"[[46, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nnnaaa uhhhh playah! shawty aint got nun, maybe i...\" with entities \"[[76, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yo wake your **** up  and go to work  go get that...\" with entities \"[[66, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" o its feels like a hot box and no matter where i ...\" with entities \"[[11, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"@_Glitter_  kk but 4 sum reason its not lettin me ...\" with entities \"[[34, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Nope  Not that I have to worry about the possibil...\" with entities \"[[62, 71, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Off to NC tonight until June 7th! I`m going to mis...\" with entities \"[[34, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yes bb  There are actually 2 of them, but the oth...\" with entities \"[[36, 90, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  What`s wrong with her?\" with entities \"[[7, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m feeling so frustrated...I just can`t get thing...\" with entities \"[[0, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Awww. Don`t mean to sound like an overgrown age 3...\" with entities \"[[60, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"..dat dude look crazy w/ dat hair on his face lmao...\" with entities \"[[110, 133, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i wish i  would in california.....i m so sad\" with entities \"[[40, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Alright...you missed one crazy party last night\" with entities \"[[10, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Been there and never at a good time   Your recou...\" with entities \"[[15, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hi I`m ok   still not feeling great\" with entities \"[[1, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Having one of my bad days....Migraine today. My 1s...\" with entities \"[[0, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Definitely grass cutting   Cole has committed him...\" with entities \"[[119, 129, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"frame damage... car could be totalled\" with entities \"[[6, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" my poor baby I think it`s allergies! Can I do amy...\" with entities \"[[2, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Crisis: forgot my fringe comb  I`m with men....no ...\" with entities \"[[46, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  thx, I was aware,  2 day festival -multi bands -...\" with entities \"[[58, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"sorry paul scheuring, but prison break series fina...\" with entities \"[[0, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh! Yeah,your mom told be about that.  I thought ...\" with entities \"[[101, 108, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is on twitter for the second day running. This is ...\" with entities \"[[1, 111, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Umm..ok..just don`t start cats on fire..  ...prom...\" with entities \"[[9, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" get better omg i still dont believe that i didn`t...\" with entities \"[[77, 86, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i`m a little sad that school ended today i`m movin...\" with entities \"[[6, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Getting closer to logging in. My left hand is so s...\" with entities \"[[110, 121, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"TGIF, too bad the weather sucks...\" with entities \"[[6, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Gees can this week get anymore horrible....now i c...\" with entities \"[[5, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is still pretty depressed about losing her hello k...\" with entities \"[[0, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  to mast ladki patata hai chal jiske sath bhi jay...\" with entities \"[[69, 75, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I feel like ive done the London marathon, I ach al...\" with entities \"[[44, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"    i have been getting **** ones as i mentioned -...\" with entities \"[[47, 86, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" lunch was going home to rest...not well today\" with entities \"[[31, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ****  real sorry to hear that ma\" with entities \"[[10, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"After work....Hillcats game!   .25 cent hot dogs h...\" with entities \"[[47, 53, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m not sleeping at all until  accepts my appology\" with entities \"[[0, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My dreams have been crushed...Spock does not like ...\" with entities \"[[20, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  that`s the worst dream ever. weird to think all ...\" with entities \"[[11, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" very familiar.....sorry you`re feeling that way\" with entities \"[[18, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hate u....  I have 2 wait one week to see it cuz ...\" with entities \"[[1, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m sorryyyyyy  I`ll be home as fast as possible ...\" with entities \"[[3, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I hear you   Any time earlier than 11am is just m...\" with entities \"[[46, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"if officially done with high school....  so sad......\" with entities \"[[41, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"graduation is done  im a little sad.. anyone want ...\" with entities \"[[32, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is house bound with acute mumps  bad times.... who...\" with entities \"[[15, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_newman i just called and it`s sold out.  bummer. ...\" with entities \"[[39, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Aw poor you..ironing! Eek! lol It`s raining here ...\" with entities \"[[99, 126, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I kinda want to smack that darn skeleton though.\" with entities \"[[8, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  it might be the swine flu! haha `cause i`ve got ...\" with entities \"[[16, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"acsvxdcbgfn soccer now. shall see young phoebe aft...\" with entities \"[[56, 86, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I know!!  effing embarrassing! Eff our lives\" with entities \"[[16, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   someone is ignoring me  & being mean..\" with entities \"[[11, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Definition of senioritis: Me. About to go to chem ...\" with entities \"[[67, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" not my groom!  think i`ll die an old maid! lol\" with entities \"[[25, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Heading to the gym.  The group of guys that USED t...\" with entities \"[[121, 126, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yea...looks like it is...sorry abt nt gettin in t...\" with entities \"[[25, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"DIDO 'US 2 Little Gods' http://ow.ly/9UIn 'Just th...\" with entities \"[[123, 130, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  We can`t even call you from belgium  sucks\" with entities \"[[36, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" so sad...sorry to hear that.  She was a sweet dog...\" with entities \"[[1, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" then how come I`m not uber successful?  I`m not m...\" with entities \"[[63, 73, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m bored... Don`t want to stay home tonight, but ...\" with entities \"[[4, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ack, no can see  either.  and weird, these tweets...\" with entities \"[[28, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I need to burp ....  Im so nauseas....\" with entities \"[[27, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_Punk_Robot  wtf.....winter isn`t due til monday, ...\" with entities \"[[13, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m a jerk...  now I can`t go out    Dammit Frank...\" with entities \"[[7, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I found a link on WWE.com  http://www.wwe.com/ins...\" with entities \"[[81, 89, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"http://twitpic.com/675u6 - Square B - she is sad b...\" with entities \"[[45, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Its sooooooooo not funny when I have to move from ...\" with entities \"[[0, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"dog just farted  so bad.....\" with entities \"[[20, 24, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"HEY YOU` ALL SUCK;its anybody on there :s im so bo...\" with entities \"[[13, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Math class ugh.  Rather be a class act.  **** quiz...\" with entities \"[[0, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"...And omg whats this dirty letter from Danny ever...\" with entities \"[[118, 134, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"So much to tell-Only blip is her immune system has...\" with entities \"[[47, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_xox  Oh god, everyone`s dying.  But it`s mainly j...\" with entities \"[[54, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"feels ****! and feet are aching  need my beeeeeddd...\" with entities \"[[0, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"oh i hate the rain... and septa... and leaving my ...\" with entities \"[[0, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yeah exactly the fans overpower the haters anyday...\" with entities \"[[73, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"exhausted and sick... my face is greenish\" with entities \"[[14, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Sometimes it hurts that pets cant talk back to us....\" with entities \"[[10, 79, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"dont wanna cry  but the seniors are out there grad...\" with entities \"[[56, 78, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is feeling so bored... i miss school time\" with entities \"[[0, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Omg i`m on a one year work permit! Going home end...\" with entities \"[[60, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" wassup m8 ... bad day not good\" with entities \"[[13, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_WOCKEEZ  Don`t wanna miss ANY of your shows...you...\" with entities \"[[65, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Shelf from Ikea fell off the wall. damage done...a...\" with entities \"[[35, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" haha, its under 18 :@ so ive got no one to go wit...\" with entities \"[[56, 84, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I`m starting to feel depressed with this hurrica...\" with entities \"[[21, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i hav a bet to get a 6 pack in 35 days...im on da...\" with entities \"[[56, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Bout to get ready for work ugh i hate workin on fr...\" with entities \"[[33, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" idk if i could.  it would cost me soo much there.\" with entities \"[[25, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"$4 lonestar pitchers at  ?  If only I wasn`t still...\" with entities \"[[88, 103, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no    I kind of miss my first main.   Male Tauren...\" with entities \"[[14, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i think i hate you.  i didnt really want to but y...\" with entities \"[[47, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"dont get to see my boys tomorroww.im sad\" with entities \"[[34, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I REALLY  should have gone to the Chiropractor thi...\" with entities \"[[78, 85, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" http://twitpic.com/4j585 - Guess I need to get me...\" with entities \"[[85, 90, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Stuck in traffic on the 91 on the way to costa mes...\" with entities \"[[0, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"on my way to my dad`s with my sistas..  r.i.p. Deb...\" with entities \"[[37, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"In the middle of breakfast the school called.Yep.....\" with entities \"[[80, 91, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Im a bad blogger!! I have not blogged in weeks~ oo...\" with entities \"[[5, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"hates these khaki pants! project to do todayy\" with entities \"[[0, 8, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  will have to wait on the recipe at Simply Recipe...\" with entities \"[[51, 60, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  you are disappointing me......\" with entities \"[[2, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" they don`t use MSN either I don`t think  and they...\" with entities \"[[80, 93, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"at work booo....\" with entities \"[[8, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I feel slightly sick now  #BGT\" with entities \"[[16, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I know.  Sorry.\" with entities \"[[8, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Will we be able to see clips/episodes on the C4 ...\" with entities \"[[78, 122, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yeah  just told Stanley its the only time I want ...\" with entities \"[[51, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I know... he`s mad at us... :`(\" with entities \"[[10, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"On the way to Malaysia...no internet access to Twi...\" with entities \"[[24, 36, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Dropping my mum at the station   I`ll miss u mum\" with entities \"[[36, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Dreambears were **** compared to their wicked audi...\" with entities \"[[16, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"we`re getting another puppy  ... not cool... reall...\" with entities \"[[33, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Im JBobsessed  xD I miss them soooooo much!  Th...\" with entities \"[[8, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m sorry, but x-men sucks... in a bad way!  ;p\" with entities \"[[22, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I always feel guilty about it\" with entities \"[[8, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"had plans with people but they cancelled...now wha...\" with entities \"[[31, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Still dealing with quite a bit of pain, will jum...\" with entities \"[[34, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh dear, I take back my request.... I get so drun...\" with entities \"[[73, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" trying to have a baby, don`t want my soda addicti...\" with entities \"[[85, 90, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Why no sn... o. yeah... Sad day.....\" with entities \"[[23, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Bored... Some vector ****... Off to work after thi...\" with entities \"[[0, 7, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i feel u  but its sooo close to me hard not to  b...\" with entities \"[[1, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"THIS twitter is driving me nuts...WONT LET ME DOWN...\" with entities \"[[16, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I have to choose between  and _FC on Sunday and  w...\" with entities \"[[52, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ok cause the one  S orange is still open. Whew, y...\" with entities \"[[56, 64, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" http://www.CultureShockMag.com  shoutz 2  the mix...\" with entities \"[[69, 84, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_soch hah nooo she is the obly one that can AUMFFF...\" with entities \"[[51, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" didn`t have my camera with me  totally regretting...\" with entities \"[[38, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I don`t think I`ve ever been so tierd in my life.U...\" with entities \"[[0, 50, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"kinda has a headache...\" with entities \"[[12, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" from your fevered imagination, my son\" with entities \"[[9, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"PKU meeting in London, ON all day today.  One of m...\" with entities \"[[113, 135, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Meeting up with Karen and the boys for some drinks...\" with entities \"[[35, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" she is that`s why she never speaks to me in colle...\" with entities \"[[21, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i do show some discretion occasionally\" with entities \"[[14, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" That is super sad   How is Bart etc holding up?\" with entities \"[[7, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I told u I tried but 88 said it was 2 late  cause...\" with entities \"[[28, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"A movie`s worst fate used to be 'Straight to DVD'....\" with entities \"[[0, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Their inability to manage money, tough job market...\" with entities \"[[5, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" please do  I`ll settle for cheap cider for meetin...\" with entities \"[[9, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"It`s gloomy as hell outside today.\" with entities \"[[15, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  i think my niece got me sickee  lame.\" with entities \"[[24, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" well, I took it in early `00, graduated in `01. w...\" with entities \"[[47, 116, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" wish we could come see u on Denver  husband lost ...\" with entities \"[[43, 49, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"WHAT THE HELL IS GOING ON?!?! Last night and this ...\" with entities \"[[45, 66, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" they are having a closing down sale !    does not...\" with entities \"[[42, 58, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" not impressed....! it might go away if you compla...\" with entities \"[[1, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" CVS is that like a genetic brand?Poor you,my hubb...\" with entities \"[[33, 38, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"http://bit.ly/61Aam   these dogs are going to die ...\" with entities \"[[16, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"seriously getting hurt.... 4 days before nationals...\" with entities \"[[0, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I don`t know how to quit you-brokeback mountain\" with entities \"[[0, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  that`s sad. Trauma... Future serial killer...\" with entities \"[[7, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"just drove with my mom and brynn. my mom said im t...\" with entities \"[[34, 72, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I have 3 computers all going now.  IE 7 on XP and...\" with entities \"[[71, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" It`s sunny and hot in London today, while I sit i...\" with entities \"[[57, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" my plans might have just gone out the window too ...\" with entities \"[[53, 61, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" *HUGS you*  awwww......i`m sorry you are feeling ...\" with entities \"[[26, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" You have arthritis in them?  Really??  Poor you  ...\" with entities \"[[61, 69, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"afaik A LITTLE SAD THAT CROCCOS IS NO LONGER AVAIL...\" with entities \"[[77, 85, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  they r the most random things that my mind can c...\" with entities \"[[69, 75, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"a night alone with my piano...and a pro tools sess...\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"this sux but took like 4 minutes. going to sleep f...\" with entities \"[[0, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hot weather for the lose. And I have to clean too...\" with entities \"[[72, 79, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i did and i feel great....   but i still miss it....\" with entities \"[[39, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yep, exactly   And I`m really sad about this tour...\" with entities \"[[1, 91, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Right, **** the whole Twitter silence experiment. ...\" with entities \"[[7, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Ahhh...can`t do this one....will be in las Vegas ...\" with entities \"[[1, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m really nervous about giving a speech at a wedd...\" with entities \"[[0, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yeah, the economy sucks SO BAD.  Yeah, I know wha...\" with entities \"[[99, 111, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"y do i even bother getting a new fone..i just ****...\" with entities \"[[46, 59, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"yeha i broke their page... damit... im trying to f...\" with entities \"[[27, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"sitting at home being bored.......\" with entities \"[[22, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Trickery?  No, just exasperation at seeing **** P...\" with entities \"[[87, 95, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" HIII!!!!  i`ve missed you  just bored....what abo...\" with entities \"[[11, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Visit 2  La Ventana de los Cielos foundation was p...\" with entities \"[[110, 137, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Beto`s Pizzeria is on Banksville Rd in I believe ...\" with entities \"[[70, 77, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" you`re in harlem? where? im so jealous right now!...\" with entities \"[[30, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I think I might get some of that today.  My throa...\" with entities \"[[53, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Unless that invite comes with a beta key I`m not ...\" with entities \"[[40, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" the no tweeting guilt trip didn`t stop you huh?  ...\" with entities \"[[58, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no news on the kid. They can`t find the parent!\" with entities \"[[24, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"How sad is it that your best friend is so selfish ...\" with entities \"[[113, 125, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Feeling bad that  didnt get to see UP\" with entities \"[[0, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"HollowbabesHere comes the utter shite #bgt <I comp...\" with entities \"[[11, 37, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m not feeling very inspired today...I was suppo...\" with entities \"[[1, 38, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" will the presentations be available online during...\" with entities \"[[104, 131, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_Star95 oh so you know how I feel then  **** repre...\" with entities \"[[78, 102, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I need to do some more post but I don`t have time...\" with entities \"[[75, 108, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"http://twitpic.com/66ydb -  I made sure you got cr...\" with entities \"[[79, 112, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I am so hungry...if my arm were on the core diet I...\" with entities \"[[0, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Awww my daddy! Got in a car accident! Pray for him...\" with entities \"[[15, 40, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Practically my whole body burns... I can`t bend ov...\" with entities \"[[26, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i`m about to have to hang up   my fone is getting...\" with entities \"[[11, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Hell if I know.  I`m suffering\" with entities \"[[20, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" WHO IS SAYING ALL THIS...are you ignoring me *fro...\" with entities \"[[25, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  heheheheh... lol... I always figured he`d send t...\" with entities \"[[84, 112, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I feel bad over everything..  How can I be so stup...\" with entities \"[[2, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  i got too do course work   i hate it it is hard ...\" with entities \"[[29, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh no fair.... thats in 9 hours\" with entities \"[[4, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"He still doesn`t love me... I won`t ask again\" with entities \"[[0, 26, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" -thanks i hope i do 2  iv been playing dmc4 like ...\" with entities \"[[56, 74, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"dammit! hulu desktop has totally screwed up my abi...\" with entities \"[[0, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate being reminded how weak my eyes are  I over...\" with entities \"[[75, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" no panasonic charger.sorry\" with entities \"[[21, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I`m bummed to miss you.   Hope you enjoy your wr...\" with entities \"[[14, 20, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   Let us know what happens, poor little guy.\" with entities \"[[26, 44, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_1   is leavin bc of racists *starts cryin*\" with entities \"[[35, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i know  i`m tweeting more now though don`t you wo...\" with entities \"[[36, 124, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"thinking of you   why we cant control our thoug...\" with entities \"[[18, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Thanks for the follow my new Twitpeeps!\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is feeling her eyes burned-fried after 10 hours at...\" with entities \"[[20, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i know.. i suck.. i`m a master procrastinator  .....\" with entities \"[[10, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" DO NOT DO IT  I`ve seen enough  movies to 'know' ...\" with entities \"[[1, 91, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yep! It`s just quarter til 4 now.  I`m going to t...\" with entities \"[[72, 82, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"sad day*Lakers please make me happy with a W\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hey Jodi.. what`s up??ugg.. im bored.. i just mad...\" with entities \"[[22, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" majorspoilers.com has problems - cannot get the s...\" with entities \"[[21, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  yer it is...poor little ****  but she well doesn...\" with entities \"[[42, 58, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"How are YOU convinced that I have always wanted yo...\" with entities \"[[88, 110, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Rainy day today.  No car so we`re stuck in the hou...\" with entities \"[[92, 102, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate that I am so stinkin tired everyday!  It`s ...\" with entities \"[[45, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Feels all kinds of not so well right now\" with entities \"[[19, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" There are 3 other Drs. in the office and only min...\" with entities \"[[74, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yep...sadly I only had 10 min before a meeting!\" with entities \"[[6, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_Happy_EmoX lmao. Lucky! It`s 10 minutes on foot f...\" with entities \"[[57, 62, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is so tired ive walked 6.05 kilometres today\" with entities \"[[0, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  walah me 2 still i am not getting the full idea\" with entities \"[[22, 49, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"#BGT  Piers shouldn`t have buzzed when the little ...\" with entities \"[[10, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Well thats disappointing to hear.\" with entities \"[[13, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" its not a starfleet one  its not even a romulin o...\" with entities \"[[117, 123, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Here`s a more appropriate @ tweet... is everythin...\" with entities \"[[81, 109, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  it`s an app to finally face the truth: you lack ...\" with entities \"[[38, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"has the urge to go shopping.hmmm but i`ve got no m...\" with entities \"[[33, 56, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" she`s in LA, wanting sun today... but apparently ...\" with entities \"[[51, 70, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My flip flop just broke...walking in downtown seat...\" with entities \"[[18, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" u think its fair...... k den i guess m wrng.... s...\" with entities \"[[49, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is not feelin well... i feel sooooo weak....i hate...\" with entities \"[[36, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Is sad that her brother is having a bad day\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ask  to create a fake competetion and declare you...\" with entities \"[[13, 34, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m watching it at the moment  -sighs- and straig...\" with entities \"[[70, 83, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"ugh... dunno why im just not in the best of moods....\" with entities \"[[7, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" aww  I have to go to class on that day... So imma...\" with entities \"[[57, 64, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  why canceled your performance on Letterman? i`m ...\" with entities \"[[51, 56, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  I guess you are not interested !!\" with entities \"[[16, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_l I blame you for 1/2 price Fridays replacing Fre...\" with entities \"[[0, 13, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hmm...your blog won`t let me post a comment.\" with entities \"[[6, 45, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I like to support my friends  It`s sad that I`m y...\" with entities \"[[34, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  ugh headache   i just wanna go home\" with entities \"[[4, 14, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Cruising 'Serious Eats NY' does not bode well for ...\" with entities \"[[66, 76, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I wish y`all...unfortunately I won`t be able to m...\" with entities \"[[15, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" That`s one of the reasons we thought 'Should we h...\" with entities \"[[96, 114, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"God! They look stumpy... I`m not sharing my toes t...\" with entities \"[[5, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" You can get into Canada, but I can`t?  WTF!!!   (...\" with entities \"[[57, 95, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Another long walk in the heat... I hate this...\" with entities \"[[18, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"cant believe i stay out this late!.....waking up f...\" with entities \"[[29, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Is fighting a horrid headache with a large Vanilla...\" with entities \"[[14, 32, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"just found out I won`t be tweeting from ,my phone ...\" with entities \"[[123, 130, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"hate living down here in fl. missing GA like crazy...\" with entities \"[[0, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  totally missed the chatroom. I`m so lame\" with entities \"[[8, 16, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_elaine Our chandelier is here! I seriously don`t ...\" with entities \"[[32, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"The chicken noodle soup I made for lunch to feel b...\" with entities \"[[83, 98, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" blue skies? where, it`s still grey and hazy out o...\" with entities \"[[29, 44, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Ugh! I can`t access through my mobile web!\" with entities \"[[0, 15, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i can`t i can`t i can`t  i`m sad.... i`m from ven...\" with entities \"[[28, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" i want to comment but don`t understand what you`r...\" with entities \"[[21, 39, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"flipping out on my hairloss....gotta go to the doc...\" with entities \"[[19, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Anyone want to stop by Carl`s Jr and bring me a ch...\" with entities \"[[63, 79, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Something is totally eating up my broc, cab and be...\" with entities \"[[76, 96, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" you hate her, I love her.  presentation got cance...\" with entities \"[[43, 54, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Ah.  I just found it weird because it`s my screen...\" with entities \"[[20, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hey! chutti was very tiring.. and have to travel ...\" with entities \"[[22, 29, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Sorting out Twitter issues....very frustrated that...\" with entities \"[[30, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Yes it does. Please dont` go. If you die I will c...\" with entities \"[[99, 107, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"grrh  wii remote dead.. no multiplayer here tonigh...\" with entities \"[[8, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Star Warz day? Really..that is a hot topic? Man..o...\" with entities \"[[48, 57, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Ooooh, I`m jealous  I might try and get some for ...\" with entities \"[[65, 114, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" they are terrible little beast but if the garden ...\" with entities \"[[8, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" are you having any problems sending images from T...\" with entities \"[[65, 93, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Depends on what they want for it....I`ve become p...\" with entities \"[[36, 59, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  it sucks no matter where you are! I`m gonna frea...\" with entities \"[[3, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" The Northern Clemency.  But I don`t recommend it....\" with entities \"[[92, 103, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"favorite shirt ruined:death by bleach  #fb\" with entities \"[[15, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I hate different referenced assemblies. My FNH goe...\" with entities \"[[2, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yeah doesn`t that suck!  I am working with a Nano...\" with entities \"[[92, 100, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ooow those look painful, poor bb\" with entities \"[[10, 33, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I had a double cheeseburger and fries from The Go...\" with entities \"[[64, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Why are the sinks in hospital toilets so low? Now ...\" with entities \"[[38, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I have one less follower  That makes me sad and I ...\" with entities \"[[23, 94, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"pics arent working for me here on twitter\" with entities \"[[5, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is sad that she is not seeing Basshunter at Metrop...\" with entities \"[[0, 9, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  dude i will check again but i couldnt find anyth...\" with entities \"[[70, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Bought new racquet for $145... wish this racquet w...\" with entities \"[[82, 130, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" girl i am buying & posting your pressie tomorrow ...\" with entities \"[[88, 117, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" oh dear.. u serious? so how does one prevent bite...\" with entities \"[[60, 67, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Just had my teeth checked, now my eyes. I`m dying ...\" with entities \"[[67, 81, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"no so sad about that  i`m from MALTA have you hear...\" with entities \"[[3, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ha! I know..I`m very ashamed.\" with entities \"[[12, 30, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" yeahh  idk if i like owen anymore though... i kin...\" with entities \"[[43, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"also. proof number #2923848932 that I have no life...\" with entities \"[[101, 107, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I can`t eat a hot pocket anymore without thinking ...\" with entities \"[[0, 10, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"sleeping... would`ve been home sooner but we accid...\" with entities \"[[58, 67, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it`s a dreary monday morning and I slept like ***...\" with entities \"[[47, 52, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"moving back home today. pro: obnoxiously closer to...\" with entities \"[[29, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Ooooh, boo!  We only see each other at the bar (a...\" with entities \"[[62, 68, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" it is sooo hard.... truck and fish please\" with entities \"[[12, 17, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Not sure, but I CAN tell you what happens to a pr...\" with entities \"[[117, 127, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" :: I know the feeling  Its a little depressing :S\" with entities \"[[13, 47, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Ow... My shoulder muscle (I can`t remember the nam...\" with entities \"[[56, 63, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" Celebrity sighting: Spongebobs here! #BEA09   LOL...\" with entities \"[[81, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"There is something wrong with me! I`m so tired I c...\" with entities \"[[9, 27, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" _kat I`ve begged my mum to lt me get them out the...\" with entities \"[[99, 107, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" nope  het is LOST&found he ;-)\" with entities \"[[12, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"There`s Only One Thing I Hate About Friends And Da...\" with entities \"[[13, 46, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"Feet hurt...finally in bed...will not forget this ...\" with entities \"[[5, 11, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"as if i finsh work at eleven.. IS THAT EVEN ALLOWD...\" with entities \"[[56, 80, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  man i wont be home to co host with you!  xo*blai...\" with entities \"[[4, 41, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"My poor heather, she didnt make the cheerleading s...\" with entities \"[[59, 67, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" she fell into deep crack in the glacier  so terri...\" with entities \"[[43, 53, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"doesn`t wanna get dressed up and be an adult today...\" with entities \"[[0, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"leather jackets=uncomfortable....not my thing\" with entities \"[[16, 31, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"The balmain knockoffs in bebe make me sad.....I wa...\" with entities \"[[38, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"_pina_14  Not good!!He wouldnt like his girl flirt...\" with entities \"[[10, 19, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  im trying to fix myself really but i need to sto...\" with entities \"[[45, 51, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" boo...I thought being on the list meant it would ...\" with entities \"[[1, 5, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i don`t know what to do... time is going by so fas...\" with entities \"[[0, 25, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"is envious of people not in long-distance relation...\" with entities \"[[0, 23, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"This is not a happy tweet\" with entities \"[[0, 22, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m sowwy.   It sucks, I know, I`ve been there. Y...\" with entities \"[[14, 21, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ~ Sorry the response to my assistant job has alre...\" with entities \"[[99, 123, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"I`m so confused about the weather, is it really go...\" with entities \"[[0, 18, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"in about half a hour i`m going to my english lesso...\" with entities \"[[60, 79, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  Yeah the spammers are discriminating: none of th...\" with entities \"[[22, 38, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"im so not feelinq this huqe **** pimple smack in t...\" with entities \"[[75, 88, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" I`m sorry about your car. I feel for you...\" with entities \"[[1, 43, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"   People are cruel sometimes.  I can`t imagine be...\" with entities \"[[3, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"  We`ll miss you  #Sixx?\" with entities \"[[6, 12, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" so the beneath show got cancelled BUMMER! i guess...\" with entities \"[[33, 42, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"GOD SCHOOL IS GOING TO SUCK **** NEXT YEAR!\" with entities \"[[23, 35, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" hahahaha nice. i gave up on bio cos idk what the ...\" with entities \"[[35, 65, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \"i donbt like to peel prawns, i also dont like goin...\" with entities \"[[36, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" ugggh idk how to do that  but i only wanna stop g...\" with entities \"[[42, 48, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning:\n",
      "\n",
      "[W030] Some entities could not be aligned in the text \" used is definitely cheaper... may have to get lat...\" with entities \"[[20, 28, 'selected_text']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "\n",
      " 33%|                                                          | 1/3 [01:10<02:20, 70.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 32123.792404081207}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                             | 2/3 [02:20<01:10, 70.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28874.46996561622}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [03:27<00:00, 69.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 27161.839791838494}\n",
      "Saved model to ../working/models/model_neg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment = 'negative'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(text, model):\n",
    "    doc = model(text)\n",
    "    ent_array = []\n",
    "    for ent in doc.ents:\n",
    "        start = text.find(ent.text)\n",
    "        end = start + len(ent.text)\n",
    "        new_int = [start, end, ent.label_]\n",
    "        if new_int not in ent_array:\n",
    "            ent_array.append([start, end, ent.label_])\n",
    "    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
    "    return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models  from  ../working/models/\n"
     ]
    }
   ],
   "source": [
    "selected_texts = []\n",
    "MODELS_BASE_PATH = '../working/models/'\n",
    "\n",
    "if MODELS_BASE_PATH is not None:\n",
    "    print(\"Loading Models  from \", MODELS_BASE_PATH)\n",
    "    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n",
    "    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n",
    "        \n",
    "    for index, row in df_test.iterrows():\n",
    "        text = row.text\n",
    "        output_str = \"\"\n",
    "        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n",
    "            selected_texts.append(text)\n",
    "        elif row.sentiment == 'positive':\n",
    "            selected_texts.append(predict_entities(text, model_pos))\n",
    "        else:\n",
    "            selected_texts.append(predict_entities(text, model_neg))\n",
    "        \n",
    "df_test['selected_text'] = selected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                      selected_text\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n",
       "1  96d74cb729                                           exciting\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...\n",
       "3  01082688c6                                        happy bday!\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!\n",
       "5  726e501993                    that`s great!! weee!! visitors!\n",
       "6  261932614e            I THINK EVERYONE HATES ME ON HERE   lol\n",
       "7  afa11da83f   soooooo wish i could, but im in school and my...\n",
       "8  e64208b4ef   and within a short time of the last clue all ...\n",
       "9  37bcad24ca   What did you get?  My day is alright.. haven`..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_submission['selected_text'] = df_test['selected_text']\n",
    "df_submission.to_csv(\"submission.csv\", index=False)\n",
    "display(df_submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finished !!!! did not undestand the last part...but just wanted to complete this...!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
